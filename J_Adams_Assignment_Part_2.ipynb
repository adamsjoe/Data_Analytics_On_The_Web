{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J_Adams_Assignment_Part_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2YM-cY3XAb1"
      },
      "source": [
        "# Training a linear regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4OkOIjgXImQ"
      },
      "source": [
        "### Background\n",
        "\n",
        "The dataset which was created for part 1 has been constructed so that each borough can be identified.  This means that a linear regressor could be made for each indivual borough.  As the code uses the dataset with the same structure, what works for one, would work for all.  However, in order to simplifiy this notebook, only one borough will be used.  That borough is **Manhatten**.\n",
        "\n",
        "To begin with, the data must first be loaded.  Once loaded, using the query method of the pandas dataframe the rows which are in Mahattan can be extracted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUkPRKJw1mm6"
      },
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load the data as per normal\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv', index_col=0)\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv')\n",
        "\n",
        "# now setup to query the dataframe for only the borough noted\n",
        "borough_df = df.query('BOROUGH==\"MANHATTAN\"')\n",
        "\n",
        "# ignore this for now\n",
        "# remove 2012\n",
        "remove_2012 = borough_df.query('YEAR!=2012')\n",
        "\n",
        "# remove 2020\n",
        "remove_2020 = remove_2012.query('YEAR!=2020')\n",
        "\n",
        "#remove 2021\n",
        "remove_2021 = remove_2020.query('YEAR!=2021')\n",
        "\n",
        "# make a new dataframe, which by now shall only contain data for Manhattan in the years 2013 to 2019\n",
        "manhat_df = remove_2021\n",
        "\n",
        "year_2013 = manhat_df.query(\"YEAR==2013\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYJbRFX5YExF"
      },
      "source": [
        "#### Data Verification\n",
        "\n",
        "Once the data has been loaded, it is a good idea to check this.  Printing only 6 rows shows that all are Manhattan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNzPMAL314nG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae26a7e-225f-46ee-97f7-c20460e25e33"
      },
      "source": [
        "# check the data had loaded by printing it\n",
        "print(manhat_df[:6])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "924  04-02-2013  MANHATTAN        1  ...          0         14        93\n",
            "929  19-01-2013  MANHATTAN        6  ...          0         19       108\n",
            "931  24-01-2013  MANHATTAN        4  ...          0         31       125\n",
            "936  24-05-2013  MANHATTAN        5  ...          0         41       153\n",
            "941  24-04-2013  MANHATTAN        3  ...          1         21       117\n",
            "946  07-03-2013  MANHATTAN        4  ...          0         18       110\n",
            "\n",
            "[6 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSW7NtK4dBAj"
      },
      "source": [
        "## Import numpy and shuffle\n",
        "\n",
        "Create a new shuffled data by using the random permutation function of numpy using the length of the original mahattan data frame.  In this particular data set this is important as the data is time series (or time series derived) and there could be patterns within the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-NlRVds2BEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3186ecf5-4e46-4c73-940e-aee35299c6b0"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhatten = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "print(shuffle_manhatten[:5])\n",
        "\n",
        "# setup constant for use later\n",
        "SCALE_NUM_COLS = 1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "11229  11-02-2018  MANHATTAN        7  ...          0         17       103\n",
            "2044   02-07-2013  MANHATTAN        2  ...          1         24       119\n",
            "10511  15-07-2018  MANHATTAN        7  ...          1         21       108\n",
            "6325   08-09-2015  MANHATTAN        2  ...          0         27       167\n",
            "2263   17-05-2013  MANHATTAN        5  ...          0         28       171\n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFG25By8dtfc"
      },
      "source": [
        "## Predictors, Training set and Testing set\n",
        "\n",
        "Firstly the predictors are created.  These are created from the shuffled data and only the third, fourth, fifth, seventh and last column is used.  These are, in order, year, month, day, temp and num_cols (number of collisions).  If the data was not being filtered by borough at the start, then the borough would need to be brought in also.\n",
        "\n",
        "The Target is then defined - this is the last column in the shuffled dataset.\n",
        "\n",
        "The training set will be 80% of the full data set (0.8) and the testing data will be the remainder - so in this case, 100 - 80 = 20%\n",
        "\n",
        "Constants are setup for the number of predictors (3 in this case: year, month and day) and the number of outputs (or targets, which is 1 here.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01AcNdrBh3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77edf61-305b-4847-b30c-cc69f6164553"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[3,4,5]]\n",
        "print(predictors_manhatten[:6])\n",
        "\n",
        "# We want the last column (the NUM_COLS)\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "print(targets_manhattan[:6])\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month and year = 3 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 3\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       YEAR  MONTH  DAY\n",
            "11229  2018      2   11\n",
            "2044   2013      7    2\n",
            "10511  2018      7   15\n",
            "6325   2015      9    8\n",
            "2263   2013      5   17\n",
            "8512   2017      2   27\n",
            "11229    103\n",
            "2044     119\n",
            "10511    108\n",
            "6325     167\n",
            "2263     171\n",
            "8512      85\n",
            "Name: NUM_COLS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9cyW1wjfAIk"
      },
      "source": [
        "### Verification\n",
        "\n",
        "Just a simple print to ensure the predictor and values are populated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYOnh5yUElQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e14a2b3e-dc77-4959-ada1-d473f9184ffb"
      },
      "source": [
        "print(predictors_manhatten.values)\n",
        "print(predictors_manhatten)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2018    2   11]\n",
            " [2013    7    2]\n",
            " [2018    7   15]\n",
            " ...\n",
            " [2018    9   20]\n",
            " [2018    6    3]\n",
            " [2015    9    5]]\n",
            "       YEAR  MONTH  DAY\n",
            "11229  2018      2   11\n",
            "2044   2013      7    2\n",
            "10511  2018      7   15\n",
            "6325   2015      9    8\n",
            "2263   2013      5   17\n",
            "...     ...    ...  ...\n",
            "4290   2014      2   15\n",
            "1511   2013      5   19\n",
            "11468  2018      9   20\n",
            "11546  2018      6    3\n",
            "5712   2015      9    5\n",
            "\n",
            "[2556 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axySTDY1fKHw"
      },
      "source": [
        "## The Tensorflow bit.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIj_sLztBlsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aedc1f8a-a827-4e08-dcf4-5ecd46e8be1e"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model'\n",
        "\n",
        "# remove the last training model - if it is present\n",
        "if os.path.isdir(manhattan_dir):\n",
        "  print(\"\\n// Removing old model directory ....\")\n",
        "  shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "else:\n",
        "  print(\"\\n// No model directory to remove ....\")\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.1), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\\n\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan,NO_TARGETS)/SCALE_NUM_COLS, steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - predslistscale)**2))\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('\\n\\n// Lnear Regression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('\\n\\n// Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "\n",
            "// No model directory to remove ....\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-6-9488ecbb1cd5>:28: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please convert numpy dtypes explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/linear.py:740: regression_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.contrib.estimator.*_head.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9863aa5310>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:From <ipython-input-6-9488ecbb1cd5>:28: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to the Estimator interface.\n",
            "// Starting to train Manhattan model............\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 15265.641, step = 1\n",
            "INFO:tensorflow:global_step/sec: 754.469\n",
            "INFO:tensorflow:loss = 875.73645, step = 101 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 910.21\n",
            "INFO:tensorflow:loss = 751.6991, step = 201 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 810.945\n",
            "INFO:tensorflow:loss = 646.26843, step = 301 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 873.897\n",
            "INFO:tensorflow:loss = 578.2637, step = 401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 909.821\n",
            "INFO:tensorflow:loss = 745.7429, step = 501 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.915\n",
            "INFO:tensorflow:loss = 561.95575, step = 601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 932.924\n",
            "INFO:tensorflow:loss = 1062.3799, step = 701 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 835.772\n",
            "INFO:tensorflow:loss = 770.6991, step = 801 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 910.195\n",
            "INFO:tensorflow:loss = 662.66626, step = 901 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 869.751\n",
            "INFO:tensorflow:loss = 708.79895, step = 1001 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.782\n",
            "INFO:tensorflow:loss = 955.7309, step = 1101 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 866.255\n",
            "INFO:tensorflow:loss = 948.77814, step = 1201 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.784\n",
            "INFO:tensorflow:loss = 612.2501, step = 1301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 839.768\n",
            "INFO:tensorflow:loss = 632.59674, step = 1401 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 908.174\n",
            "INFO:tensorflow:loss = 937.7179, step = 1501 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.47\n",
            "INFO:tensorflow:loss = 704.2484, step = 1601 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 778.375\n",
            "INFO:tensorflow:loss = 1014.598, step = 1701 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 773.409\n",
            "INFO:tensorflow:loss = 849.66516, step = 1801 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 875.965\n",
            "INFO:tensorflow:loss = 547.7467, step = 1901 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 828.611\n",
            "INFO:tensorflow:loss = 639.8302, step = 2001 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 927.999\n",
            "INFO:tensorflow:loss = 1288.8448, step = 2101 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 934.935\n",
            "INFO:tensorflow:loss = 596.96967, step = 2201 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.809\n",
            "INFO:tensorflow:loss = 620.36237, step = 2301 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.531\n",
            "INFO:tensorflow:loss = 978.72235, step = 2401 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 894.957\n",
            "INFO:tensorflow:loss = 625.55695, step = 2501 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 837.624\n",
            "INFO:tensorflow:loss = 805.9225, step = 2601 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 836.342\n",
            "INFO:tensorflow:loss = 622.9663, step = 2701 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 883.114\n",
            "INFO:tensorflow:loss = 771.5093, step = 2801 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 789.102\n",
            "INFO:tensorflow:loss = 632.56104, step = 2901 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 951.331\n",
            "INFO:tensorflow:loss = 673.01685, step = 3001 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 807.879\n",
            "INFO:tensorflow:loss = 672.3506, step = 3101 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 836.232\n",
            "INFO:tensorflow:loss = 680.7364, step = 3201 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 869.534\n",
            "INFO:tensorflow:loss = 563.43256, step = 3301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.349\n",
            "INFO:tensorflow:loss = 1077.4379, step = 3401 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 956.658\n",
            "INFO:tensorflow:loss = 936.07465, step = 3501 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 857.62\n",
            "INFO:tensorflow:loss = 637.0228, step = 3601 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 880.858\n",
            "INFO:tensorflow:loss = 656.4358, step = 3701 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 894.68\n",
            "INFO:tensorflow:loss = 655.8242, step = 3801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 862.435\n",
            "INFO:tensorflow:loss = 956.526, step = 3901 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.528\n",
            "INFO:tensorflow:loss = 647.37244, step = 4001 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.995\n",
            "INFO:tensorflow:loss = 631.7863, step = 4101 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 989.099\n",
            "INFO:tensorflow:loss = 1004.39404, step = 4201 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 866.875\n",
            "INFO:tensorflow:loss = 572.9149, step = 4301 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 962.352\n",
            "INFO:tensorflow:loss = 646.0637, step = 4401 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.721\n",
            "INFO:tensorflow:loss = 811.9579, step = 4501 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 880.992\n",
            "INFO:tensorflow:loss = 528.57855, step = 4601 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 832.722\n",
            "INFO:tensorflow:loss = 847.7732, step = 4701 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 851.635\n",
            "INFO:tensorflow:loss = 735.91, step = 4801 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 934.441\n",
            "INFO:tensorflow:loss = 704.60364, step = 4901 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 915.181\n",
            "INFO:tensorflow:loss = 791.43115, step = 5001 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 862.752\n",
            "INFO:tensorflow:loss = 700.40234, step = 5101 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.339\n",
            "INFO:tensorflow:loss = 531.21075, step = 5201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.355\n",
            "INFO:tensorflow:loss = 723.49493, step = 5301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 932.186\n",
            "INFO:tensorflow:loss = 746.29236, step = 5401 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 887.995\n",
            "INFO:tensorflow:loss = 1127.4404, step = 5501 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.632\n",
            "INFO:tensorflow:loss = 607.66644, step = 5601 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.544\n",
            "INFO:tensorflow:loss = 651.02765, step = 5701 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 914.013\n",
            "INFO:tensorflow:loss = 910.79724, step = 5801 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 901.925\n",
            "INFO:tensorflow:loss = 634.39197, step = 5901 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.407\n",
            "INFO:tensorflow:loss = 619.7812, step = 6001 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 850.991\n",
            "INFO:tensorflow:loss = 744.6896, step = 6101 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.553\n",
            "INFO:tensorflow:loss = 837.15295, step = 6201 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 881.182\n",
            "INFO:tensorflow:loss = 702.77124, step = 6301 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 900.879\n",
            "INFO:tensorflow:loss = 607.4418, step = 6401 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 888.259\n",
            "INFO:tensorflow:loss = 1400.9595, step = 6501 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.656\n",
            "INFO:tensorflow:loss = 1248.6288, step = 6601 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 867.617\n",
            "INFO:tensorflow:loss = 788.719, step = 6701 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 939.382\n",
            "INFO:tensorflow:loss = 699.9753, step = 6801 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 905.379\n",
            "INFO:tensorflow:loss = 794.92645, step = 6901 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 887.503\n",
            "INFO:tensorflow:loss = 1244.8647, step = 7001 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 876.102\n",
            "INFO:tensorflow:loss = 711.5847, step = 7101 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 862.52\n",
            "INFO:tensorflow:loss = 748.91565, step = 7201 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 898.199\n",
            "INFO:tensorflow:loss = 856.5515, step = 7301 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 872.964\n",
            "INFO:tensorflow:loss = 981.19684, step = 7401 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.281\n",
            "INFO:tensorflow:loss = 733.42255, step = 7501 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 902.812\n",
            "INFO:tensorflow:loss = 1276.3848, step = 7601 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.877\n",
            "INFO:tensorflow:loss = 1036.4823, step = 7701 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.441\n",
            "INFO:tensorflow:loss = 1070.1407, step = 7801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 871.614\n",
            "INFO:tensorflow:loss = 585.78284, step = 7901 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.994\n",
            "INFO:tensorflow:loss = 721.90826, step = 8001 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 872.096\n",
            "INFO:tensorflow:loss = 701.282, step = 8101 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 780.076\n",
            "INFO:tensorflow:loss = 749.3536, step = 8201 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.085\n",
            "INFO:tensorflow:loss = 883.2998, step = 8301 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.25\n",
            "INFO:tensorflow:loss = 577.32324, step = 8401 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.279\n",
            "INFO:tensorflow:loss = 600.1791, step = 8501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 925.011\n",
            "INFO:tensorflow:loss = 855.84106, step = 8601 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 808.012\n",
            "INFO:tensorflow:loss = 987.7743, step = 8701 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 913.517\n",
            "INFO:tensorflow:loss = 937.77277, step = 8801 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 878.535\n",
            "INFO:tensorflow:loss = 644.8561, step = 8901 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 909.563\n",
            "INFO:tensorflow:loss = 728.3578, step = 9001 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 902.278\n",
            "INFO:tensorflow:loss = 524.36804, step = 9101 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 814.02\n",
            "INFO:tensorflow:loss = 596.41675, step = 9201 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 894.028\n",
            "INFO:tensorflow:loss = 734.72327, step = 9301 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.32\n",
            "INFO:tensorflow:loss = 616.33923, step = 9401 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 869.664\n",
            "INFO:tensorflow:loss = 690.56177, step = 9501 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 891.243\n",
            "INFO:tensorflow:loss = 978.1345, step = 9601 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 977.869\n",
            "INFO:tensorflow:loss = 722.7284, step = 9701 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 892.848\n",
            "INFO:tensorflow:loss = 980.55756, step = 9801 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 841.718\n",
            "INFO:tensorflow:loss = 800.4274, step = 9901 (0.118 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 848.9869.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "// Lnear Regression has RMSE of 26.291278524360123\n",
            "\n",
            "\n",
            "// Just using average = 120.52054794520548 has RMSE of 24.454960709369775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t23ehycblB5R"
      },
      "source": [
        "## Initial Output\n",
        "\n",
        "The RSME is quite large, which would indicate a not accurate model - however this model is only trying to predict based on a day.  Not using any extra conditions.  Temperature could be added in and this may affect the the output.\n",
        "\n",
        "The model needs to be tested first, to do this some values will be fed in to be the target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pizTrw7Aks8S"
      },
      "source": [
        "## Inital Prediction\n",
        "\n",
        "```python\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'DAY' : [1, 1, 1]\n",
        "        })\n",
        "\n",
        "```\n",
        "\n",
        "Setting up the values for preduction, 3 have been chosen.  1/1/2013, 1/6/2016 and 1.12/2022 will be fed into model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjS3zTafVMB8",
        "outputId": "d6f39203-ce07-4cfa-d009-c0ca2d2a9e51"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'DAY' : [1, 1, 1]\n",
        "        })\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)\n",
        "                                                                                 )\n",
        ")\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 1.0\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98b9a74e10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[123.973206 130.58997  138.67604 ]\n",
            "[123.973206 130.58997  138.67604 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hnzo1hOFa-l"
      },
      "source": [
        "### Result of First Run\n",
        "\n",
        "The output (at the time of writing) was \n",
        "\n",
        "[117.42061  123.957085 131.939   ]\n",
        "\n",
        "The model is being asked to predict 3 dates.  Two of these dates are known, these can be used as \"control\" dates - the number of collisions is known - so these should be fairly accurate (or at least, that is the theory...)\n",
        "\n",
        "The dates are:\n",
        "\n",
        "Date|Prediction|Actual\n",
        ":--:|:--------:|:----:\n",
        "1/1/2013|117|78\n",
        "1/6/2016|123|121\n",
        "1/12/2020|131|N/A\n",
        "\n",
        "While the trend is, generally, going upwards, which does **sort of** look ok.. As noted above, it would be a good idea to try to add in an additional predictor.  The Temp value should suffice.\n",
        "\n",
        "**Note** these values may change if the notebook is run at a later stage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65w8sb15lZj3"
      },
      "source": [
        "## Adding in Temp\n",
        "\n",
        "The code cells will be copied from above, this time the predictors will be ammeded to include temperature.\n",
        "\n",
        "**Note:** For brevity, the additional prints will not be inluded and all code will be added to the one cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxd35_S4ln2-",
        "outputId": "e4ea6178-eb1c-4ca3-c70d-38e54ce28990"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[3,4,5,7]]\n",
        "print(predictors_manhatten[:6])\n",
        "\n",
        "# We want the last column (the NUM_COLS)\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "print(targets_manhattan[:6])\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month, year and now temp = 4 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 4\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model_including_temp'\n",
        "\n",
        "# remove the last training model\n",
        "shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.1), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\\n\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan,NO_TARGETS)/SCALE_NUM_COLS, steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - predslistscale)**2))\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('\\n\\n// Lnear Regression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('\\n\\n// Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       YEAR  MONTH  DAY  TEMP\n",
            "11229  2018      2   11  46.3\n",
            "2044   2013      7    2  67.7\n",
            "10511  2018      7   15  65.5\n",
            "6325   2015      9    8  76.4\n",
            "2263   2013      5   17  58.2\n",
            "8512   2017      2   27  39.1\n",
            "11229    103\n",
            "2044     119\n",
            "10511    108\n",
            "6325     167\n",
            "2263     171\n",
            "8512      85\n",
            "Name: NUM_COLS, dtype: int64\n",
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f985b5a9750>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp', '_session_creation_timeout_secs': 7200}\n",
            "// Starting to train Manhattan model............\n",
            "\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_including_temp/model.ckpt.\n",
            "INFO:tensorflow:loss = 15265.641, step = 1\n",
            "INFO:tensorflow:global_step/sec: 820.527\n",
            "INFO:tensorflow:loss = 867.36816, step = 101 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 947.93\n",
            "INFO:tensorflow:loss = 700.314, step = 201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 914.673\n",
            "INFO:tensorflow:loss = 638.85205, step = 301 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.767\n",
            "INFO:tensorflow:loss = 571.464, step = 401 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 845.919\n",
            "INFO:tensorflow:loss = 715.1377, step = 501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.054\n",
            "INFO:tensorflow:loss = 524.84424, step = 601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 939.239\n",
            "INFO:tensorflow:loss = 1270.9135, step = 701 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 866.205\n",
            "INFO:tensorflow:loss = 758.94165, step = 801 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 842.323\n",
            "INFO:tensorflow:loss = 660.76746, step = 901 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 878.298\n",
            "INFO:tensorflow:loss = 648.2138, step = 1001 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.502\n",
            "INFO:tensorflow:loss = 884.7716, step = 1101 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 951.97\n",
            "INFO:tensorflow:loss = 867.1008, step = 1201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.997\n",
            "INFO:tensorflow:loss = 593.69794, step = 1301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 925.57\n",
            "INFO:tensorflow:loss = 722.232, step = 1401 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 905.189\n",
            "INFO:tensorflow:loss = 931.91473, step = 1501 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.221\n",
            "INFO:tensorflow:loss = 619.0823, step = 1601 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 877.132\n",
            "INFO:tensorflow:loss = 774.103, step = 1701 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 837.635\n",
            "INFO:tensorflow:loss = 946.8242, step = 1801 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 895.383\n",
            "INFO:tensorflow:loss = 548.5069, step = 1901 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 962.491\n",
            "INFO:tensorflow:loss = 620.8449, step = 2001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 925.736\n",
            "INFO:tensorflow:loss = 1119.1569, step = 2101 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.015\n",
            "INFO:tensorflow:loss = 595.94196, step = 2201 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.223\n",
            "INFO:tensorflow:loss = 622.58325, step = 2301 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.092\n",
            "INFO:tensorflow:loss = 815.8578, step = 2401 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.575\n",
            "INFO:tensorflow:loss = 641.2973, step = 2501 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 835.124\n",
            "INFO:tensorflow:loss = 712.8569, step = 2601 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.756\n",
            "INFO:tensorflow:loss = 630.0758, step = 2701 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.176\n",
            "INFO:tensorflow:loss = 769.69714, step = 2801 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 942.714\n",
            "INFO:tensorflow:loss = 569.93713, step = 2901 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.623\n",
            "INFO:tensorflow:loss = 628.9882, step = 3001 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.755\n",
            "INFO:tensorflow:loss = 684.51074, step = 3101 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 848.014\n",
            "INFO:tensorflow:loss = 650.7322, step = 3201 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 938.495\n",
            "INFO:tensorflow:loss = 545.22205, step = 3301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 920.225\n",
            "INFO:tensorflow:loss = 1035.2688, step = 3401 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.109\n",
            "INFO:tensorflow:loss = 911.7787, step = 3501 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 922.265\n",
            "INFO:tensorflow:loss = 606.37964, step = 3601 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.393\n",
            "INFO:tensorflow:loss = 618.21564, step = 3701 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 940.868\n",
            "INFO:tensorflow:loss = 669.65497, step = 3801 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 887.901\n",
            "INFO:tensorflow:loss = 874.87976, step = 3901 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 832.894\n",
            "INFO:tensorflow:loss = 629.63855, step = 4001 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.112\n",
            "INFO:tensorflow:loss = 606.6763, step = 4101 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 911.247\n",
            "INFO:tensorflow:loss = 821.9286, step = 4201 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 939.405\n",
            "INFO:tensorflow:loss = 564.52423, step = 4301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 913.288\n",
            "INFO:tensorflow:loss = 605.68225, step = 4401 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 905.662\n",
            "INFO:tensorflow:loss = 749.5873, step = 4501 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 890.51\n",
            "INFO:tensorflow:loss = 493.12695, step = 4601 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.558\n",
            "INFO:tensorflow:loss = 767.19604, step = 4701 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 940.448\n",
            "INFO:tensorflow:loss = 688.7181, step = 4801 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 852.153\n",
            "INFO:tensorflow:loss = 699.7587, step = 4901 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.38\n",
            "INFO:tensorflow:loss = 703.5851, step = 5001 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 876.391\n",
            "INFO:tensorflow:loss = 742.88965, step = 5101 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.984\n",
            "INFO:tensorflow:loss = 542.65234, step = 5201 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 879.099\n",
            "INFO:tensorflow:loss = 779.3903, step = 5301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 905.727\n",
            "INFO:tensorflow:loss = 718.80884, step = 5401 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 871.232\n",
            "INFO:tensorflow:loss = 1132.2047, step = 5501 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 976.441\n",
            "INFO:tensorflow:loss = 623.7566, step = 5601 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.246\n",
            "INFO:tensorflow:loss = 665.5051, step = 5701 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.114\n",
            "INFO:tensorflow:loss = 764.70984, step = 5801 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 858.814\n",
            "INFO:tensorflow:loss = 730.2805, step = 5901 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.04\n",
            "INFO:tensorflow:loss = 580.75574, step = 6001 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 971.551\n",
            "INFO:tensorflow:loss = 648.72534, step = 6101 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 892.2\n",
            "INFO:tensorflow:loss = 743.477, step = 6201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.182\n",
            "INFO:tensorflow:loss = 645.42615, step = 6301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 902.535\n",
            "INFO:tensorflow:loss = 673.83167, step = 6401 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 987.076\n",
            "INFO:tensorflow:loss = 1230.0603, step = 6501 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.048\n",
            "INFO:tensorflow:loss = 1409.3696, step = 6601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 953.641\n",
            "INFO:tensorflow:loss = 931.5504, step = 6701 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 913.422\n",
            "INFO:tensorflow:loss = 647.02405, step = 6801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 1003.69\n",
            "INFO:tensorflow:loss = 862.63635, step = 6901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.886\n",
            "INFO:tensorflow:loss = 1224.0983, step = 7001 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 866.395\n",
            "INFO:tensorflow:loss = 751.843, step = 7101 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 954.766\n",
            "INFO:tensorflow:loss = 697.2035, step = 7201 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 896.32\n",
            "INFO:tensorflow:loss = 720.5285, step = 7301 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.907\n",
            "INFO:tensorflow:loss = 1099.5726, step = 7401 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.042\n",
            "INFO:tensorflow:loss = 596.14966, step = 7501 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 810.138\n",
            "INFO:tensorflow:loss = 1179.6841, step = 7601 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 839.818\n",
            "INFO:tensorflow:loss = 1004.2803, step = 7701 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 850.249\n",
            "INFO:tensorflow:loss = 1012.9506, step = 7801 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.895\n",
            "INFO:tensorflow:loss = 585.8528, step = 7901 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 866.984\n",
            "INFO:tensorflow:loss = 670.61597, step = 8001 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 963.765\n",
            "INFO:tensorflow:loss = 684.52673, step = 8101 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 935.706\n",
            "INFO:tensorflow:loss = 673.036, step = 8201 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 920.076\n",
            "INFO:tensorflow:loss = 835.4187, step = 8301 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 939.989\n",
            "INFO:tensorflow:loss = 564.1381, step = 8401 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 969.1\n",
            "INFO:tensorflow:loss = 552.6888, step = 8501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 927.178\n",
            "INFO:tensorflow:loss = 803.5179, step = 8601 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 889.772\n",
            "INFO:tensorflow:loss = 971.2787, step = 8701 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 959.595\n",
            "INFO:tensorflow:loss = 929.7265, step = 8801 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 830.212\n",
            "INFO:tensorflow:loss = 643.10645, step = 8901 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 937.329\n",
            "INFO:tensorflow:loss = 667.9939, step = 9001 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 935.245\n",
            "INFO:tensorflow:loss = 481.68854, step = 9101 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 778.937\n",
            "INFO:tensorflow:loss = 571.2899, step = 9201 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.556\n",
            "INFO:tensorflow:loss = 689.92334, step = 9301 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.632\n",
            "INFO:tensorflow:loss = 583.4177, step = 9401 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 867.088\n",
            "INFO:tensorflow:loss = 707.40137, step = 9501 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.708\n",
            "INFO:tensorflow:loss = 1117.3962, step = 9601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 879.064\n",
            "INFO:tensorflow:loss = 725.5422, step = 9701 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 893.721\n",
            "INFO:tensorflow:loss = 874.1386, step = 9801 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.54\n",
            "INFO:tensorflow:loss = 770.34094, step = 9901 (0.106 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_including_temp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 813.56195.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "// Lnear Regression has RMSE of 24.11964121576692\n",
            "\n",
            "\n",
            "// Just using average = 120.52054794520548 has RMSE of 24.454960709369775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMnfjCXRmT_D",
        "outputId": "47abb519-ee30-4b98-d914-7abfcaa62bb8"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'DAY' : [1, 1, 1],\n",
        "         'TEMP': [35,60,30]\n",
        "        })\n",
        "\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)\n",
        "                                                                                 )\n",
        ")\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "# print(preds)\n",
        "\n",
        "# The Number of collisions scale will be 106.072969 - which is the average number of collisions in Manhattan (359057 (collisions)/ 3385 (days))\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 106.072969\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98619b6cd0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp', '_session_creation_timeout_secs': 7200}\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[108.22681  120.34025  114.661476]\n",
            "[11479.938 12764.848 12162.483]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M1tZRi3mxmo"
      },
      "source": [
        "### After Temp\n",
        "\n",
        "After adding in the temp, the values have changed:\n",
        "\n",
        "\n",
        "Date|Prediction (no temp)|Prediction (with temp)|Actual\n",
        ":--:|:------------------:|:--------------------:|:----:\n",
        "1/1/2013|122|112|78|\n",
        "1/6/2016|128|125|121|\n",
        "1/12/2020|135|119|N/A|\n",
        "\n",
        "So while the values are pulling closer (on this current run) they are not **exact**\n",
        "\n",
        "Looking at the data from part 1 of the assignment, year, month and day do not affect the outputs, at least not directly.  Temperature and Weekday do.  So, the model could be changed to use these as predictors. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtiQ7GRssxjM"
      },
      "source": [
        "## Using Temperature and Weekday \n",
        "\n",
        "Taking the code from above, it will be modified to use these two parameters as predictors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yIdAco-s8Dn",
        "outputId": "2b815616-3819-40af-8353-4f1c554e3a0f"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[2,7]]\n",
        "print(\"// Printing predictors ...\")\n",
        "print(predictors_manhatten[:6])\n",
        "\n",
        "# We want the last column (the NUM_COLS)\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "print(\"// Printing targets .....\")\n",
        "print(targets_manhattan[:6])\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month, year and now temp = 4 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 2\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model_including_temp_and_weekday'\n",
        "\n",
        "# remove the last training model\n",
        "shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.1), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\\n\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan,NO_TARGETS)/SCALE_NUM_COLS, steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - predslistscale)**2))\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('\\n\\n// Lnear Regression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('\\n\\n// Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// Printing predictors ...\n",
            "       WEEKDAY  TEMP\n",
            "11229        7  46.3\n",
            "2044         2  67.7\n",
            "10511        7  65.5\n",
            "6325         2  76.4\n",
            "2263         5  58.2\n",
            "8512         1  39.1\n",
            "// Printing targets .....\n",
            "11229    103\n",
            "2044     119\n",
            "10511    108\n",
            "6325     167\n",
            "2263     171\n",
            "8512      85\n",
            "Name: NUM_COLS, dtype: int64\n",
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f986198dc90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp_and_weekday', '_session_creation_timeout_secs': 7200}\n",
            "// Starting to train Manhattan model............\n",
            "\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt.\n",
            "INFO:tensorflow:loss = 15265.641, step = 1\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 26 vs previous value: 26. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 31 vs previous value: 31. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 51 vs previous value: 51. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 637.382\n",
            "INFO:tensorflow:loss = 1368.9404, step = 101 (0.164 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 142 vs previous value: 142. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 145 vs previous value: 145. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 803.95\n",
            "INFO:tensorflow:loss = 1032.7516, step = 201 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 925.915\n",
            "INFO:tensorflow:loss = 1250.5166, step = 301 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.826\n",
            "INFO:tensorflow:loss = 1138.655, step = 401 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 820.562\n",
            "INFO:tensorflow:loss = 1301.8218, step = 501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 925.317\n",
            "INFO:tensorflow:loss = 908.1094, step = 601 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.239\n",
            "INFO:tensorflow:loss = 1128.7528, step = 701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 880.058\n",
            "INFO:tensorflow:loss = 957.55615, step = 801 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 902.739\n",
            "INFO:tensorflow:loss = 1126.5847, step = 901 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 921.199\n",
            "INFO:tensorflow:loss = 900.6199, step = 1001 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 778.928\n",
            "INFO:tensorflow:loss = 955.2146, step = 1101 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 959.938\n",
            "INFO:tensorflow:loss = 1034.6096, step = 1201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 953.914\n",
            "INFO:tensorflow:loss = 736.1588, step = 1301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.306\n",
            "INFO:tensorflow:loss = 777.1933, step = 1401 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.485\n",
            "INFO:tensorflow:loss = 936.18884, step = 1501 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1002.5\n",
            "INFO:tensorflow:loss = 642.82733, step = 1601 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.77\n",
            "INFO:tensorflow:loss = 657.8523, step = 1701 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.663\n",
            "INFO:tensorflow:loss = 832.11926, step = 1801 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.32\n",
            "INFO:tensorflow:loss = 601.8274, step = 1901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 894.26\n",
            "INFO:tensorflow:loss = 632.9334, step = 2001 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 900.336\n",
            "INFO:tensorflow:loss = 630.10126, step = 2101 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.587\n",
            "INFO:tensorflow:loss = 529.1714, step = 2201 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.768\n",
            "INFO:tensorflow:loss = 632.843, step = 2301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 967.245\n",
            "INFO:tensorflow:loss = 677.1475, step = 2401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1011.46\n",
            "INFO:tensorflow:loss = 733.221, step = 2501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.749\n",
            "INFO:tensorflow:loss = 528.6858, step = 2601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.204\n",
            "INFO:tensorflow:loss = 594.6445, step = 2701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 869.677\n",
            "INFO:tensorflow:loss = 539.90015, step = 2801 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 896.571\n",
            "INFO:tensorflow:loss = 549.2431, step = 2901 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.128\n",
            "INFO:tensorflow:loss = 587.1086, step = 3001 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.654\n",
            "INFO:tensorflow:loss = 676.9301, step = 3101 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.238\n",
            "INFO:tensorflow:loss = 646.14417, step = 3201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1019.7\n",
            "INFO:tensorflow:loss = 448.34915, step = 3301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 915.044\n",
            "INFO:tensorflow:loss = 610.21423, step = 3401 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 994.352\n",
            "INFO:tensorflow:loss = 754.5785, step = 3501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 858.031\n",
            "INFO:tensorflow:loss = 536.71783, step = 3601 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.11\n",
            "INFO:tensorflow:loss = 586.45593, step = 3701 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.463\n",
            "INFO:tensorflow:loss = 624.77515, step = 3801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.677\n",
            "INFO:tensorflow:loss = 624.8659, step = 3901 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.197\n",
            "INFO:tensorflow:loss = 589.9039, step = 4001 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1012.55\n",
            "INFO:tensorflow:loss = 576.6937, step = 4101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 894.646\n",
            "INFO:tensorflow:loss = 537.67444, step = 4201 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 890.202\n",
            "INFO:tensorflow:loss = 571.21277, step = 4301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 954.496\n",
            "INFO:tensorflow:loss = 603.63495, step = 4401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.321\n",
            "INFO:tensorflow:loss = 731.2427, step = 4501 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.814\n",
            "INFO:tensorflow:loss = 466.94012, step = 4601 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 867.438\n",
            "INFO:tensorflow:loss = 750.0165, step = 4701 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.195\n",
            "INFO:tensorflow:loss = 672.113, step = 4801 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.57\n",
            "INFO:tensorflow:loss = 645.66266, step = 4901 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 967.328\n",
            "INFO:tensorflow:loss = 557.26025, step = 5001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 968.729\n",
            "INFO:tensorflow:loss = 643.8043, step = 5101 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.624\n",
            "INFO:tensorflow:loss = 553.9033, step = 5201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.935\n",
            "INFO:tensorflow:loss = 642.3055, step = 5301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 917.968\n",
            "INFO:tensorflow:loss = 708.98285, step = 5401 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 899\n",
            "INFO:tensorflow:loss = 782.7035, step = 5501 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 858.521\n",
            "INFO:tensorflow:loss = 607.115, step = 5601 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.636\n",
            "INFO:tensorflow:loss = 651.74023, step = 5701 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 886.918\n",
            "INFO:tensorflow:loss = 691.28064, step = 5801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.273\n",
            "INFO:tensorflow:loss = 640.6738, step = 5901 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 966.882\n",
            "INFO:tensorflow:loss = 570.2241, step = 6001 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 907.616\n",
            "INFO:tensorflow:loss = 610.1124, step = 6101 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.236\n",
            "INFO:tensorflow:loss = 665.4019, step = 6201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 891.878\n",
            "INFO:tensorflow:loss = 593.1786, step = 6301 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.033\n",
            "INFO:tensorflow:loss = 494.51257, step = 6401 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 962.089\n",
            "INFO:tensorflow:loss = 563.5275, step = 6501 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.892\n",
            "INFO:tensorflow:loss = 692.00525, step = 6601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 868.672\n",
            "INFO:tensorflow:loss = 698.50806, step = 6701 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 969.297\n",
            "INFO:tensorflow:loss = 605.9703, step = 6801 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 940.332\n",
            "INFO:tensorflow:loss = 679.39844, step = 6901 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 905.088\n",
            "INFO:tensorflow:loss = 682.1513, step = 7001 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.522\n",
            "INFO:tensorflow:loss = 709.3002, step = 7101 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 902.562\n",
            "INFO:tensorflow:loss = 623.7706, step = 7201 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.453\n",
            "INFO:tensorflow:loss = 613.1696, step = 7301 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.132\n",
            "INFO:tensorflow:loss = 750.6406, step = 7401 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.036\n",
            "INFO:tensorflow:loss = 614.46704, step = 7501 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.028\n",
            "INFO:tensorflow:loss = 700.934, step = 7601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 807.76\n",
            "INFO:tensorflow:loss = 594.2084, step = 7701 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.367\n",
            "INFO:tensorflow:loss = 694.78894, step = 7801 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 939.02\n",
            "INFO:tensorflow:loss = 550.3761, step = 7901 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.425\n",
            "INFO:tensorflow:loss = 656.30676, step = 8001 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.369\n",
            "INFO:tensorflow:loss = 677.3979, step = 8101 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 850.408\n",
            "INFO:tensorflow:loss = 640.91394, step = 8201 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 887.497\n",
            "INFO:tensorflow:loss = 816.1025, step = 8301 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 927.742\n",
            "INFO:tensorflow:loss = 553.6045, step = 8401 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.507\n",
            "INFO:tensorflow:loss = 527.2079, step = 8501 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 866.714\n",
            "INFO:tensorflow:loss = 668.76025, step = 8601 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.667\n",
            "INFO:tensorflow:loss = 695.04553, step = 8701 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 951.722\n",
            "INFO:tensorflow:loss = 658.59875, step = 8801 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.603\n",
            "INFO:tensorflow:loss = 600.96985, step = 8901 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.689\n",
            "INFO:tensorflow:loss = 616.4139, step = 9001 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 866.613\n",
            "INFO:tensorflow:loss = 480.82095, step = 9101 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.827\n",
            "INFO:tensorflow:loss = 537.83203, step = 9201 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.083\n",
            "INFO:tensorflow:loss = 665.94775, step = 9301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.84\n",
            "INFO:tensorflow:loss = 553.2164, step = 9401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.109\n",
            "INFO:tensorflow:loss = 565.30725, step = 9501 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.154\n",
            "INFO:tensorflow:loss = 645.09717, step = 9601 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.471\n",
            "INFO:tensorflow:loss = 685.10095, step = 9701 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 828.446\n",
            "INFO:tensorflow:loss = 529.41534, step = 9801 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 892.041\n",
            "INFO:tensorflow:loss = 710.2007, step = 9901 (0.112 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 603.9094.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "// Lnear Regression has RMSE of 24.006606090245764\n",
            "\n",
            "\n",
            "// Just using average = 120.52054794520548 has RMSE of 24.454960709369775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI3IEPqTuMcs"
      },
      "source": [
        "This still has quite a large RMSE.  However, running a prediction, again using a day which is known (but picking the weekday and temp values)\n",
        "\n",
        "Using 24-10-2018 in the Mathattan borough, the *WEEKDAY* was **3** and the *TEMP*  was **48.4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8KC5G76uW_5",
        "outputId": "e8cae249-71de-44e3-e7ac-1d225a4c5a4a"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'WEEKDAY' : [3],\n",
        "         'TEMP' : [48.4]\n",
        "        })\n",
        "\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)\n",
        "                                                                                 )\n",
        ")\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "# print(preds)\n",
        "\n",
        "# The Number of collisions scale will be 106.072969 - which is the average number of collisions in Manhattan (359057 (collisions)/ 3385 (days))\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 1\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98b9abcd10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp_and_weekday', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[126.49988]\n",
            "[126.49988]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5rrtbTyvoPQ"
      },
      "source": [
        "Which returns [120.53093] - the actual value of collisions was **120**  \n",
        "\n",
        "One thing to note is that the model always returns slightly more accidents than happened - in this case, that is probably a wise thing, better to be prepared for too many than too few accidents..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVR7uKHFqUKR"
      },
      "source": [
        "# Training a DNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uoa-o_t7N6BP"
      },
      "source": [
        "## Background\n",
        "\n",
        "The same dataset which was constructed during the first part of this assignment will be used here.  As before, the data will be limited to the Manhattan borough.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qcMkg_eOL_p"
      },
      "source": [
        "# Import pandas to use dataframes\n",
        "import pandas as pd\n",
        "\n",
        "# create data frame from csv file we hosted on our github\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv')\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/dnn_data.csv')\n",
        "\n",
        "# now setup to query the dataframe for only the boroughs noted\n",
        "manhat_df = df.query('BOROUGH==\"MANHATTAN\"')\n",
        "\n",
        "SCALE_NUM_COLS = 1.0"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV_YzN53OPBA"
      },
      "source": [
        "### Checking data loaded\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyHZeT4GOTab",
        "outputId": "c556dba6-87b1-4858-8cdb-7d7a396cc063"
      },
      "source": [
        "# Ensure data has loaded\n",
        "print(manhat_df[:6])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Unnamed: 0        DATE    BOROUGH  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "0            1  21-08-2012  MANHATTAN  ...          0         28       109\n",
            "6            7  27-10-2012  MANHATTAN  ...          0         20       122\n",
            "13          14  25-08-2012  MANHATTAN  ...          0         22        97\n",
            "16          17  09-09-2012  MANHATTAN  ...          0         29       109\n",
            "20          21  17-09-2012  MANHATTAN  ...          1         27       123\n",
            "28          29  23-11-2012  MANHATTAN  ...          0          5        66\n",
            "\n",
            "[6 rows x 46 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGRIp8ghOYNO"
      },
      "source": [
        "## Importing Numpy and setting preductors\n",
        "\n",
        "For the predictors, all the columns which have integer values are used.  The borough has been excluded (as only Manhattan is being selected) and the collision_date is being exluded (but those values are present in the DAY, MONTH and YEAR columns)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jmqYqn2OpMw",
        "outputId": "5d89b2c2-e3ea-48b5-d7ce-16c7ab672814"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhattan = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "\n",
        "# setup predictors\n",
        "# Removing the data fields as the DNN should be able to extract this.  Also exluding the borough field as only dealing with Manhattan\n",
        "predictors_manhattan = shuffle_manhattan.iloc[:,[3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28,29,30,31,32,33,34,35,36]]\n",
        "\n",
        "# Check -1 (for all columns) has worked\n",
        "print(predictors_manhattan[:6])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Fri  Mon  Sat  Sun  Thu  ...   MAX   MIN  PRCP  all_data.SNDP  FOG\n",
            "16074    0    0    0    0    0  ...  54.0  43.0  0.00          999.9    0\n",
            "2917     0    0    0    1    0  ...  72.0  54.0  0.00          999.9    0\n",
            "2614     0    1    0    0    0  ...  64.4  55.9  1.36          999.9    1\n",
            "2422     0    1    0    0    0  ...  55.9  42.8  0.00          999.9    0\n",
            "2410     0    0    1    0    0  ...  48.9  39.0  0.24          999.9    0\n",
            "7276     1    0    0    0    0  ...  81.0  66.9  0.00          999.9    1\n",
            "\n",
            "[6 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTJoKhCuOvL5",
        "outputId": "0297dadc-8f7e-4848-cd29-0bc0195d27ca"
      },
      "source": [
        "# print first 5 rows of the shuffle\n",
        "print(shuffle_manhattan[:5])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0        DATE    BOROUGH  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "16074       16075  24-03-2021  MANHATTAN  ...          0         24        44\n",
            "2917         2918  25-08-2014  MANHATTAN  ...          0         22       113\n",
            "2614         2615  11-06-2013  MANHATTAN  ...          0         16       128\n",
            "2422         2423  14-05-2013  MANHATTAN  ...          0         19       128\n",
            "2410         2411  21-04-2013  MANHATTAN  ...          0         25        74\n",
            "\n",
            "[5 rows x 46 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQQdhn5aOyQI"
      },
      "source": [
        "### Defining the target\n",
        "\n",
        "For this test model, only the number of collisions (NUM_COLS) is of interest.  This needs to be defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6R6mCNoO7oE",
        "outputId": "430bd48d-e3a0-4fbf-e441-cefe64f688b7"
      },
      "source": [
        "# Define the target (the NUM_COLS)\n",
        "target_manhatan = shuffle_manhattan.iloc[:,-1]\n",
        "\n",
        "# print the targets\n",
        "print(target_manhatan[:6])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16074     44\n",
            "2917     113\n",
            "2614     128\n",
            "2422     128\n",
            "2410      74\n",
            "7276     130\n",
            "Name: NUM_COLS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46NkBLJCPAb7"
      },
      "source": [
        "### Training and Testing dataset\n",
        "\n",
        "As with the linear regressor, a training and testing dataset of 80% and 20% of the results is defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMrFGPmSPIm_"
      },
      "source": [
        "# Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "training_size_manhattan = int(len(shuffle_manhattan['NUM_COLS'] ) *0.8)\n",
        "\n",
        "# The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "testing_size_manhattan = len(shuffle_manhattan['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# Define the number of input values (predictors) - won't be 27, it will not include the borough or date - but should it include the borough?\n",
        "no_predictors = 33\n",
        "\n",
        "# Define the number of output values (targets)\n",
        "no_outputs = 1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnmGlJyXPTtq"
      },
      "source": [
        "## The tensorflow bit...\n",
        "\n",
        "Now the tensorflow model can be setup.  This is mostly the same as the regressor (except the DNN uses the DNNRegressor, of course.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyMqMtXiPjr1",
        "outputId": "30667a34-8f9f-4df1-a1cc-743b257230ef"
      },
      "source": [
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "model_dir = '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model'\n",
        "\n",
        "# remove the last training model - if it is present\n",
        "if os.path.isdir(model_dir):\n",
        "  print(\"\\n// Removing old model directory ....\")\n",
        "  shutil.rmtree(model_dir, ignore_errors=True)\n",
        "else:\n",
        "  print(\"\\n// No model directory to remove ....\")\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(\n",
        "    model_dir=model_dir, \n",
        "    hidden_units=[20,18,14], \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhattan.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Prints a log to show model is starting to train\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator.fit(predictors_manhattan[:training_size_manhattan].values, \n",
        "              target_manhatan[:training_size_manhattan].values.reshape(training_size_manhattan, no_outputs) / SCALE_NUM_COLS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_manhattan[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((target_manhatan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the Life Satisfaction Values.\n",
        "avg = np.mean(shuffle_manhattan['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using Life Satisfaction Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhattan['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n",
            "\n",
            "// Removing old model directory ....\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f308d4f3910>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 101144.59, step = 1\n",
            "INFO:tensorflow:global_step/sec: 486.032\n",
            "INFO:tensorflow:loss = 1468.3466, step = 101 (0.211 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.496\n",
            "INFO:tensorflow:loss = 1597.5862, step = 201 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.314\n",
            "INFO:tensorflow:loss = 1430.9529, step = 301 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.357\n",
            "INFO:tensorflow:loss = 1491.2056, step = 401 (0.187 sec)\n",
            "INFO:tensorflow:global_step/sec: 621.416\n",
            "INFO:tensorflow:loss = 1508.4451, step = 501 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.608\n",
            "INFO:tensorflow:loss = 1264.5486, step = 601 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 594.916\n",
            "INFO:tensorflow:loss = 1335.3289, step = 701 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.447\n",
            "INFO:tensorflow:loss = 1216.9562, step = 801 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.983\n",
            "INFO:tensorflow:loss = 1383.1628, step = 901 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.579\n",
            "INFO:tensorflow:loss = 1759.962, step = 1001 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 606.479\n",
            "INFO:tensorflow:loss = 1264.1436, step = 1101 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.091\n",
            "INFO:tensorflow:loss = 1352.4977, step = 1201 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 594.869\n",
            "INFO:tensorflow:loss = 1018.3789, step = 1301 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 584.383\n",
            "INFO:tensorflow:loss = 1401.9882, step = 1401 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.608\n",
            "INFO:tensorflow:loss = 1179.4719, step = 1501 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 600.963\n",
            "INFO:tensorflow:loss = 1321.0502, step = 1601 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 611.231\n",
            "INFO:tensorflow:loss = 1130.9779, step = 1701 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.333\n",
            "INFO:tensorflow:loss = 1381.4387, step = 1801 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.008\n",
            "INFO:tensorflow:loss = 1138.213, step = 1901 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.51\n",
            "INFO:tensorflow:loss = 1284.0045, step = 2001 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.343\n",
            "INFO:tensorflow:loss = 1466.6796, step = 2101 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.812\n",
            "INFO:tensorflow:loss = 1043.3492, step = 2201 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 600.771\n",
            "INFO:tensorflow:loss = 1416.2356, step = 2301 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 578.368\n",
            "INFO:tensorflow:loss = 1640.9287, step = 2401 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.576\n",
            "INFO:tensorflow:loss = 1117.1943, step = 2501 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.025\n",
            "INFO:tensorflow:loss = 1202.8213, step = 2601 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.976\n",
            "INFO:tensorflow:loss = 1349.3958, step = 2701 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.737\n",
            "INFO:tensorflow:loss = 1365.2787, step = 2801 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 596.712\n",
            "INFO:tensorflow:loss = 1315.6759, step = 2901 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.564\n",
            "INFO:tensorflow:loss = 1047.4851, step = 3001 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 631.865\n",
            "INFO:tensorflow:loss = 1349.2091, step = 3101 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 654.051\n",
            "INFO:tensorflow:loss = 1134.5919, step = 3201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 680.149\n",
            "INFO:tensorflow:loss = 1318.8281, step = 3301 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.995\n",
            "INFO:tensorflow:loss = 1335.7266, step = 3401 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.756\n",
            "INFO:tensorflow:loss = 895.8402, step = 3501 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.135\n",
            "INFO:tensorflow:loss = 1107.4666, step = 3601 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.026\n",
            "INFO:tensorflow:loss = 1097.8016, step = 3701 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.692\n",
            "INFO:tensorflow:loss = 964.63226, step = 3801 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 594.613\n",
            "INFO:tensorflow:loss = 1314.5275, step = 3901 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.203\n",
            "INFO:tensorflow:loss = 1282.6553, step = 4001 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 679.835\n",
            "INFO:tensorflow:loss = 1188.685, step = 4101 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.358\n",
            "INFO:tensorflow:loss = 1079.343, step = 4201 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.457\n",
            "INFO:tensorflow:loss = 1435.2678, step = 4301 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.56\n",
            "INFO:tensorflow:loss = 1062.2759, step = 4401 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.869\n",
            "INFO:tensorflow:loss = 867.04895, step = 4501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.707\n",
            "INFO:tensorflow:loss = 1076.5176, step = 4601 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.893\n",
            "INFO:tensorflow:loss = 1221.2029, step = 4701 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.26\n",
            "INFO:tensorflow:loss = 1528.6718, step = 4801 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.715\n",
            "INFO:tensorflow:loss = 1822.446, step = 4901 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.489\n",
            "INFO:tensorflow:loss = 1181.7192, step = 5001 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.81\n",
            "INFO:tensorflow:loss = 1312.5254, step = 5101 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.885\n",
            "INFO:tensorflow:loss = 1221.0376, step = 5201 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.329\n",
            "INFO:tensorflow:loss = 1343.4198, step = 5301 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.049\n",
            "INFO:tensorflow:loss = 1401.087, step = 5401 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 591.037\n",
            "INFO:tensorflow:loss = 1135.405, step = 5501 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 605.508\n",
            "INFO:tensorflow:loss = 1080.0535, step = 5601 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.791\n",
            "INFO:tensorflow:loss = 1184.8624, step = 5701 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.714\n",
            "INFO:tensorflow:loss = 976.15155, step = 5801 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.804\n",
            "INFO:tensorflow:loss = 1092.3926, step = 5901 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.99\n",
            "INFO:tensorflow:loss = 1132.1167, step = 6001 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.832\n",
            "INFO:tensorflow:loss = 1248.4194, step = 6101 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.372\n",
            "INFO:tensorflow:loss = 1213.066, step = 6201 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 594.708\n",
            "INFO:tensorflow:loss = 1530.0889, step = 6301 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.87\n",
            "INFO:tensorflow:loss = 1179.2017, step = 6401 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.134\n",
            "INFO:tensorflow:loss = 1112.4082, step = 6501 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 587.493\n",
            "INFO:tensorflow:loss = 1060.9353, step = 6601 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 571.58\n",
            "INFO:tensorflow:loss = 894.9892, step = 6701 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.25\n",
            "INFO:tensorflow:loss = 1012.82947, step = 6801 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 652.928\n",
            "INFO:tensorflow:loss = 1172.0323, step = 6901 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.35\n",
            "INFO:tensorflow:loss = 1195.0955, step = 7001 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.845\n",
            "INFO:tensorflow:loss = 1325.9915, step = 7101 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.218\n",
            "INFO:tensorflow:loss = 1021.18787, step = 7201 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 583.806\n",
            "INFO:tensorflow:loss = 1222.3718, step = 7301 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.897\n",
            "INFO:tensorflow:loss = 1120.1492, step = 7401 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 578.074\n",
            "INFO:tensorflow:loss = 986.6354, step = 7501 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 599.63\n",
            "INFO:tensorflow:loss = 1343.2413, step = 7601 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.186\n",
            "INFO:tensorflow:loss = 2044.2024, step = 7701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.508\n",
            "INFO:tensorflow:loss = 1031.3354, step = 7801 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 597.933\n",
            "INFO:tensorflow:loss = 1192.2024, step = 7901 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 582.552\n",
            "INFO:tensorflow:loss = 1185.1558, step = 8001 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.45\n",
            "INFO:tensorflow:loss = 1228.4816, step = 8101 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.24\n",
            "INFO:tensorflow:loss = 1154.7106, step = 8201 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.832\n",
            "INFO:tensorflow:loss = 1230.908, step = 8301 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 593.683\n",
            "INFO:tensorflow:loss = 1367.72, step = 8401 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 558.234\n",
            "INFO:tensorflow:loss = 1250.8007, step = 8501 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.049\n",
            "INFO:tensorflow:loss = 1096.5693, step = 8601 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 615.531\n",
            "INFO:tensorflow:loss = 1297.3811, step = 8701 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 608.324\n",
            "INFO:tensorflow:loss = 1070.7257, step = 8801 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.172\n",
            "INFO:tensorflow:loss = 1101.092, step = 8901 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.84\n",
            "INFO:tensorflow:loss = 1581.9324, step = 9001 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.915\n",
            "INFO:tensorflow:loss = 1007.074, step = 9101 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 587.28\n",
            "INFO:tensorflow:loss = 1126.5004, step = 9201 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.161\n",
            "INFO:tensorflow:loss = 1083.7227, step = 9301 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.911\n",
            "INFO:tensorflow:loss = 1275.128, step = 9401 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.816\n",
            "INFO:tensorflow:loss = 1083.9866, step = 9501 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 657.45\n",
            "INFO:tensorflow:loss = 1366.7517, step = 9601 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 661.288\n",
            "INFO:tensorflow:loss = 1239.8555, step = 9701 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 620.799\n",
            "INFO:tensorflow:loss = 1352.5104, step = 9801 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 569.56\n",
            "INFO:tensorflow:loss = 1151.8914, step = 9901 (0.175 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1161.9432.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "DNNRegression has RMSE of 62.666568086468935\n",
            "Just using average = 105.94347986701145 has RMSE of 38.87763177825813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ52I5cuQOQV"
      },
      "source": [
        "### Testing the model\n",
        "\n",
        "As a test for the model, a date is selected from the data and the values plugged in.  For this test, the 05/05/2017 in MANHATTAN has been selected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agdZ-ef2Qa_b",
        "outputId": "99f2f975-8f6b-4131-b4e4-71ff3bc4f5c9"
      },
      "source": [
        "# As a test, use something which is known - this case the values for MANHATTAN on the 05/05/2016\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "        'Fri': [0],\n",
        "        'Mon': [0],\n",
        "        'Sat': [0],\n",
        "        'Sun': [0],\n",
        "        'Thu': [0],\n",
        "        'Tue': [0],\t\n",
        "        'Wed': [1],\t\n",
        "        'YEAR': [2016],\n",
        "        'Apr': [0],\t\n",
        "        'Aug': [0],\t\n",
        "        'Dec': [0],\t\n",
        "        'Feb': [0],\t\n",
        "        'Jan': [0],\t\n",
        "        'Jul': [0],\t\n",
        "        'Jun': [0],\t\n",
        "        'Mar': [0],\t\n",
        "        'May': [1],\t\n",
        "        'Nov': [0],\t\n",
        "        'Oct': [0],\t\n",
        "        'Sep': [0],\t\n",
        "        'DAY': [4],\n",
        "        'TEMP': [45.5],\n",
        "        'DEWP': [43.9],\t\n",
        "        'SLP': [1003.7],\t\n",
        "        'VISIB': [5.9],\n",
        "        'WDSP': [21.5],\t\n",
        "        'MXPSD': [26],\n",
        "        'GUST': [35],\t\n",
        "        'MAX': [50],\n",
        "        'MIN': [45],\t\n",
        "        'PRCP': [0.52],\n",
        "        'SNDP': [999.9],\n",
        "        'FOG': [0]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir=model_dir, hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n",
        "print(predslistnorm)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f302f6e1250>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[129.1172]\n",
            "[129.1172]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_da79fqQe5f"
      },
      "source": [
        "This returns **[128.98424]** (the value may change on subsequent runs) - and this value is a _little_ higher than the recorded value of **128**\n",
        "\n",
        "That is quite a good result from a first run!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "081Vz4aoQvMb"
      },
      "source": [
        "### Testing an unknown date.\n",
        "\n",
        "When the data was constructed the year 2021 was removed (due to covid) however, the weather data for 2021 is still available.  Selecting a more recent date (in this case 21-11-2021) and using the weather data from then will give a different result.\n",
        "\n",
        "date      |year|mo|da|temp|dewp|slp   |visib|wdsp|mxpsd|gust |max |min|prcp|sndp |fog\n",
        "----------|----|--|--|----|----|------|-----|----|-----|-----|----|---|----|-----|---\n",
        "2021-11-21|2021|11|21|52.3|42.2|1028.0|10.0 |11.3|14   |999.9|57.9|39.0|0.0|999.9|1\n",
        "\n",
        "This will result in an ```input``` which looks like this:\n",
        "\n",
        "```python\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'Fri': [0],\n",
        "         'Mon': [0],\n",
        "         'Sat': [1],\n",
        "         'Sun': [0],\n",
        "         'Thu': [0],\n",
        "         'Tue': [0],\t\n",
        "         'Wed': [0],\t\n",
        "         'YEAR': [2021],\n",
        "         'Apr': [0],\t\n",
        "         'Aug': [0],\t\n",
        "         'Dec': [0],\t\n",
        "         'Feb': [0],\t\n",
        "         'Jan': [0],\t\n",
        "         'Jul': [0],\t\n",
        "         'Jun': [0],\t\n",
        "         'Mar': [0],\t\n",
        "         'May': [1],\t\n",
        "         'Nov': [0],\t\n",
        "         'Oct': [0],\t\n",
        "         'Sep': [0],\t\n",
        "         'DAY': [4],       \n",
        "         'TEMP' : [52.3],\n",
        "         'DEWP' : [42.2],\n",
        "         'SLP' : [1028.0],\n",
        "         'VISIB' : [10.0],\n",
        "         'WDSP' : [11.3],\n",
        "         'MXPSD' : [14],\n",
        "         'GUST' : [999.9],\n",
        "         'MAX' : [57.9],\n",
        "         'MIN' : [39],\n",
        "         'PRCP' : [0.0],\n",
        "         'SNDP' : [999.9],\n",
        "         'FOG' : [1]\n",
        "        })\n",
        "```\n",
        "\n",
        "creating a new code block which incorporates all the above code items (for brevity) is below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inshwx5eU_Ut",
        "outputId": "ca305ace-8317-4ddb-a614-6e2ebe0a2848"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhattan = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "\n",
        "# setup predictors\n",
        "# Removing the data fields as the DNN should be able to extract this.  Also exluding the borough field as only dealing with Manhattan\n",
        "predictors_manhattan = shuffle_manhattan.iloc[:,[3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28,29,30,31,32,33,34,35,36]]\n",
        "\n",
        "# Check -1 (for all columns) has worked\n",
        "print(predictors_manhattan[:6])\n",
        "\n",
        "# print first 5 rows of the shuffle\n",
        "print(shuffle_manhattan[:5])\n",
        "\n",
        "# Define the target (the NUM_COLS)\n",
        "target_manhatan = shuffle_manhattan.iloc[:,-1]\n",
        "\n",
        "# print the targets\n",
        "print(target_manhatan[:6])\n",
        "\n",
        "# Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "training_size_manhattan = int(len(shuffle_manhattan['NUM_COLS'] ) *0.8)\n",
        "\n",
        "# The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "testing_size_manhattan = len(shuffle_manhattan['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# Define the number of input values (predictors) - won't be 27, it will not include the borough or date - but should it include the borough?\n",
        "no_predictors = 33\n",
        "\n",
        "# Define the number of output values (targets)\n",
        "no_outputs = 1\n",
        "\n",
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "model_dir = '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model'\n",
        "\n",
        "# remove the last training model - if it is present\n",
        "if os.path.isdir(model_dir):\n",
        "  print(\"\\n// Removing old model directory ....\")\n",
        "  shutil.rmtree(model_dir, ignore_errors=True)\n",
        "else:\n",
        "  print(\"\\n// No model directory to remove ....\")\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(\n",
        "    model_dir=model_dir, \n",
        "    hidden_units=[20,18,14], \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhattan.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Prints a log to show model is starting to train\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator.fit(predictors_manhattan[:training_size_manhattan].values, \n",
        "              target_manhatan[:training_size_manhattan].values.reshape(training_size_manhattan, no_outputs) / SCALE_NUM_COLS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_manhattan[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((target_manhatan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the Life Satisfaction Values.\n",
        "avg = np.mean(shuffle_manhattan['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using Life Satisfaction Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhattan['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n",
        "\n",
        "# As a test, use something which is known - this case the values for MANHATTAN on the 05/05/2017\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "        {\n",
        "         'Fri': [0],\n",
        "         'Mon': [0],\n",
        "         'Sat': [1],\n",
        "         'Sun': [0],\n",
        "         'Thu': [0],\n",
        "         'Tue': [0],\t\n",
        "         'Wed': [0],\t\n",
        "         'YEAR': [2021],\n",
        "         'Apr': [0],\t\n",
        "         'Aug': [0],\t\n",
        "         'Dec': [0],\t\n",
        "         'Feb': [0],\t\n",
        "         'Jan': [0],\t\n",
        "         'Jul': [0],\t\n",
        "         'Jun': [0],\t\n",
        "         'Mar': [0],\t\n",
        "         'May': [1],\t\n",
        "         'Nov': [0],\t\n",
        "         'Oct': [0],\t\n",
        "         'Sep': [0],\t\n",
        "         'DAY': [4],       \n",
        "         'TEMP' : [52.3],\n",
        "         'DEWP' : [42.2],\n",
        "         'SLP' : [1028.0],\n",
        "         'VISIB' : [10.0],\n",
        "         'WDSP' : [11.3],\n",
        "         'MXPSD' : [14],\n",
        "         'GUST' : [999.9],\n",
        "         'MAX' : [57.9],\n",
        "         'MIN' : [39],\n",
        "         'PRCP' : [0.0],\n",
        "         'SNDP' : [999.9],\n",
        "         'FOG' : [1]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir=model_dir, hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n",
        "print(predslistnorm)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Fri  Mon  Sat  Sun  Thu  ...   MAX   MIN  PRCP  all_data.SNDP  FOG\n",
            "1881     0    0    0    0    1  ...  42.1  26.1  0.00          999.9    0\n",
            "5259     0    0    0    0    0  ...  79.0  62.1  0.00          999.9    0\n",
            "6185     0    0    0    0    0  ...  27.0  17.1  0.00          999.9    0\n",
            "6247     0    0    0    1    0  ...  48.0  39.9  0.00          999.9    0\n",
            "10637    1    0    0    0    0  ...  60.1  39.9  0.13          999.9    1\n",
            "10073    0    0    0    0    0  ...  37.9  33.8  0.86          999.9    0\n",
            "\n",
            "[6 rows x 33 columns]\n",
            "       Unnamed: 0        DATE    BOROUGH  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "1881         1882  29-11-2013  MANHATTAN  ...          0         13        88\n",
            "5259         5260  25-06-2015  MANHATTAN  ...          0         21       151\n",
            "6185         6186  07-01-2015  MANHATTAN  ...          0         12       102\n",
            "6247         6248  19-10-2015  MANHATTAN  ...          0         18       144\n",
            "10637       10638  28-04-2018  MANHATTAN  ...          0         24       127\n",
            "\n",
            "[5 rows x 46 columns]\n",
            "1881      88\n",
            "5259     151\n",
            "6185     102\n",
            "6247     144\n",
            "10637    127\n",
            "10073    121\n",
            "Name: NUM_COLS, dtype: int64\n",
            "1.15.2\n",
            "\n",
            "// Removing old model directory ....\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f302f595310>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 40818.812, step = 1\n",
            "INFO:tensorflow:global_step/sec: 483.342\n",
            "INFO:tensorflow:loss = 1456.7056, step = 101 (0.210 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.01\n",
            "INFO:tensorflow:loss = 1445.0881, step = 201 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.142\n",
            "INFO:tensorflow:loss = 1907.1804, step = 301 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 549.935\n",
            "INFO:tensorflow:loss = 1443.9764, step = 401 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.12\n",
            "INFO:tensorflow:loss = 1250.0614, step = 501 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.004\n",
            "INFO:tensorflow:loss = 1390.5691, step = 601 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 602.587\n",
            "INFO:tensorflow:loss = 1642.2781, step = 701 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.25\n",
            "INFO:tensorflow:loss = 1516.7144, step = 801 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.297\n",
            "INFO:tensorflow:loss = 1247.6016, step = 901 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 582.636\n",
            "INFO:tensorflow:loss = 1202.1448, step = 1001 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.911\n",
            "INFO:tensorflow:loss = 1114.8555, step = 1101 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.213\n",
            "INFO:tensorflow:loss = 1451.3439, step = 1201 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 546.989\n",
            "INFO:tensorflow:loss = 1195.0022, step = 1301 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.686\n",
            "INFO:tensorflow:loss = 1510.7449, step = 1401 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.154\n",
            "INFO:tensorflow:loss = 1256.267, step = 1501 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 586.653\n",
            "INFO:tensorflow:loss = 1206.4431, step = 1601 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 552.093\n",
            "INFO:tensorflow:loss = 1214.4951, step = 1701 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.164\n",
            "INFO:tensorflow:loss = 1361.4644, step = 1801 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 582.279\n",
            "INFO:tensorflow:loss = 1172.1001, step = 1901 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.761\n",
            "INFO:tensorflow:loss = 1476.2515, step = 2001 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 590.238\n",
            "INFO:tensorflow:loss = 1017.6662, step = 2101 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.647\n",
            "INFO:tensorflow:loss = 1278.2108, step = 2201 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.955\n",
            "INFO:tensorflow:loss = 1130.2648, step = 2301 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.436\n",
            "INFO:tensorflow:loss = 1288.1006, step = 2401 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 583.382\n",
            "INFO:tensorflow:loss = 1085.3246, step = 2501 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.885\n",
            "INFO:tensorflow:loss = 1470.4606, step = 2601 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.128\n",
            "INFO:tensorflow:loss = 1119.959, step = 2701 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.102\n",
            "INFO:tensorflow:loss = 1093.9843, step = 2801 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.965\n",
            "INFO:tensorflow:loss = 1100.0859, step = 2901 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.386\n",
            "INFO:tensorflow:loss = 1036.1183, step = 3001 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 619.157\n",
            "INFO:tensorflow:loss = 1370.1234, step = 3101 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 656.909\n",
            "INFO:tensorflow:loss = 1451.8408, step = 3201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 616.678\n",
            "INFO:tensorflow:loss = 1075.6595, step = 3301 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 590.013\n",
            "INFO:tensorflow:loss = 1277.0188, step = 3401 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.587\n",
            "INFO:tensorflow:loss = 1025.4983, step = 3501 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 663.164\n",
            "INFO:tensorflow:loss = 1308.4268, step = 3601 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 669.968\n",
            "INFO:tensorflow:loss = 1086.8376, step = 3701 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.136\n",
            "INFO:tensorflow:loss = 1202.1047, step = 3801 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.465\n",
            "INFO:tensorflow:loss = 1310.6201, step = 3901 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 634.027\n",
            "INFO:tensorflow:loss = 1081.0854, step = 4001 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 662.597\n",
            "INFO:tensorflow:loss = 1034.9043, step = 4101 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.367\n",
            "INFO:tensorflow:loss = 1234.2339, step = 4201 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.146\n",
            "INFO:tensorflow:loss = 1323.5729, step = 4301 (0.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.557\n",
            "INFO:tensorflow:loss = 1210.2953, step = 4401 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 645.31\n",
            "INFO:tensorflow:loss = 1129.9333, step = 4501 (0.157 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4590 vs previous value: 4590. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 611.588\n",
            "INFO:tensorflow:loss = 1118.3445, step = 4601 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 637.834\n",
            "INFO:tensorflow:loss = 1074.8176, step = 4701 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.018\n",
            "INFO:tensorflow:loss = 1253.4045, step = 4801 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.481\n",
            "INFO:tensorflow:loss = 1144.9564, step = 4901 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.712\n",
            "INFO:tensorflow:loss = 1256.9503, step = 5001 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.597\n",
            "INFO:tensorflow:loss = 1266.7396, step = 5101 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 648.935\n",
            "INFO:tensorflow:loss = 1280.5187, step = 5201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 612.317\n",
            "INFO:tensorflow:loss = 1233.5054, step = 5301 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.475\n",
            "INFO:tensorflow:loss = 1252.0691, step = 5401 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 602.402\n",
            "INFO:tensorflow:loss = 1018.8216, step = 5501 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.837\n",
            "INFO:tensorflow:loss = 1030.9309, step = 5601 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 604.387\n",
            "INFO:tensorflow:loss = 1255.8351, step = 5701 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 614.24\n",
            "INFO:tensorflow:loss = 1029.5293, step = 5801 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 588.594\n",
            "INFO:tensorflow:loss = 1346.4722, step = 5901 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.54\n",
            "INFO:tensorflow:loss = 1482.478, step = 6001 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 602.549\n",
            "INFO:tensorflow:loss = 1191.0732, step = 6101 (0.168 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 6152 vs previous value: 6152. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 587.657\n",
            "INFO:tensorflow:loss = 1033.0469, step = 6201 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.041\n",
            "INFO:tensorflow:loss = 1172.1699, step = 6301 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 624.072\n",
            "INFO:tensorflow:loss = 989.6042, step = 6401 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 580.454\n",
            "INFO:tensorflow:loss = 1247.3523, step = 6501 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.84\n",
            "INFO:tensorflow:loss = 1032.3496, step = 6601 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 606.538\n",
            "INFO:tensorflow:loss = 1190.5452, step = 6701 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.609\n",
            "INFO:tensorflow:loss = 1101.6287, step = 6801 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.613\n",
            "INFO:tensorflow:loss = 1054.6748, step = 6901 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.01\n",
            "INFO:tensorflow:loss = 1268.2314, step = 7001 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.382\n",
            "INFO:tensorflow:loss = 1212.3643, step = 7101 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 600.803\n",
            "INFO:tensorflow:loss = 995.5737, step = 7201 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 590.936\n",
            "INFO:tensorflow:loss = 1146.0505, step = 7301 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 610.129\n",
            "INFO:tensorflow:loss = 1039.3171, step = 7401 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 587.781\n",
            "INFO:tensorflow:loss = 1163.6843, step = 7501 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 603.17\n",
            "INFO:tensorflow:loss = 1435.7681, step = 7601 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.353\n",
            "INFO:tensorflow:loss = 908.6356, step = 7701 (0.177 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 7764 vs previous value: 7764. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 602.103\n",
            "INFO:tensorflow:loss = 1353.4778, step = 7801 (0.167 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.538\n",
            "INFO:tensorflow:loss = 1458.9093, step = 7901 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 611.528\n",
            "INFO:tensorflow:loss = 1483.9913, step = 8001 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.491\n",
            "INFO:tensorflow:loss = 1001.00665, step = 8101 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 656.99\n",
            "INFO:tensorflow:loss = 1090.6285, step = 8201 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 667.543\n",
            "INFO:tensorflow:loss = 1331.0476, step = 8301 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 549.476\n",
            "INFO:tensorflow:loss = 1056.06, step = 8401 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 609.7\n",
            "INFO:tensorflow:loss = 1078.0083, step = 8501 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 611.921\n",
            "INFO:tensorflow:loss = 1128.1979, step = 8601 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 656.534\n",
            "INFO:tensorflow:loss = 1201.9219, step = 8701 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.679\n",
            "INFO:tensorflow:loss = 936.3627, step = 8801 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 622.864\n",
            "INFO:tensorflow:loss = 878.1859, step = 8901 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 612.844\n",
            "INFO:tensorflow:loss = 817.0128, step = 9001 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.734\n",
            "INFO:tensorflow:loss = 1130.7048, step = 9101 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 664.834\n",
            "INFO:tensorflow:loss = 1236.8547, step = 9201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 615.247\n",
            "INFO:tensorflow:loss = 1298.5898, step = 9301 (0.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.739\n",
            "INFO:tensorflow:loss = 1212.4222, step = 9401 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 640.352\n",
            "INFO:tensorflow:loss = 1109.8302, step = 9501 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 584.084\n",
            "INFO:tensorflow:loss = 1043.043, step = 9601 (0.168 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.827\n",
            "INFO:tensorflow:loss = 1051.1625, step = 9701 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.167\n",
            "INFO:tensorflow:loss = 1118.6536, step = 9801 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 668.89\n",
            "INFO:tensorflow:loss = 963.88074, step = 9901 (0.152 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1132.573.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "DNNRegression has RMSE of 145.6689693111595\n",
            "Just using average = 106.10380495012929 has RMSE of 39.6383642678382\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3036db4a90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[76.59831]\n",
            "[76.59831]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTPPF1pmXATF"
      },
      "source": [
        "### Prediction\n",
        "\n",
        "This returns [76.59831]  - while there is no way to tell if this is correct or not, and with covid still a large part of daily lives, the NY collisions data has been updated to show that 27 accidents have been recorded in the Manhattan area on the date selected.  This value was found using the followng query:\n",
        "\n",
        "```sql\n",
        "SELECT *  FROM `bigquery-public-data.new_york_mv_collisions.nypd_mv_collisions`\n",
        "where timestamp between '2021-11-20'  and '2021-11-22'\n",
        "ORDER BY timestamp DESC\n",
        "```\n",
        "\n",
        "The result of this was saved (file name \"pred_check_results.csv\" and the location column removed (as this was a comma seperated value it caused issues) as well as the header.  A new python script was created (check_results.py) which used the getBoroghFromLatLong function used when creating the data.  The result was saved to a new file which then had the header inserted and the data filtered.\n",
        "\n",
        "While the result obtained is less than the \"recorded\" result, COVID is still very mich a factor in people's daily lives and the predicticion could be affected by this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMnV5BCbhnJw"
      },
      "source": [
        "# Conclusion"
      ]
    }
  ]
}