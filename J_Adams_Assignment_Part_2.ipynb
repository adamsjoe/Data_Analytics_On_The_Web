{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J_Adams_Assignment_Part_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2YM-cY3XAb1"
      },
      "source": [
        "# Training a linear regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4OkOIjgXImQ"
      },
      "source": [
        "### Background\n",
        "\n",
        "The dataset which was created for part 1 has been constructed so that each borough can be identified.  This means that a linear regressor could be made for each indivual borough.  As the code uses the dataset with the same structure, what works for one, would work for all.  However, in order to simplifiy this notebook, only one borough will be used.  That borough is **Manhatten**.\n",
        "\n",
        "To begin with, the data must first be loaded.  Once loaded, using the query method of the pandas dataframe the rows which are in Mahattan can be extracted.\n",
        "\n",
        "It should be noted, for the linear regressor the non one hot endoded data is used.  For the DNN, the one hot encoded data will be used in place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUkPRKJw1mm6"
      },
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load the data as per normal\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv', index_col=0)\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv')\n",
        "\n",
        "# now setup to query the dataframe for only the borough noted\n",
        "borough_df = df.query('BOROUGH==\"MANHATTAN\"')\n",
        "\n",
        "# ignore this for now\n",
        "# remove 2012\n",
        "remove_2012 = borough_df.query('YEAR!=2012')\n",
        "\n",
        "# remove 2020\n",
        "remove_2020 = remove_2012.query('YEAR!=2020')\n",
        "\n",
        "#remove 2021\n",
        "remove_2021 = remove_2020.query('YEAR!=2021')\n",
        "\n",
        "# make a new dataframe, which by now shall only contain data for Manhattan in the years 2013 to 2019\n",
        "manhat_df = remove_2021\n",
        "\n",
        "year_2013 = manhat_df.query(\"YEAR==2013\")\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYJbRFX5YExF"
      },
      "source": [
        "#### Data Verification\n",
        "\n",
        "Once the data has been loaded, it is a good idea to check this.  Printing only 6 rows shows that all are Manhattan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNzPMAL314nG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a1824e-def2-4e55-b0af-aa79c062a526"
      },
      "source": [
        "# check the data had loaded by printing it\n",
        "print(manhat_df[:6])\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "924  04-02-2013  MANHATTAN        1  ...          0         14        93\n",
            "929  19-01-2013  MANHATTAN        6  ...          0         19       108\n",
            "931  24-01-2013  MANHATTAN        4  ...          0         31       125\n",
            "936  24-05-2013  MANHATTAN        5  ...          0         41       153\n",
            "941  24-04-2013  MANHATTAN        3  ...          1         21       117\n",
            "946  07-03-2013  MANHATTAN        4  ...          0         18       110\n",
            "\n",
            "[6 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSW7NtK4dBAj"
      },
      "source": [
        "## Import numpy and shuffle\n",
        "\n",
        "Create a new shuffled data by using the random permutation function of numpy using the length of the original mahattan data frame.  In this particular data set this is important as the data is time series (or time series derived) and there could be patterns within the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-NlRVds2BEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2928894c-4bb3-4d56-defd-2f0e85e8e662"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhatten = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "print(shuffle_manhatten[:5])\n",
        "\n",
        "# setup constant for use later\n",
        "SCALE_NUM_COLS = 1.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "13528  18-12-2019  MANHATTAN        3  ...          0         23       110\n",
            "7285   17-11-2016  MANHATTAN        4  ...          0         27       167\n",
            "12635  03-11-2019  MANHATTAN        7  ...          0         16        85\n",
            "9703   2017-10-23  MANHATTAN        1  ...          0         34       148\n",
            "11259  30-10-2018  MANHATTAN        2  ...          0         26       115\n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFG25By8dtfc"
      },
      "source": [
        "## Predictors, Training set and Testing set\n",
        "\n",
        "Firstly the predictors are created.  These are created from the shuffled data and only the third, fourth, fifth, seventh and last column is used.  These are, in order, year, month, day, temp and num_cols (number of collisions).  If the data was not being filtered by borough at the start, then the borough would need to be brought in also.\n",
        "\n",
        "The Target is then defined - this is the last column in the shuffled dataset.\n",
        "\n",
        "The training set will be 80% of the full data set (0.8) and the testing data will be the remainder - so in this case, 100 - 80 = 20%\n",
        "\n",
        "Constants are setup for the number of predictors (3 in this case: year, month and day) and the number of outputs (or targets, which is 1 here.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01AcNdrBh3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8eb358c-b600-4136-e773-a090a91b5e6a"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[3,4,5]]\n",
        "print(predictors_manhatten[:6])\n",
        "\n",
        "# We want the last column (the NUM_COLS)\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "print(targets_manhattan[:6])\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month and year = 3 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 3\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       YEAR  MONTH  DAY\n",
            "13528  2019     12   18\n",
            "7285   2016     11   17\n",
            "12635  2019     11    3\n",
            "9703   2017     10   23\n",
            "11259  2018     10   30\n",
            "6591   2016     11   20\n",
            "13528    110\n",
            "7285     167\n",
            "12635     85\n",
            "9703     148\n",
            "11259    115\n",
            "6591     118\n",
            "Name: NUM_COLS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9cyW1wjfAIk"
      },
      "source": [
        "### Verification\n",
        "\n",
        "Just a simple print to ensure the predictor and values are populated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYOnh5yUElQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be61a80-6f5f-4161-f300-34173d977981"
      },
      "source": [
        "print(predictors_manhatten.values)\n",
        "print(predictors_manhatten)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2019   12   18]\n",
            " [2016   11   17]\n",
            " [2019   11    3]\n",
            " ...\n",
            " [2014    3   28]\n",
            " [2013    4    6]\n",
            " [2016    5   17]]\n",
            "       YEAR  MONTH  DAY\n",
            "13528  2019     12   18\n",
            "7285   2016     11   17\n",
            "12635  2019     11    3\n",
            "9703   2017     10   23\n",
            "11259  2018     10   30\n",
            "...     ...    ...  ...\n",
            "4048   2014      7    2\n",
            "9423   2017      8   28\n",
            "4508   2014      3   28\n",
            "2547   2013      4    6\n",
            "7905   2016      5   17\n",
            "\n",
            "[2556 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axySTDY1fKHw"
      },
      "source": [
        "## The Tensorflow bit.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIj_sLztBlsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b35eff-e565-426c-8b1f-89cd6bfcfb48"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model'\n",
        "\n",
        "# remove the last training model - if it is present\n",
        "if os.path.isdir(manhattan_dir):\n",
        "  print(\"\\n// Removing old model directory ....\")\n",
        "  shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "else:\n",
        "  print(\"\\n// No model directory to remove ....\")\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.1), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\\n\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan,NO_TARGETS)/SCALE_NUM_COLS, steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - predslistscale)**2))\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('\\n\\n// Lnear Regression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('\\n\\n// Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "\n",
            "// No model directory to remove ....\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-6-9488ecbb1cd5>:28: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please convert numpy dtypes explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/linear.py:740: regression_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.contrib.estimator.*_head.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f888e4ae710>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:From <ipython-input-6-9488ecbb1cd5>:28: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to the Estimator interface.\n",
            "// Starting to train Manhattan model............\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 15022.711, step = 1\n",
            "INFO:tensorflow:global_step/sec: 1050.74\n",
            "INFO:tensorflow:loss = 665.46655, step = 101 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1129.45\n",
            "INFO:tensorflow:loss = 507.83533, step = 201 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1261.18\n",
            "INFO:tensorflow:loss = 771.7008, step = 301 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1146.72\n",
            "INFO:tensorflow:loss = 541.4203, step = 401 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1169.67\n",
            "INFO:tensorflow:loss = 474.60904, step = 501 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1190.43\n",
            "INFO:tensorflow:loss = 867.1687, step = 601 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1196.26\n",
            "INFO:tensorflow:loss = 728.1577, step = 701 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1243.72\n",
            "INFO:tensorflow:loss = 1104.8853, step = 801 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1158.6\n",
            "INFO:tensorflow:loss = 866.17737, step = 901 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1146.32\n",
            "INFO:tensorflow:loss = 1047.1655, step = 1001 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1238.64\n",
            "INFO:tensorflow:loss = 709.542, step = 1101 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1213.57\n",
            "INFO:tensorflow:loss = 664.0989, step = 1201 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1280.77\n",
            "INFO:tensorflow:loss = 1043.2286, step = 1301 (0.075 sec)\n",
            "INFO:tensorflow:global_step/sec: 1349.8\n",
            "INFO:tensorflow:loss = 779.3754, step = 1401 (0.074 sec)\n",
            "INFO:tensorflow:global_step/sec: 1267.61\n",
            "INFO:tensorflow:loss = 592.5292, step = 1501 (0.082 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1501 vs previous value: 1501. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 1149.03\n",
            "INFO:tensorflow:loss = 653.74976, step = 1601 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1173.6\n",
            "INFO:tensorflow:loss = 758.60693, step = 1701 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1199.7\n",
            "INFO:tensorflow:loss = 987.8132, step = 1801 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.68\n",
            "INFO:tensorflow:loss = 795.1814, step = 1901 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 1213.5\n",
            "INFO:tensorflow:loss = 691.1915, step = 2001 (0.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 1228.44\n",
            "INFO:tensorflow:loss = 710.73047, step = 2101 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1174.54\n",
            "INFO:tensorflow:loss = 773.6097, step = 2201 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1054.04\n",
            "INFO:tensorflow:loss = 911.80396, step = 2301 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1190.24\n",
            "INFO:tensorflow:loss = 669.8007, step = 2401 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1244.04\n",
            "INFO:tensorflow:loss = 677.6438, step = 2501 (0.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 1217.42\n",
            "INFO:tensorflow:loss = 603.4939, step = 2601 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1148.95\n",
            "INFO:tensorflow:loss = 856.39136, step = 2701 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1186.78\n",
            "INFO:tensorflow:loss = 799.4242, step = 2801 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1185.17\n",
            "INFO:tensorflow:loss = 730.9247, step = 2901 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1127.93\n",
            "INFO:tensorflow:loss = 599.2197, step = 3001 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1147.28\n",
            "INFO:tensorflow:loss = 760.8524, step = 3101 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1231.48\n",
            "INFO:tensorflow:loss = 645.33606, step = 3201 (0.078 sec)\n",
            "INFO:tensorflow:global_step/sec: 1254.21\n",
            "INFO:tensorflow:loss = 867.4762, step = 3301 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1091.89\n",
            "INFO:tensorflow:loss = 545.79626, step = 3401 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1270.81\n",
            "INFO:tensorflow:loss = 790.3478, step = 3501 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1175.43\n",
            "INFO:tensorflow:loss = 629.12085, step = 3601 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1187.86\n",
            "INFO:tensorflow:loss = 640.46545, step = 3701 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1175.82\n",
            "INFO:tensorflow:loss = 756.4453, step = 3801 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1167.98\n",
            "INFO:tensorflow:loss = 582.98175, step = 3901 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1213.77\n",
            "INFO:tensorflow:loss = 701.49963, step = 4001 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1173.14\n",
            "INFO:tensorflow:loss = 733.11523, step = 4101 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1138.79\n",
            "INFO:tensorflow:loss = 839.9608, step = 4201 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1128.74\n",
            "INFO:tensorflow:loss = 675.1825, step = 4301 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1086.03\n",
            "INFO:tensorflow:loss = 603.92145, step = 4401 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1104.37\n",
            "INFO:tensorflow:loss = 596.86444, step = 4501 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1164.44\n",
            "INFO:tensorflow:loss = 538.7344, step = 4601 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1120.04\n",
            "INFO:tensorflow:loss = 863.45953, step = 4701 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1133.04\n",
            "INFO:tensorflow:loss = 529.6443, step = 4801 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1203.26\n",
            "INFO:tensorflow:loss = 776.2062, step = 4901 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1276.79\n",
            "INFO:tensorflow:loss = 747.88, step = 5001 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1201.19\n",
            "INFO:tensorflow:loss = 952.02203, step = 5101 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1207.8\n",
            "INFO:tensorflow:loss = 921.91345, step = 5201 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1172.71\n",
            "INFO:tensorflow:loss = 565.47424, step = 5301 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1223.45\n",
            "INFO:tensorflow:loss = 562.8346, step = 5401 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1210.41\n",
            "INFO:tensorflow:loss = 514.5855, step = 5501 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1201.1\n",
            "INFO:tensorflow:loss = 629.2601, step = 5601 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1205.91\n",
            "INFO:tensorflow:loss = 659.7384, step = 5701 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1140.76\n",
            "INFO:tensorflow:loss = 737.6007, step = 5801 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1259.47\n",
            "INFO:tensorflow:loss = 607.40576, step = 5901 (0.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 1277.47\n",
            "INFO:tensorflow:loss = 814.6416, step = 6001 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1236.16\n",
            "INFO:tensorflow:loss = 1192.4695, step = 6101 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1186.08\n",
            "INFO:tensorflow:loss = 969.14435, step = 6201 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1211.79\n",
            "INFO:tensorflow:loss = 751.5635, step = 6301 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1253.52\n",
            "INFO:tensorflow:loss = 633.2514, step = 6401 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1218.09\n",
            "INFO:tensorflow:loss = 607.82874, step = 6501 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1230.61\n",
            "INFO:tensorflow:loss = 779.70074, step = 6601 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1164.76\n",
            "INFO:tensorflow:loss = 801.2663, step = 6701 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1154.22\n",
            "INFO:tensorflow:loss = 680.62524, step = 6801 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1203.87\n",
            "INFO:tensorflow:loss = 795.35583, step = 6901 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1172.46\n",
            "INFO:tensorflow:loss = 1104.6982, step = 7001 (0.086 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 7001 vs previous value: 7001. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 1222.96\n",
            "INFO:tensorflow:loss = 710.4228, step = 7101 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1231.63\n",
            "INFO:tensorflow:loss = 982.12573, step = 7201 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1149.03\n",
            "INFO:tensorflow:loss = 844.886, step = 7301 (0.089 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 7301 vs previous value: 7301. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 1129.24\n",
            "INFO:tensorflow:loss = 879.14294, step = 7401 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1092.04\n",
            "INFO:tensorflow:loss = 764.0973, step = 7501 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1212.89\n",
            "INFO:tensorflow:loss = 678.5241, step = 7601 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1177.49\n",
            "INFO:tensorflow:loss = 719.99036, step = 7701 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1200.19\n",
            "INFO:tensorflow:loss = 690.8271, step = 7801 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1093\n",
            "INFO:tensorflow:loss = 887.29834, step = 7901 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1237.29\n",
            "INFO:tensorflow:loss = 977.03265, step = 8001 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1222.41\n",
            "INFO:tensorflow:loss = 720.9954, step = 8101 (0.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 1138.7\n",
            "INFO:tensorflow:loss = 759.5659, step = 8201 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1094.74\n",
            "INFO:tensorflow:loss = 1294.8022, step = 8301 (0.093 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 8301 vs previous value: 8301. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 1061.97\n",
            "INFO:tensorflow:loss = 775.1624, step = 8401 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1234.93\n",
            "INFO:tensorflow:loss = 775.21, step = 8501 (0.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 1223.69\n",
            "INFO:tensorflow:loss = 619.8347, step = 8601 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1295.42\n",
            "INFO:tensorflow:loss = 832.13513, step = 8701 (0.077 sec)\n",
            "INFO:tensorflow:global_step/sec: 1199.02\n",
            "INFO:tensorflow:loss = 871.3605, step = 8801 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1120.18\n",
            "INFO:tensorflow:loss = 590.692, step = 8901 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1211.8\n",
            "INFO:tensorflow:loss = 488.50922, step = 9001 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1194.82\n",
            "INFO:tensorflow:loss = 890.4999, step = 9101 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1239.83\n",
            "INFO:tensorflow:loss = 777.57214, step = 9201 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1236.54\n",
            "INFO:tensorflow:loss = 688.60144, step = 9301 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1118.59\n",
            "INFO:tensorflow:loss = 782.15204, step = 9401 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1171.23\n",
            "INFO:tensorflow:loss = 561.1024, step = 9501 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1218.89\n",
            "INFO:tensorflow:loss = 645.9881, step = 9601 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1270.66\n",
            "INFO:tensorflow:loss = 678.4695, step = 9701 (0.078 sec)\n",
            "INFO:tensorflow:global_step/sec: 1071.1\n",
            "INFO:tensorflow:loss = 841.19653, step = 9801 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1196.81\n",
            "INFO:tensorflow:loss = 816.5835, step = 9901 (0.086 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 642.047.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "// Lnear Regression has RMSE of 26.856691353851343\n",
            "\n",
            "\n",
            "// Just using average = 120.94080234833659 has RMSE of 25.33555206163677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t23ehycblB5R"
      },
      "source": [
        "## Initial Output\n",
        "\n",
        "The RSME is quite large, which would indicate a not accurate model - however this model is only trying to predict based on a day.  Not using any extra conditions.  Temperature could be added in and this may affect the the output.\n",
        "\n",
        "The model needs to be tested first, to do this some values will be fed in to be the input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pizTrw7Aks8S"
      },
      "source": [
        "## Inital Prediction\n",
        "\n",
        "```python\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "                 'MONTH' : [1, 6, 12],\n",
        "                 'DAY' : [1, 1, 1]\n",
        "                 })\n",
        "```\n",
        "\n",
        "Setting up the values for preduction, 3 have been chosen.  1/1/2013, 1/6/2016 and 1.12/2022 will be fed into model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjS3zTafVMB8",
        "outputId": "d2ab29a6-6758-4528-c221-6bc78cdce43f"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'DAY' : [1, 1, 1]\n",
        "        })\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)\n",
        "                                                                                 )\n",
        ")\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 1.0\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f888b070b90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[102.4882   109.69276  118.458374]\n",
            "[102.4882   109.69276  118.458374]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hnzo1hOFa-l"
      },
      "source": [
        "### Result of First Run\n",
        "\n",
        "The output (at the time of writing) was \n",
        "\n",
        "[117.42061  123.957085 131.939   ]\n",
        "\n",
        "The model is being asked to predict 3 dates.  Two of these dates are known, these can be used as \"control\" dates - the number of collisions is known - so these should be fairly accurate (or at least, that is the theory...)\n",
        "\n",
        "The dates are:\n",
        "\n",
        "Date|Prediction|Actual\n",
        ":--:|:--------:|:----:\n",
        "1/1/2013|102|78\n",
        "1/6/2016|110|121\n",
        "1/12/2020|118|N/A\n",
        "\n",
        "While the trend is, generally, going upwards, which does **sort of** look ok.. As noted above, it would be a good idea to try to add in an additional predictor.  The Temp value should suffice.\n",
        "\n",
        "**Note** these values may change if the notebook is run at a later stage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65w8sb15lZj3"
      },
      "source": [
        "## Adding in Temp\n",
        "\n",
        "The code cells will be copied from above, this time the predictors will be ammeded to include temperature.\n",
        "\n",
        "**Note:** For brevity, the additional prints will not be inluded and all code will be added to the one cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxd35_S4ln2-",
        "outputId": "c8642008-bf8e-470f-b871-6dde3ec1dcd6"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[3,4,5,7]]\n",
        "print(predictors_manhatten[:6])\n",
        "\n",
        "# We want the last column (the NUM_COLS)\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "print(targets_manhattan[:6])\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month, year and now temp = 4 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 4\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model_including_temp'\n",
        "\n",
        "# remove the last training model\n",
        "shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.1), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\\n\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan,NO_TARGETS)/SCALE_NUM_COLS, steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - predslistscale)**2))\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('\\n\\n// Lnear Regression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('\\n\\n// Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       YEAR  MONTH  DAY  TEMP\n",
            "13528  2019     12   18  39.3\n",
            "7285   2016     11   17  48.6\n",
            "12635  2019     11    3  51.0\n",
            "9703   2017     10   23  59.5\n",
            "11259  2018     10   30  47.9\n",
            "6591   2016     11   20  47.0\n",
            "13528    110\n",
            "7285     167\n",
            "12635     85\n",
            "9703     148\n",
            "11259    115\n",
            "6591     118\n",
            "Name: NUM_COLS, dtype: int64\n",
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f888d24d090>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp', '_session_creation_timeout_secs': 7200}\n",
            "// Starting to train Manhattan model............\n",
            "\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_including_temp/model.ckpt.\n",
            "INFO:tensorflow:loss = 15022.711, step = 1\n",
            "INFO:tensorflow:global_step/sec: 1082.09\n",
            "INFO:tensorflow:loss = 653.2813, step = 101 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1176.17\n",
            "INFO:tensorflow:loss = 480.3943, step = 201 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1180.55\n",
            "INFO:tensorflow:loss = 718.75977, step = 301 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1170.69\n",
            "INFO:tensorflow:loss = 548.96625, step = 401 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1077.85\n",
            "INFO:tensorflow:loss = 448.84625, step = 501 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1129.59\n",
            "INFO:tensorflow:loss = 813.4352, step = 601 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1231.45\n",
            "INFO:tensorflow:loss = 672.4744, step = 701 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1214.31\n",
            "INFO:tensorflow:loss = 1014.89685, step = 801 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1181.12\n",
            "INFO:tensorflow:loss = 899.4371, step = 901 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1119.37\n",
            "INFO:tensorflow:loss = 1052.8417, step = 1001 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1215.5\n",
            "INFO:tensorflow:loss = 686.4802, step = 1101 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1242.23\n",
            "INFO:tensorflow:loss = 689.06055, step = 1201 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1121.23\n",
            "INFO:tensorflow:loss = 887.86206, step = 1301 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1022.62\n",
            "INFO:tensorflow:loss = 715.615, step = 1401 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1269.57\n",
            "INFO:tensorflow:loss = 552.73413, step = 1501 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1247.47\n",
            "INFO:tensorflow:loss = 719.02966, step = 1601 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1186.11\n",
            "INFO:tensorflow:loss = 715.39233, step = 1701 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1175.2\n",
            "INFO:tensorflow:loss = 944.6005, step = 1801 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1172.7\n",
            "INFO:tensorflow:loss = 801.94116, step = 1901 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1168.23\n",
            "INFO:tensorflow:loss = 659.7395, step = 2001 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1207.14\n",
            "INFO:tensorflow:loss = 679.7406, step = 2101 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1164.99\n",
            "INFO:tensorflow:loss = 673.7826, step = 2201 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1077.54\n",
            "INFO:tensorflow:loss = 828.279, step = 2301 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1188.71\n",
            "INFO:tensorflow:loss = 578.3101, step = 2401 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1179.5\n",
            "INFO:tensorflow:loss = 755.26, step = 2501 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1031.88\n",
            "INFO:tensorflow:loss = 576.7363, step = 2601 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1148.17\n",
            "INFO:tensorflow:loss = 747.9418, step = 2701 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1199.7\n",
            "INFO:tensorflow:loss = 722.2859, step = 2801 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1175.03\n",
            "INFO:tensorflow:loss = 644.7473, step = 2901 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1131.55\n",
            "INFO:tensorflow:loss = 662.301, step = 3001 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1217.44\n",
            "INFO:tensorflow:loss = 664.3722, step = 3101 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1212.11\n",
            "INFO:tensorflow:loss = 603.64246, step = 3201 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1003.17\n",
            "INFO:tensorflow:loss = 852.5517, step = 3301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1045.71\n",
            "INFO:tensorflow:loss = 511.64178, step = 3401 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1124.93\n",
            "INFO:tensorflow:loss = 816.0371, step = 3501 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1246.62\n",
            "INFO:tensorflow:loss = 651.552, step = 3601 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1091.8\n",
            "INFO:tensorflow:loss = 663.0242, step = 3701 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1206.5\n",
            "INFO:tensorflow:loss = 733.49725, step = 3801 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1127.26\n",
            "INFO:tensorflow:loss = 577.0183, step = 3901 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1176.29\n",
            "INFO:tensorflow:loss = 641.5457, step = 4001 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1204.36\n",
            "INFO:tensorflow:loss = 717.33655, step = 4101 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1271.8\n",
            "INFO:tensorflow:loss = 806.12463, step = 4201 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1182.43\n",
            "INFO:tensorflow:loss = 678.3422, step = 4301 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1152.88\n",
            "INFO:tensorflow:loss = 625.84644, step = 4401 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1190.61\n",
            "INFO:tensorflow:loss = 544.2765, step = 4501 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1163.08\n",
            "INFO:tensorflow:loss = 542.1857, step = 4601 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1067.3\n",
            "INFO:tensorflow:loss = 902.86835, step = 4701 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1185.04\n",
            "INFO:tensorflow:loss = 553.95966, step = 4801 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1129.83\n",
            "INFO:tensorflow:loss = 718.2076, step = 4901 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1131.92\n",
            "INFO:tensorflow:loss = 701.1362, step = 5001 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1169.13\n",
            "INFO:tensorflow:loss = 836.14075, step = 5101 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1191.26\n",
            "INFO:tensorflow:loss = 937.79736, step = 5201 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1191.25\n",
            "INFO:tensorflow:loss = 527.9852, step = 5301 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1183.82\n",
            "INFO:tensorflow:loss = 572.3088, step = 5401 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1233.23\n",
            "INFO:tensorflow:loss = 493.83453, step = 5501 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1198.94\n",
            "INFO:tensorflow:loss = 614.13745, step = 5601 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1139.07\n",
            "INFO:tensorflow:loss = 663.65515, step = 5701 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1176.07\n",
            "INFO:tensorflow:loss = 759.5263, step = 5801 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1204.8\n",
            "INFO:tensorflow:loss = 598.567, step = 5901 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1191.84\n",
            "INFO:tensorflow:loss = 926.77545, step = 6001 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1086.24\n",
            "INFO:tensorflow:loss = 1199.6654, step = 6101 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1223.5\n",
            "INFO:tensorflow:loss = 919.999, step = 6201 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1228.15\n",
            "INFO:tensorflow:loss = 886.5445, step = 6301 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1115.3\n",
            "INFO:tensorflow:loss = 666.4206, step = 6401 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1232.92\n",
            "INFO:tensorflow:loss = 590.26526, step = 6501 (0.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 1172.92\n",
            "INFO:tensorflow:loss = 863.95374, step = 6601 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1150.56\n",
            "INFO:tensorflow:loss = 692.5199, step = 6701 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1176.51\n",
            "INFO:tensorflow:loss = 573.6223, step = 6801 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1185.78\n",
            "INFO:tensorflow:loss = 780.18494, step = 6901 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1083.49\n",
            "INFO:tensorflow:loss = 895.7343, step = 7001 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1100.21\n",
            "INFO:tensorflow:loss = 699.6648, step = 7101 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1167.41\n",
            "INFO:tensorflow:loss = 890.3925, step = 7201 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1084.83\n",
            "INFO:tensorflow:loss = 864.8773, step = 7301 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1080.95\n",
            "INFO:tensorflow:loss = 1288.3423, step = 7401 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1180.18\n",
            "INFO:tensorflow:loss = 645.1071, step = 7501 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1144.19\n",
            "INFO:tensorflow:loss = 738.58356, step = 7601 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1244.43\n",
            "INFO:tensorflow:loss = 679.11914, step = 7701 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1066.68\n",
            "INFO:tensorflow:loss = 710.4444, step = 7801 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1087.76\n",
            "INFO:tensorflow:loss = 629.04846, step = 7901 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1105.49\n",
            "INFO:tensorflow:loss = 885.62305, step = 8001 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1158.02\n",
            "INFO:tensorflow:loss = 786.55365, step = 8101 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1196.3\n",
            "INFO:tensorflow:loss = 724.9584, step = 8201 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1246.65\n",
            "INFO:tensorflow:loss = 949.73364, step = 8301 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1055.37\n",
            "INFO:tensorflow:loss = 811.5497, step = 8401 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1227.14\n",
            "INFO:tensorflow:loss = 705.1719, step = 8501 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1173.49\n",
            "INFO:tensorflow:loss = 627.7707, step = 8601 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1229.44\n",
            "INFO:tensorflow:loss = 788.6242, step = 8701 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1079.22\n",
            "INFO:tensorflow:loss = 703.37164, step = 8801 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1253.34\n",
            "INFO:tensorflow:loss = 590.3462, step = 8901 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1191.2\n",
            "INFO:tensorflow:loss = 485.45834, step = 9001 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1109.6\n",
            "INFO:tensorflow:loss = 662.2342, step = 9101 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1161.91\n",
            "INFO:tensorflow:loss = 1002.1038, step = 9201 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1180.57\n",
            "INFO:tensorflow:loss = 665.5652, step = 9301 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1229.11\n",
            "INFO:tensorflow:loss = 825.7742, step = 9401 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1061.03\n",
            "INFO:tensorflow:loss = 516.8203, step = 9501 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1147.93\n",
            "INFO:tensorflow:loss = 575.51514, step = 9601 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1230.5\n",
            "INFO:tensorflow:loss = 719.51306, step = 9701 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1130.21\n",
            "INFO:tensorflow:loss = 757.4479, step = 9801 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1133.67\n",
            "INFO:tensorflow:loss = 754.9672, step = 9901 (0.088 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_including_temp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 636.13306.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "// Lnear Regression has RMSE of 25.67782985476902\n",
            "\n",
            "\n",
            "// Just using average = 120.94080234833659 has RMSE of 25.33555206163677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMnfjCXRmT_D",
        "outputId": "cb8f2ecc-b338-4864-822a-de8cfacaea44"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'DAY' : [1, 1, 1],\n",
        "         'TEMP': [35,60,30]\n",
        "        })\n",
        "\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)\n",
        "                                                                                 )\n",
        ")\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "# print(preds)\n",
        "\n",
        "# The Number of collisions scale will be 106.072969 - which is the average number of collisions in Manhattan (359057 (collisions)/ 3385 (days))\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 106.072969\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f888ae5a6d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp', '_session_creation_timeout_secs': 7200}\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[101.84443 114.89365 110.08072]\n",
            "[10802.94  12187.11  11676.589]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M1tZRi3mxmo"
      },
      "source": [
        "### After Temp\n",
        "\n",
        "After adding in the temp, the values have changed:\n",
        "\n",
        "\n",
        "Date|Prediction (no temp)|Prediction (with temp)|Actual\n",
        ":--:|:------------------:|:--------------------:|:----:\n",
        "1/1/2013|102|102|78|\n",
        "1/6/2016|110|115|121|\n",
        "1/12/2020|118|110|N/A|\n",
        "\n",
        "So while the values are pulling closer (on this current run) they are not **exact**\n",
        "\n",
        "Looking at the data from part 1 of the assignment, year, month and day do not affect the outputs, at least not directly.  Temperature and Weekday do.  So, the model could be changed to use these as predictors. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtiQ7GRssxjM"
      },
      "source": [
        "## Using Temperature and Weekday \n",
        "\n",
        "Taking the code from above, it will be modified to use these two parameters as predictors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yIdAco-s8Dn",
        "outputId": "82efe9a1-ead5-4ecc-8ed7-b088c726409e"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[2,7]]\n",
        "print(\"// Printing predictors ...\")\n",
        "print(predictors_manhatten[:6])\n",
        "\n",
        "# We want the last column (the NUM_COLS)\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "print(\"// Printing targets .....\")\n",
        "print(targets_manhattan[:6])\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month, year and now temp = 4 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 2\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model_including_temp_and_weekday'\n",
        "\n",
        "# remove the last training model\n",
        "shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.1), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\\n\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan,NO_TARGETS)/SCALE_NUM_COLS, steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - predslistscale)**2))\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('\\n\\n// Lnear Regression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('\\n\\n// Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// Printing predictors ...\n",
            "       WEEKDAY  TEMP\n",
            "13528        3  39.3\n",
            "7285         4  48.6\n",
            "12635        7  51.0\n",
            "9703         1  59.5\n",
            "11259        2  47.9\n",
            "6591         7  47.0\n",
            "// Printing targets .....\n",
            "13528    110\n",
            "7285     167\n",
            "12635     85\n",
            "9703     148\n",
            "11259    115\n",
            "6591     118\n",
            "Name: NUM_COLS, dtype: int64\n",
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f888b083bd0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp_and_weekday', '_session_creation_timeout_secs': 7200}\n",
            "// Starting to train Manhattan model............\n",
            "\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt.\n",
            "INFO:tensorflow:loss = 15022.711, step = 1\n",
            "INFO:tensorflow:global_step/sec: 1035.56\n",
            "INFO:tensorflow:loss = 1354.1578, step = 101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1164.62\n",
            "INFO:tensorflow:loss = 1046.0447, step = 201 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1167.48\n",
            "INFO:tensorflow:loss = 1058.7025, step = 301 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1225.1\n",
            "INFO:tensorflow:loss = 1095.7776, step = 401 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1194.24\n",
            "INFO:tensorflow:loss = 924.0018, step = 501 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1207.87\n",
            "INFO:tensorflow:loss = 1070.0171, step = 601 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1101.36\n",
            "INFO:tensorflow:loss = 957.4231, step = 701 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1252.24\n",
            "INFO:tensorflow:loss = 966.4741, step = 801 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1225.01\n",
            "INFO:tensorflow:loss = 726.4725, step = 901 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1163.62\n",
            "INFO:tensorflow:loss = 1237.2623, step = 1001 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1145.47\n",
            "INFO:tensorflow:loss = 890.23535, step = 1101 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1252.56\n",
            "INFO:tensorflow:loss = 1098.764, step = 1201 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1183.43\n",
            "INFO:tensorflow:loss = 841.94275, step = 1301 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1113.12\n",
            "INFO:tensorflow:loss = 760.1046, step = 1401 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1203.19\n",
            "INFO:tensorflow:loss = 719.7801, step = 1501 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1112.85\n",
            "INFO:tensorflow:loss = 617.12213, step = 1601 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1189.27\n",
            "INFO:tensorflow:loss = 793.54865, step = 1701 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1131.71\n",
            "INFO:tensorflow:loss = 869.95154, step = 1801 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1020.35\n",
            "INFO:tensorflow:loss = 933.53467, step = 1901 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1082.49\n",
            "INFO:tensorflow:loss = 711.6516, step = 2001 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1178.17\n",
            "INFO:tensorflow:loss = 716.34955, step = 2101 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1271.86\n",
            "INFO:tensorflow:loss = 584.4814, step = 2201 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1250.74\n",
            "INFO:tensorflow:loss = 786.9229, step = 2301 (0.078 sec)\n",
            "INFO:tensorflow:global_step/sec: 1233.24\n",
            "INFO:tensorflow:loss = 614.8067, step = 2401 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1189.63\n",
            "INFO:tensorflow:loss = 699.0513, step = 2501 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1153.84\n",
            "INFO:tensorflow:loss = 587.3982, step = 2601 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1232.55\n",
            "INFO:tensorflow:loss = 734.4459, step = 2701 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1171.43\n",
            "INFO:tensorflow:loss = 690.04956, step = 2801 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1257.74\n",
            "INFO:tensorflow:loss = 569.79834, step = 2901 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1178.96\n",
            "INFO:tensorflow:loss = 597.70593, step = 3001 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1150.6\n",
            "INFO:tensorflow:loss = 593.60236, step = 3101 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1213.53\n",
            "INFO:tensorflow:loss = 515.90967, step = 3201 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1268.4\n",
            "INFO:tensorflow:loss = 865.7058, step = 3301 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1211.76\n",
            "INFO:tensorflow:loss = 482.81406, step = 3401 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1199.43\n",
            "INFO:tensorflow:loss = 803.766, step = 3501 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1190.71\n",
            "INFO:tensorflow:loss = 531.781, step = 3601 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1196.26\n",
            "INFO:tensorflow:loss = 664.8806, step = 3701 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1163.93\n",
            "INFO:tensorflow:loss = 693.49097, step = 3801 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1235\n",
            "INFO:tensorflow:loss = 531.76733, step = 3901 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1275.03\n",
            "INFO:tensorflow:loss = 595.821, step = 4001 (0.078 sec)\n",
            "INFO:tensorflow:global_step/sec: 1223.97\n",
            "INFO:tensorflow:loss = 643.6393, step = 4101 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1223.21\n",
            "INFO:tensorflow:loss = 592.81476, step = 4201 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1109.85\n",
            "INFO:tensorflow:loss = 680.1558, step = 4301 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1212.28\n",
            "INFO:tensorflow:loss = 574.6697, step = 4401 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1254.1\n",
            "INFO:tensorflow:loss = 515.5348, step = 4501 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1192.17\n",
            "INFO:tensorflow:loss = 528.28, step = 4601 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1187.33\n",
            "INFO:tensorflow:loss = 446.54028, step = 4701 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1030.51\n",
            "INFO:tensorflow:loss = 544.11096, step = 4801 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1202.25\n",
            "INFO:tensorflow:loss = 547.5762, step = 4901 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1095.1\n",
            "INFO:tensorflow:loss = 656.0472, step = 5001 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1219.56\n",
            "INFO:tensorflow:loss = 540.9462, step = 5101 (0.080 sec)\n",
            "INFO:tensorflow:global_step/sec: 1226.89\n",
            "INFO:tensorflow:loss = 624.56384, step = 5201 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1129.81\n",
            "INFO:tensorflow:loss = 487.27728, step = 5301 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1265.88\n",
            "INFO:tensorflow:loss = 567.266, step = 5401 (0.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 1189.7\n",
            "INFO:tensorflow:loss = 501.81775, step = 5501 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1149.26\n",
            "INFO:tensorflow:loss = 603.94763, step = 5601 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1154.72\n",
            "INFO:tensorflow:loss = 718.3247, step = 5701 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1236.54\n",
            "INFO:tensorflow:loss = 519.933, step = 5801 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1229.44\n",
            "INFO:tensorflow:loss = 605.354, step = 5901 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1150.48\n",
            "INFO:tensorflow:loss = 638.97363, step = 6001 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1243.87\n",
            "INFO:tensorflow:loss = 696.5032, step = 6101 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1104.4\n",
            "INFO:tensorflow:loss = 578.07544, step = 6201 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1247.65\n",
            "INFO:tensorflow:loss = 608.9754, step = 6301 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1127.8\n",
            "INFO:tensorflow:loss = 603.7903, step = 6401 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1166.38\n",
            "INFO:tensorflow:loss = 593.9702, step = 6501 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1221.52\n",
            "INFO:tensorflow:loss = 548.6456, step = 6601 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1182.67\n",
            "INFO:tensorflow:loss = 665.97327, step = 6701 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1237.14\n",
            "INFO:tensorflow:loss = 572.64734, step = 6801 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1240.73\n",
            "INFO:tensorflow:loss = 730.4781, step = 6901 (0.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 1224.05\n",
            "INFO:tensorflow:loss = 739.26526, step = 7001 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1094.08\n",
            "INFO:tensorflow:loss = 735.11255, step = 7101 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1190.32\n",
            "INFO:tensorflow:loss = 831.8572, step = 7201 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1221.72\n",
            "INFO:tensorflow:loss = 697.5901, step = 7301 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1109.1\n",
            "INFO:tensorflow:loss = 515.54095, step = 7401 (0.091 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 7401 vs previous value: 7401. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 1196.35\n",
            "INFO:tensorflow:loss = 579.1168, step = 7501 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1258.38\n",
            "INFO:tensorflow:loss = 540.4749, step = 7601 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1260.32\n",
            "INFO:tensorflow:loss = 665.1017, step = 7701 (0.079 sec)\n",
            "INFO:tensorflow:global_step/sec: 1224.42\n",
            "INFO:tensorflow:loss = 628.17456, step = 7801 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1111.63\n",
            "INFO:tensorflow:loss = 654.78503, step = 7901 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1267.65\n",
            "INFO:tensorflow:loss = 599.05945, step = 8001 (0.078 sec)\n",
            "INFO:tensorflow:global_step/sec: 1171.93\n",
            "INFO:tensorflow:loss = 685.5067, step = 8101 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1138.76\n",
            "INFO:tensorflow:loss = 695.3357, step = 8201 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1196.24\n",
            "INFO:tensorflow:loss = 697.8225, step = 8301 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1215.01\n",
            "INFO:tensorflow:loss = 713.9491, step = 8401 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1087.48\n",
            "INFO:tensorflow:loss = 589.8538, step = 8501 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1152.49\n",
            "INFO:tensorflow:loss = 545.86414, step = 8601 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1213.52\n",
            "INFO:tensorflow:loss = 748.9376, step = 8701 (0.081 sec)\n",
            "INFO:tensorflow:global_step/sec: 1250.96\n",
            "INFO:tensorflow:loss = 575.5298, step = 8801 (0.078 sec)\n",
            "INFO:tensorflow:global_step/sec: 1139.47\n",
            "INFO:tensorflow:loss = 561.9448, step = 8901 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1128.49\n",
            "INFO:tensorflow:loss = 484.42737, step = 9001 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1207.88\n",
            "INFO:tensorflow:loss = 646.81396, step = 9101 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1064.4\n",
            "INFO:tensorflow:loss = 611.5641, step = 9201 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1271.78\n",
            "INFO:tensorflow:loss = 614.9111, step = 9301 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1190.2\n",
            "INFO:tensorflow:loss = 785.7261, step = 9401 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1201.87\n",
            "INFO:tensorflow:loss = 441.07285, step = 9501 (0.082 sec)\n",
            "INFO:tensorflow:global_step/sec: 1201.56\n",
            "INFO:tensorflow:loss = 525.7933, step = 9601 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1182.24\n",
            "INFO:tensorflow:loss = 605.8285, step = 9701 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1194.01\n",
            "INFO:tensorflow:loss = 711.27136, step = 9801 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1242.88\n",
            "INFO:tensorflow:loss = 622.2213, step = 9901 (0.084 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 535.48584.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "// Lnear Regression has RMSE of 24.061552401525198\n",
            "\n",
            "\n",
            "// Just using average = 120.94080234833659 has RMSE of 25.33555206163677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI3IEPqTuMcs"
      },
      "source": [
        "This still has quite a large RMSE.  However, running a prediction, again using a day which is known (but picking the weekday and temp values)\n",
        "\n",
        "Using 24-10-2018 in the Mathattan borough, the *WEEKDAY* was **3** and the *TEMP*  was **48.4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8KC5G76uW_5",
        "outputId": "0d12a183-437c-44e8-fb57-4d6c9496c24b"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'WEEKDAY' : [3],\n",
        "         'TEMP' : [48.4]\n",
        "        })\n",
        "\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)\n",
        "                                                                                 )\n",
        ")\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "# print(preds)\n",
        "\n",
        "# The Number of collisions scale will be 106.072969 - which is the average number of collisions in Manhattan (359057 (collisions)/ 3385 (days))\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 1\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f888af1c510>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp_and_weekday', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[120.75173]\n",
            "[120.75173]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5rrtbTyvoPQ"
      },
      "source": [
        "Which returns [120.75173] - the actual value of collisions was **120**  \n",
        "\n",
        "This value is pretty good for a linear model. \n",
        "\n",
        "Next up is to attempt to train and use a DNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVR7uKHFqUKR"
      },
      "source": [
        "# Training a DNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uoa-o_t7N6BP"
      },
      "source": [
        "## Background\n",
        "\n",
        "For the DNN section, the data which was created and used one hot encoding will be used.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qcMkg_eOL_p"
      },
      "source": [
        "# Import pandas to use dataframes\n",
        "import pandas as pd\n",
        "\n",
        "# create data frame from csv file we hosted on our github\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv')\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/dnn_data.csv')\n",
        "\n",
        "# now setup to query the dataframe for only the boroughs noted.\n",
        "# Again worth noting here that by the use of sqldf the values can be extracted as needed without having to extract and store multiple CSV files.\n",
        "manhat_df = df.query('BOROUGH==\"MANHATTAN\"')\n",
        "\n",
        "SCALE_NUM_COLS = 1.0"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV_YzN53OPBA"
      },
      "source": [
        "### Checking data loaded\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyHZeT4GOTab",
        "outputId": "43916898-bd5b-4799-971c-5126e344e67a"
      },
      "source": [
        "# Ensure data has loaded\n",
        "print(manhat_df[:6])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Unnamed: 0        DATE    BOROUGH  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "0            1  21-08-2012  MANHATTAN  ...          0         28       109\n",
            "6            7  27-10-2012  MANHATTAN  ...          0         20       122\n",
            "13          14  25-08-2012  MANHATTAN  ...          0         22        97\n",
            "16          17  09-09-2012  MANHATTAN  ...          0         29       109\n",
            "20          21  17-09-2012  MANHATTAN  ...          1         27       123\n",
            "28          29  23-11-2012  MANHATTAN  ...          0          5        66\n",
            "\n",
            "[6 rows x 46 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGRIp8ghOYNO"
      },
      "source": [
        "## Importing Numpy and setting preductors\n",
        "\n",
        "For the predictors, all the columns which have integer values are used.  The borough has been excluded (as only Manhattan is being selected) and the collision_date is being excluded.  However the date is being stored in the one hot encoded columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jmqYqn2OpMw",
        "outputId": "0c73d07d-2080-4e77-d5e9-0d4a358a093c"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhattan = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "\n",
        "# setup predictors\n",
        "# Removing the data fields as the DNN should be able to extract this.  Also exluding the borough field as only dealing with Manhattan\n",
        "predictors_manhattan = shuffle_manhattan.iloc[:,[3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28,29,30,31,32,33,34,35,36]]\n",
        "\n",
        "# Check -1 (for all columns) has worked\n",
        "print(predictors_manhattan[:6])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Fri  Mon  Sat  Sun  Thu  Tue  ...   GUST   MAX   MIN  PRCP   SNDP  FOG\n",
            "10152    0    0    0    1    0    0  ...   34.0  45.0  32.0  0.01  999.9    0\n",
            "12860    0    1    0    0    0    0  ...  999.9  66.9  48.0  0.00  999.9    0\n",
            "11382    0    1    0    0    0    0  ...   22.0  75.9  66.0  0.00  999.9    1\n",
            "10515    0    0    1    0    0    0  ...  999.9  77.0  57.0  0.00  999.9    0\n",
            "12722    0    0    0    0    0    1  ...   18.1  30.0  19.9  0.00  999.9    0\n",
            "9502     0    0    0    0    0    1  ...  999.9  75.0  60.1  0.00  999.9    0\n",
            "\n",
            "[6 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTJoKhCuOvL5",
        "outputId": "510910cb-1a3f-490b-bff9-fe68e4083381"
      },
      "source": [
        "# print first 5 rows of the shuffle\n",
        "print(shuffle_manhattan[:5])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0        DATE    BOROUGH  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "10152       10153  26-03-2018  MANHATTAN  ...          0         30       117\n",
            "12860       12861  01-10-2019  MANHATTAN  ...          0         23        85\n",
            "11382       11383  17-07-2018  MANHATTAN  ...          0         17       145\n",
            "10515       10516  26-08-2018  MANHATTAN  ...          0         16        77\n",
            "12722       12723  20-02-2019  MANHATTAN  ...          0         24       112\n",
            "\n",
            "[5 rows x 46 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQQdhn5aOyQI"
      },
      "source": [
        "### Defining the target\n",
        "\n",
        "For this test model, only the number of collisions (NUM_COLS) is of interest.  This needs to be defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6R6mCNoO7oE",
        "outputId": "0f385c1f-66ef-4b34-fbd9-8006ad317bcd"
      },
      "source": [
        "# Define the target (the NUM_COLS)\n",
        "target_manhatan = shuffle_manhattan.iloc[:,-1]\n",
        "\n",
        "# print the targets\n",
        "print(target_manhatan[:6])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10152    117\n",
            "12860     85\n",
            "11382    145\n",
            "10515     77\n",
            "12722    112\n",
            "9502     163\n",
            "Name: NUM_COLS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46NkBLJCPAb7"
      },
      "source": [
        "### Training and Testing dataset\n",
        "\n",
        "As with the linear regressor, a training and testing dataset of 80% and 20% of the results is defined.\n",
        "\n",
        "Also worth noting that there are a total of 33 predictors here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMrFGPmSPIm_"
      },
      "source": [
        "# Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "training_size_manhattan = int(len(shuffle_manhattan['NUM_COLS'] ) *0.8)\n",
        "\n",
        "# The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "testing_size_manhattan = len(shuffle_manhattan['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# Define the number of input values (predictors) - won't be 27, it will not include the borough or date - but should it include the borough?\n",
        "no_predictors = 33\n",
        "\n",
        "# Define the number of output values (targets)\n",
        "no_outputs = 1"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnmGlJyXPTtq"
      },
      "source": [
        "## The tensorflow bit...\n",
        "\n",
        "Now the tensorflow model can be setup.  This is mostly the same as the regressor (except the DNN uses the DNNRegressor, of course.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyMqMtXiPjr1",
        "outputId": "90e1dd31-38dc-4dbf-93be-95e4cc7c1bb4"
      },
      "source": [
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "model_dir = '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model'\n",
        "\n",
        "# remove the last training model - if it is present\n",
        "if os.path.isdir(model_dir):\n",
        "  print(\"\\n// Removing old model directory ....\")\n",
        "  shutil.rmtree(model_dir, ignore_errors=True)\n",
        "else:\n",
        "  print(\"\\n// No model directory to remove ....\")\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(\n",
        "    model_dir=model_dir, \n",
        "    hidden_units=[20,18,14], \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhattan.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Prints a log to show model is starting to train\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator.fit(predictors_manhattan[:training_size_manhattan].values, \n",
        "              target_manhatan[:training_size_manhattan].values.reshape(training_size_manhattan, no_outputs) / SCALE_NUM_COLS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_manhattan[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "rmse = np.sqrt(np.mean((target_manhatan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the Number of collisions values.\n",
        "avg = np.mean(shuffle_manhattan['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using Numbe of collision values and the mean of all target values.\n",
        "\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhattan['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n",
            "\n",
            "// Removing old model directory ....\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8885b0e0d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 6766.01, step = 1\n",
            "INFO:tensorflow:global_step/sec: 660.851\n",
            "INFO:tensorflow:loss = 1341.1533, step = 101 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 781.942\n",
            "INFO:tensorflow:loss = 1473.866, step = 201 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 778.477\n",
            "INFO:tensorflow:loss = 1239.442, step = 301 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 781.259\n",
            "INFO:tensorflow:loss = 1496.995, step = 401 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.429\n",
            "INFO:tensorflow:loss = 1386.8062, step = 501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 842.963\n",
            "INFO:tensorflow:loss = 1206.1256, step = 601 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 766.389\n",
            "INFO:tensorflow:loss = 1397.4746, step = 701 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 804.758\n",
            "INFO:tensorflow:loss = 1352.4325, step = 801 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 806.158\n",
            "INFO:tensorflow:loss = 1169.4523, step = 901 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 778.528\n",
            "INFO:tensorflow:loss = 1210.4014, step = 1001 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 789.683\n",
            "INFO:tensorflow:loss = 1315.8147, step = 1101 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 821.91\n",
            "INFO:tensorflow:loss = 1390.7987, step = 1201 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 775.534\n",
            "INFO:tensorflow:loss = 1117.5281, step = 1301 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 814.393\n",
            "INFO:tensorflow:loss = 1589.7821, step = 1401 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.15\n",
            "INFO:tensorflow:loss = 1264.7512, step = 1501 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.443\n",
            "INFO:tensorflow:loss = 1333.347, step = 1601 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.464\n",
            "INFO:tensorflow:loss = 1286.2903, step = 1701 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 793.874\n",
            "INFO:tensorflow:loss = 1425.011, step = 1801 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 816.497\n",
            "INFO:tensorflow:loss = 1381.0121, step = 1901 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 806.8\n",
            "INFO:tensorflow:loss = 1201.3433, step = 2001 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 788.092\n",
            "INFO:tensorflow:loss = 1343.7284, step = 2101 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 815.327\n",
            "INFO:tensorflow:loss = 1228.9255, step = 2201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.46\n",
            "INFO:tensorflow:loss = 1463.4463, step = 2301 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 851.692\n",
            "INFO:tensorflow:loss = 1130.2325, step = 2401 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 825.467\n",
            "INFO:tensorflow:loss = 1362.0103, step = 2501 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 825.488\n",
            "INFO:tensorflow:loss = 1422.2048, step = 2601 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 771.111\n",
            "INFO:tensorflow:loss = 1097.472, step = 2701 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.777\n",
            "INFO:tensorflow:loss = 1313.552, step = 2801 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 803.068\n",
            "INFO:tensorflow:loss = 1262.9724, step = 2901 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 810.154\n",
            "INFO:tensorflow:loss = 1265.5056, step = 3001 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 821.041\n",
            "INFO:tensorflow:loss = 1298.6736, step = 3101 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 762.177\n",
            "INFO:tensorflow:loss = 1186.8135, step = 3201 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 834.038\n",
            "INFO:tensorflow:loss = 1221.3176, step = 3301 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.042\n",
            "INFO:tensorflow:loss = 1317.031, step = 3401 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 842.38\n",
            "INFO:tensorflow:loss = 1317.8821, step = 3501 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 893.917\n",
            "INFO:tensorflow:loss = 1346.1338, step = 3601 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 757.416\n",
            "INFO:tensorflow:loss = 1129.9592, step = 3701 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 820.193\n",
            "INFO:tensorflow:loss = 1323.9253, step = 3801 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 793.396\n",
            "INFO:tensorflow:loss = 1027.1125, step = 3901 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 828.588\n",
            "INFO:tensorflow:loss = 929.14526, step = 4001 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 765.963\n",
            "INFO:tensorflow:loss = 1259.431, step = 4101 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 784.74\n",
            "INFO:tensorflow:loss = 1241.0035, step = 4201 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 873.924\n",
            "INFO:tensorflow:loss = 1074.3105, step = 4301 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 866.52\n",
            "INFO:tensorflow:loss = 1269.9111, step = 4401 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.458\n",
            "INFO:tensorflow:loss = 1093.3723, step = 4501 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 766.027\n",
            "INFO:tensorflow:loss = 1502.3096, step = 4601 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 776.29\n",
            "INFO:tensorflow:loss = 1471.1436, step = 4701 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 800.741\n",
            "INFO:tensorflow:loss = 1236.1426, step = 4801 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.789\n",
            "INFO:tensorflow:loss = 1239.2332, step = 4901 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 773.015\n",
            "INFO:tensorflow:loss = 1097.6675, step = 5001 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 768.858\n",
            "INFO:tensorflow:loss = 1176.9175, step = 5101 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.721\n",
            "INFO:tensorflow:loss = 1106.4541, step = 5201 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.56\n",
            "INFO:tensorflow:loss = 1046.5063, step = 5301 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 773.462\n",
            "INFO:tensorflow:loss = 1262.4207, step = 5401 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.719\n",
            "INFO:tensorflow:loss = 1155.2349, step = 5501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 802.536\n",
            "INFO:tensorflow:loss = 1020.1267, step = 5601 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 835.56\n",
            "INFO:tensorflow:loss = 1352.5819, step = 5701 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.216\n",
            "INFO:tensorflow:loss = 1087.6156, step = 5801 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.365\n",
            "INFO:tensorflow:loss = 1277.969, step = 5901 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 857.857\n",
            "INFO:tensorflow:loss = 1129.08, step = 6001 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 800.875\n",
            "INFO:tensorflow:loss = 974.3866, step = 6101 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.772\n",
            "INFO:tensorflow:loss = 1350.5605, step = 6201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 800.865\n",
            "INFO:tensorflow:loss = 1142.4142, step = 6301 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 812.757\n",
            "INFO:tensorflow:loss = 1164.5889, step = 6401 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.315\n",
            "INFO:tensorflow:loss = 1106.026, step = 6501 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.046\n",
            "INFO:tensorflow:loss = 1151.0985, step = 6601 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 840.237\n",
            "INFO:tensorflow:loss = 1070.3969, step = 6701 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 815.166\n",
            "INFO:tensorflow:loss = 1376.22, step = 6801 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 837.83\n",
            "INFO:tensorflow:loss = 1072.5513, step = 6901 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 723.172\n",
            "INFO:tensorflow:loss = 1396.906, step = 7001 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 732.979\n",
            "INFO:tensorflow:loss = 1273.4286, step = 7101 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 835.361\n",
            "INFO:tensorflow:loss = 996.3164, step = 7201 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 851.872\n",
            "INFO:tensorflow:loss = 892.3257, step = 7301 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.29\n",
            "INFO:tensorflow:loss = 1369.2104, step = 7401 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.991\n",
            "INFO:tensorflow:loss = 1169.3032, step = 7501 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 796.647\n",
            "INFO:tensorflow:loss = 1293.9506, step = 7601 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 850.544\n",
            "INFO:tensorflow:loss = 1183.9733, step = 7701 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 889.911\n",
            "INFO:tensorflow:loss = 1072.754, step = 7801 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 845.518\n",
            "INFO:tensorflow:loss = 1489.4639, step = 7901 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 813.551\n",
            "INFO:tensorflow:loss = 1100.742, step = 8001 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.074\n",
            "INFO:tensorflow:loss = 1193.8826, step = 8101 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 800.085\n",
            "INFO:tensorflow:loss = 1283.568, step = 8201 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 833.003\n",
            "INFO:tensorflow:loss = 1032.1841, step = 8301 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 841.034\n",
            "INFO:tensorflow:loss = 1264.2576, step = 8401 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 903.744\n",
            "INFO:tensorflow:loss = 1210.9843, step = 8501 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.894\n",
            "INFO:tensorflow:loss = 1253.6836, step = 8601 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 761.19\n",
            "INFO:tensorflow:loss = 1202.3381, step = 8701 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 813.018\n",
            "INFO:tensorflow:loss = 1030.7219, step = 8801 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.062\n",
            "INFO:tensorflow:loss = 1223.2804, step = 8901 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 858.15\n",
            "INFO:tensorflow:loss = 1207.2499, step = 9001 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 888.686\n",
            "INFO:tensorflow:loss = 1403.3208, step = 9101 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 817.904\n",
            "INFO:tensorflow:loss = 1076.1626, step = 9201 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 846.291\n",
            "INFO:tensorflow:loss = 1566.0248, step = 9301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.066\n",
            "INFO:tensorflow:loss = 1097.8813, step = 9401 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 727.476\n",
            "INFO:tensorflow:loss = 1407.041, step = 9501 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 785.043\n",
            "INFO:tensorflow:loss = 1276.2864, step = 9601 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 837.797\n",
            "INFO:tensorflow:loss = 995.6911, step = 9701 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 790.968\n",
            "INFO:tensorflow:loss = 1110.4462, step = 9801 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 836.829\n",
            "INFO:tensorflow:loss = 1064.0748, step = 9901 (0.120 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1245.8989.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "DNNRegression has RMSE of 35.34164627005854\n",
            "Just using average = 106.34503140007388 has RMSE of 39.187888150127044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ52I5cuQOQV"
      },
      "source": [
        "### Testing the model\n",
        "\n",
        "As a test for the model, a date is selected from the data and the values plugged in.  For this test, the 05/05/2017 in MANHATTAN has been selected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agdZ-ef2Qa_b",
        "outputId": "afb3cde8-2e6d-4ef5-fc4a-5ee79aefd76f"
      },
      "source": [
        "# As a test, use something which is known - this case the values for MANHATTAN on the 05/05/2016\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "        'Fri': [0],\n",
        "        'Mon': [0],\n",
        "        'Sat': [0],\n",
        "        'Sun': [0],\n",
        "        'Thu': [0],\n",
        "        'Tue': [0],\t\n",
        "        'Wed': [1],\t\n",
        "        'YEAR': [2016],\n",
        "        'Apr': [0],\t\n",
        "        'Aug': [0],\t\n",
        "        'Dec': [0],\t\n",
        "        'Feb': [0],\t\n",
        "        'Jan': [0],\t\n",
        "        'Jul': [0],\t\n",
        "        'Jun': [0],\t\n",
        "        'Mar': [0],\t\n",
        "        'May': [1],\t\n",
        "        'Nov': [0],\t\n",
        "        'Oct': [0],\t\n",
        "        'Sep': [0],\t\n",
        "        'DAY': [4],\n",
        "        'TEMP': [45.5],\n",
        "        'DEWP': [43.9],\t\n",
        "        'SLP': [1003.7],\t\n",
        "        'VISIB': [5.9],\n",
        "        'WDSP': [21.5],\t\n",
        "        'MXPSD': [26],\n",
        "        'GUST': [35],\t\n",
        "        'MAX': [50],\n",
        "        'MIN': [45],\t\n",
        "        'PRCP': [0.52],\n",
        "        'SNDP': [999.9],\n",
        "        'FOG': [0]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir=model_dir, hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n",
        "print(predslistnorm)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f88e3079550>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[127.09423]\n",
            "[127.09423]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_da79fqQe5f"
      },
      "source": [
        "This returns **[128.98424]** (the value may change on subsequent runs) - and this value is a _little_ higher than the recorded value of **128**\n",
        "\n",
        "That is quite a good result from a first run!\n",
        "\n",
        "(note on a second run the result came out as shwon as **[127.09423]** - the original 128 value is being kept to show the model accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "081Vz4aoQvMb"
      },
      "source": [
        "### Testing an unknown date.\n",
        "\n",
        "When the data was constructed the year 2021 was removed (due to covid) however, the weather data for 2021 is still available.  Selecting a more recent date (in this case 21-11-2021) and using the weather data from then will give a different result.\n",
        "\n",
        "date      |year|mo|da|temp|dewp|slp   |visib|wdsp|mxpsd|gust |max |min|prcp|sndp |fog\n",
        "----------|----|--|--|----|----|------|-----|----|-----|-----|----|---|----|-----|---\n",
        "2021-11-21|2021|11|21|52.3|42.2|1028.0|10.0 |11.3|14   |999.9|57.9|39.0|0.0|999.9|1\n",
        "\n",
        "This will result in an ```input``` which looks like this:\n",
        "\n",
        "```python\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'Fri': [0],\n",
        "         'Mon': [0],\n",
        "         'Sat': [1],\n",
        "         'Sun': [0],\n",
        "         'Thu': [0],\n",
        "         'Tue': [0],\t\n",
        "         'Wed': [0],\t\n",
        "         'YEAR': [2021],\n",
        "         'Apr': [0],\t\n",
        "         'Aug': [0],\t\n",
        "         'Dec': [0],\t\n",
        "         'Feb': [0],\t\n",
        "         'Jan': [0],\t\n",
        "         'Jul': [0],\t\n",
        "         'Jun': [0],\t\n",
        "         'Mar': [0],\t\n",
        "         'May': [1],\t\n",
        "         'Nov': [0],\t\n",
        "         'Oct': [0],\t\n",
        "         'Sep': [0],\t\n",
        "         'DAY': [4],       \n",
        "         'TEMP' : [52.3],\n",
        "         'DEWP' : [42.2],\n",
        "         'SLP' : [1028.0],\n",
        "         'VISIB' : [10.0],\n",
        "         'WDSP' : [11.3],\n",
        "         'MXPSD' : [14],\n",
        "         'GUST' : [999.9],\n",
        "         'MAX' : [57.9],\n",
        "         'MIN' : [39],\n",
        "         'PRCP' : [0.0],\n",
        "         'SNDP' : [999.9],\n",
        "         'FOG' : [1]\n",
        "        })\n",
        "```\n",
        "\n",
        "creating a new code block which incorporates all the above code items (for brevity) is below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inshwx5eU_Ut",
        "outputId": "a0005639-61a2-4883-bdee-25c999f651c2"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhattan = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "\n",
        "# setup predictors\n",
        "# Removing the data fields as the DNN should be able to extract this.  Also exluding the borough field as only dealing with Manhattan\n",
        "predictors_manhattan = shuffle_manhattan.iloc[:,[3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28,29,30,31,32,33,34,35,36]]\n",
        "\n",
        "# Check -1 (for all columns) has worked\n",
        "print(predictors_manhattan[:6])\n",
        "\n",
        "# print first 5 rows of the shuffle\n",
        "print(shuffle_manhattan[:5])\n",
        "\n",
        "# Define the target (the NUM_COLS)\n",
        "target_manhatan = shuffle_manhattan.iloc[:,-1]\n",
        "\n",
        "# print the targets\n",
        "print(target_manhatan[:6])\n",
        "\n",
        "# Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "training_size_manhattan = int(len(shuffle_manhattan['NUM_COLS'] ) *0.8)\n",
        "\n",
        "# The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "testing_size_manhattan = len(shuffle_manhattan['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# Define the number of input values (predictors) - won't be 27, it will not include the borough or date - but should it include the borough?\n",
        "no_predictors = 33\n",
        "\n",
        "# Define the number of output values (targets)\n",
        "no_outputs = 1\n",
        "\n",
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "model_dir = '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model'\n",
        "\n",
        "# remove the last training model - if it is present\n",
        "if os.path.isdir(model_dir):\n",
        "  print(\"\\n// Removing old model directory ....\")\n",
        "  shutil.rmtree(model_dir, ignore_errors=True)\n",
        "else:\n",
        "  print(\"\\n// No model directory to remove ....\")\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(\n",
        "    model_dir=model_dir, \n",
        "    hidden_units=[20,18,14], \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhattan.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Prints a log to show model is starting to train\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator.fit(predictors_manhattan[:training_size_manhattan].values, \n",
        "              target_manhatan[:training_size_manhattan].values.reshape(training_size_manhattan, no_outputs) / SCALE_NUM_COLS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_manhattan[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((target_manhatan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the Life Satisfaction Values.\n",
        "avg = np.mean(shuffle_manhattan['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using Life Satisfaction Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhattan['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n",
        "\n",
        "# As a test, use something which is known - this case the values for MANHATTAN on the 05/05/2017\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "        {\n",
        "         'Fri': [0],\n",
        "         'Mon': [0],\n",
        "         'Sat': [1],\n",
        "         'Sun': [0],\n",
        "         'Thu': [0],\n",
        "         'Tue': [0],\t\n",
        "         'Wed': [0],\t\n",
        "         'YEAR': [2021],\n",
        "         'Apr': [0],\t\n",
        "         'Aug': [0],\t\n",
        "         'Dec': [0],\t\n",
        "         'Feb': [0],\t\n",
        "         'Jan': [0],\t\n",
        "         'Jul': [0],\t\n",
        "         'Jun': [0],\t\n",
        "         'Mar': [0],\t\n",
        "         'May': [1],\t\n",
        "         'Nov': [0],\t\n",
        "         'Oct': [0],\t\n",
        "         'Sep': [0],\t\n",
        "         'DAY': [4],       \n",
        "         'TEMP' : [52.3],\n",
        "         'DEWP' : [42.2],\n",
        "         'SLP' : [1028.0],\n",
        "         'VISIB' : [10.0],\n",
        "         'WDSP' : [11.3],\n",
        "         'MXPSD' : [14],\n",
        "         'GUST' : [999.9],\n",
        "         'MAX' : [57.9],\n",
        "         'MIN' : [39],\n",
        "         'PRCP' : [0.0],\n",
        "         'SNDP' : [999.9],\n",
        "         'FOG' : [1]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir=model_dir, hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n",
        "print(predslistnorm)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Fri  Mon  Sat  Sun  Thu  Tue  ...   GUST   MAX   MIN  PRCP   SNDP  FOG\n",
            "13817    0    0    1    0    0    0  ...   38.1  48.9  36.0  0.38  999.9    1\n",
            "3535     0    0    0    1    0    0  ...  999.9  46.9  28.9  0.01  999.9    0\n",
            "15968    0    0    0    0    0    0  ...  999.9  37.0  23.0  0.00  999.9    1\n",
            "9990     0    0    0    0    0    1  ...   31.1  51.1  37.0  0.00  999.9    0\n",
            "14285    0    0    0    0    0    0  ...  999.9  71.1  53.1  0.00  999.9    1\n",
            "10239    0    1    0    0    0    0  ...   39.0  61.0  37.0  0.13  999.9    0\n",
            "\n",
            "[6 rows x 33 columns]\n",
            "       Unnamed: 0        DATE    BOROUGH  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "13817       13818  05-01-2020  MANHATTAN  ...          0         16        57\n",
            "3535         3536  13-01-2014  MANHATTAN  ...          0         17        97\n",
            "15968       15969  18-02-2021  MANHATTAN  ...          0         10        22\n",
            "9990         9991  2017-12-20  MANHATTAN  ...          0         24       119\n",
            "14285       14286  18-06-2020  MANHATTAN  ...          0         14        28\n",
            "\n",
            "[5 rows x 46 columns]\n",
            "13817     57\n",
            "3535      97\n",
            "15968     22\n",
            "9990     119\n",
            "14285     28\n",
            "10239    150\n",
            "Name: NUM_COLS, dtype: int64\n",
            "1.15.2\n",
            "\n",
            "// Removing old model directory ....\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f888a9b7090>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 304871.3, step = 1\n",
            "INFO:tensorflow:global_step/sec: 603.368\n",
            "INFO:tensorflow:loss = 1321.3813, step = 101 (0.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 789.364\n",
            "INFO:tensorflow:loss = 1244.48, step = 201 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 763.192\n",
            "INFO:tensorflow:loss = 1290.6041, step = 301 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 748.256\n",
            "INFO:tensorflow:loss = 1450.7556, step = 401 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 807.799\n",
            "INFO:tensorflow:loss = 1463.7859, step = 501 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 832.403\n",
            "INFO:tensorflow:loss = 1432.177, step = 601 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.497\n",
            "INFO:tensorflow:loss = 1281.4169, step = 701 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 858.901\n",
            "INFO:tensorflow:loss = 1355.926, step = 801 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 827.157\n",
            "INFO:tensorflow:loss = 1496.9307, step = 901 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 875.142\n",
            "INFO:tensorflow:loss = 1298.5098, step = 1001 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 812.402\n",
            "INFO:tensorflow:loss = 1648.465, step = 1101 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.528\n",
            "INFO:tensorflow:loss = 1692.1174, step = 1201 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 782.62\n",
            "INFO:tensorflow:loss = 1129.4904, step = 1301 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 821.62\n",
            "INFO:tensorflow:loss = 1418.4658, step = 1401 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 787.968\n",
            "INFO:tensorflow:loss = 1634.3588, step = 1501 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 806.414\n",
            "INFO:tensorflow:loss = 1596.1794, step = 1601 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 764.578\n",
            "INFO:tensorflow:loss = 1040.6367, step = 1701 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 733.605\n",
            "INFO:tensorflow:loss = 1511.2086, step = 1801 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 809.349\n",
            "INFO:tensorflow:loss = 1145.7787, step = 1901 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 787.277\n",
            "INFO:tensorflow:loss = 1127.5629, step = 2001 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 828.668\n",
            "INFO:tensorflow:loss = 1401.0675, step = 2101 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.222\n",
            "INFO:tensorflow:loss = 1150.6599, step = 2201 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 876.379\n",
            "INFO:tensorflow:loss = 1403.5231, step = 2301 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.237\n",
            "INFO:tensorflow:loss = 1225.168, step = 2401 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.736\n",
            "INFO:tensorflow:loss = 1417.4746, step = 2501 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.773\n",
            "INFO:tensorflow:loss = 1019.5239, step = 2601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 776.857\n",
            "INFO:tensorflow:loss = 1362.8806, step = 2701 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 867.423\n",
            "INFO:tensorflow:loss = 1164.3328, step = 2801 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 828.105\n",
            "INFO:tensorflow:loss = 1234.9039, step = 2901 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 825.093\n",
            "INFO:tensorflow:loss = 1272.3069, step = 3001 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.151\n",
            "INFO:tensorflow:loss = 1345.8577, step = 3101 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 816.457\n",
            "INFO:tensorflow:loss = 1238.0321, step = 3201 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.261\n",
            "INFO:tensorflow:loss = 1274.0353, step = 3301 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 763.624\n",
            "INFO:tensorflow:loss = 1221.0026, step = 3401 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 835.988\n",
            "INFO:tensorflow:loss = 1451.4834, step = 3501 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 755.026\n",
            "INFO:tensorflow:loss = 923.4542, step = 3601 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 805.033\n",
            "INFO:tensorflow:loss = 1143.9954, step = 3701 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 771.311\n",
            "INFO:tensorflow:loss = 1112.4324, step = 3801 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 820.326\n",
            "INFO:tensorflow:loss = 1355.791, step = 3901 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 838.304\n",
            "INFO:tensorflow:loss = 1268.154, step = 4001 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 835.046\n",
            "INFO:tensorflow:loss = 1064.2926, step = 4101 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 846.652\n",
            "INFO:tensorflow:loss = 1516.8889, step = 4201 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 799.229\n",
            "INFO:tensorflow:loss = 1088.5945, step = 4301 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.14\n",
            "INFO:tensorflow:loss = 1191.9429, step = 4401 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 867.637\n",
            "INFO:tensorflow:loss = 1105.4468, step = 4501 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.706\n",
            "INFO:tensorflow:loss = 1269.2913, step = 4601 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 751.717\n",
            "INFO:tensorflow:loss = 929.463, step = 4701 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 807.32\n",
            "INFO:tensorflow:loss = 1023.8009, step = 4801 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.857\n",
            "INFO:tensorflow:loss = 1008.29456, step = 4901 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 711.971\n",
            "INFO:tensorflow:loss = 1521.4235, step = 5001 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 840.678\n",
            "INFO:tensorflow:loss = 1134.418, step = 5101 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 799.825\n",
            "INFO:tensorflow:loss = 1304.3293, step = 5201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.813\n",
            "INFO:tensorflow:loss = 1267.9438, step = 5301 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 840.539\n",
            "INFO:tensorflow:loss = 913.84607, step = 5401 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 768.355\n",
            "INFO:tensorflow:loss = 1342.0596, step = 5501 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.517\n",
            "INFO:tensorflow:loss = 1337.1954, step = 5601 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 776.129\n",
            "INFO:tensorflow:loss = 1501.9275, step = 5701 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.309\n",
            "INFO:tensorflow:loss = 1085.4462, step = 5801 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 862.568\n",
            "INFO:tensorflow:loss = 1679.0277, step = 5901 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 804.9\n",
            "INFO:tensorflow:loss = 1282.7506, step = 6001 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 825.732\n",
            "INFO:tensorflow:loss = 1028.2145, step = 6101 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.125\n",
            "INFO:tensorflow:loss = 1042.2031, step = 6201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 840.667\n",
            "INFO:tensorflow:loss = 1273.023, step = 6301 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.482\n",
            "INFO:tensorflow:loss = 1202.2607, step = 6401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 890.87\n",
            "INFO:tensorflow:loss = 1234.1371, step = 6501 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 838.972\n",
            "INFO:tensorflow:loss = 1128.0322, step = 6601 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.05\n",
            "INFO:tensorflow:loss = 1273.7285, step = 6701 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.082\n",
            "INFO:tensorflow:loss = 993.67773, step = 6801 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 803.242\n",
            "INFO:tensorflow:loss = 968.9443, step = 6901 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 858.982\n",
            "INFO:tensorflow:loss = 1346.9883, step = 7001 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.256\n",
            "INFO:tensorflow:loss = 1221.6744, step = 7101 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 806.543\n",
            "INFO:tensorflow:loss = 1260.3535, step = 7201 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 870.892\n",
            "INFO:tensorflow:loss = 1386.7001, step = 7301 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 787.786\n",
            "INFO:tensorflow:loss = 1234.9921, step = 7401 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.535\n",
            "INFO:tensorflow:loss = 1283.5316, step = 7501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.03\n",
            "INFO:tensorflow:loss = 1009.7668, step = 7601 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.574\n",
            "INFO:tensorflow:loss = 1373.0917, step = 7701 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 877.469\n",
            "INFO:tensorflow:loss = 1284.4192, step = 7801 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 869.228\n",
            "INFO:tensorflow:loss = 1187.8827, step = 7901 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 809.193\n",
            "INFO:tensorflow:loss = 1057.1234, step = 8001 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 804.052\n",
            "INFO:tensorflow:loss = 1195.5907, step = 8101 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.765\n",
            "INFO:tensorflow:loss = 1215.9889, step = 8201 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 796.734\n",
            "INFO:tensorflow:loss = 1425.8047, step = 8301 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.299\n",
            "INFO:tensorflow:loss = 1263.536, step = 8401 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 785.63\n",
            "INFO:tensorflow:loss = 1302.7593, step = 8501 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 853.394\n",
            "INFO:tensorflow:loss = 1173.9988, step = 8601 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 741.668\n",
            "INFO:tensorflow:loss = 1020.2665, step = 8701 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 753.67\n",
            "INFO:tensorflow:loss = 1147.5125, step = 8801 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.946\n",
            "INFO:tensorflow:loss = 1088.8518, step = 8901 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.424\n",
            "INFO:tensorflow:loss = 1122.5574, step = 9001 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 848.833\n",
            "INFO:tensorflow:loss = 1112.6562, step = 9101 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 815.965\n",
            "INFO:tensorflow:loss = 1209.9058, step = 9201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 764.532\n",
            "INFO:tensorflow:loss = 1058.4321, step = 9301 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 804.947\n",
            "INFO:tensorflow:loss = 1104.6089, step = 9401 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.609\n",
            "INFO:tensorflow:loss = 1127.085, step = 9501 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 807.223\n",
            "INFO:tensorflow:loss = 939.42993, step = 9601 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 850.401\n",
            "INFO:tensorflow:loss = 1089.9404, step = 9701 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 853.872\n",
            "INFO:tensorflow:loss = 1195.9529, step = 9801 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 808.276\n",
            "INFO:tensorflow:loss = 996.97174, step = 9901 (0.125 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1423.8184.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "DNNRegression has RMSE of 34.68531330238657\n",
            "Just using average = 106.03472478758773 has RMSE of 38.39582058308093\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8885c6f810>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[63.714706]\n",
            "[63.714706]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTPPF1pmXATF"
      },
      "source": [
        "### Prediction\n",
        "\n",
        "This returns [63.714706]  - while there is no way to tell if this is correct or not, and with covid still a large part of daily lives, the NY collisions data has been updated to show that 27 accidents have been recorded in the Manhattan area on the date selected.  This value was found using the followng query:\n",
        "\n",
        "```sql\n",
        "SELECT *  FROM `bigquery-public-data.new_york_mv_collisions.nypd_mv_collisions`\n",
        "where timestamp between '2021-11-20'  and '2021-11-22'\n",
        "ORDER BY timestamp DESC\n",
        "```\n",
        "\n",
        "The result of this was saved (file name \"pred_check_results.csv\" and the location column removed (as this was a comma seperated value it caused issues) as well as the header.  A new python script was created (check_results.py) which used the getBoroghFromLatLong function used when creating the data.  The result was saved to a new file which then had the header inserted and the data filtered.\n",
        "\n",
        "While the result obtained is less than the \"recorded\" result, COVID is still very mich a factor in people's daily lives and the predicticion could be affected by this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK92aBaLDvQR"
      },
      "source": [
        "## Additional\n",
        "\n",
        "While the current implentation using tensorflow 1.x does not support, at least out of the box, multiple dimension arrays, getting a prediction using collisions and injuries could still be possible (even if outside the scope of this assignment) - it would simply be a case of setting a different target for each run.  So one model for collisions and a different model for each of the injuries. \n",
        "\n",
        "As an example:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_-BiaFFEJ50"
      },
      "source": [
        "### Cyclists killed Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zngZWMZSEjNl",
        "outputId": "5f08319f-2d6e-4928-b630-f85cff04ba44"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhattan = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "\n",
        "# setup predictors\n",
        "# Removing the data fields as the DNN should be able to extract this.  Also exluding the borough field as only dealing with Manhattan\n",
        "predictors_manhattan = shuffle_manhattan.iloc[:,[3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28,29,30,31,32,33,34,35,36]]\n",
        "\n",
        "# Check -1 (for all columns) has worked\n",
        "print(predictors_manhattan[:6])\n",
        "\n",
        "# print first 5 rows of the shuffle\n",
        "print(shuffle_manhattan[:5])\n",
        "\n",
        "# Define the target (the NUM_COLS)\n",
        "target_manhatan = shuffle_manhattan.iloc[:,37]\n",
        "\n",
        "# print the targets\n",
        "print(target_manhatan[:6])\n",
        "\n",
        "# Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "training_size_manhattan = int(len(shuffle_manhattan['CYC_KILL'] ) *0.8)\n",
        "\n",
        "# The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "testing_size_manhattan = len(shuffle_manhattan['CYC_KILL']) - training_size_manhattan\n",
        "\n",
        "# Define the number of input values (predictors) - won't be 27, it will not include the borough or date - but should it include the borough?\n",
        "no_predictors = 33\n",
        "\n",
        "# Define the number of output values (targets)\n",
        "no_outputs = 1\n",
        "\n",
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "model_dir = '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Cyclist_killed'\n",
        "\n",
        "# remove the last training model - if it is present\n",
        "if os.path.isdir(model_dir):\n",
        "  print(\"\\n// Removing old model directory ....\")\n",
        "  shutil.rmtree(model_dir, ignore_errors=True)\n",
        "else:\n",
        "  print(\"\\n// No model directory to remove ....\")\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(\n",
        "    model_dir=model_dir, \n",
        "    hidden_units=[20,18,14], \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhattan.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Prints a log to show model is starting to train\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator.fit(predictors_manhattan[:training_size_manhattan].values, \n",
        "              target_manhatan[:training_size_manhattan].values.reshape(training_size_manhattan, no_outputs) / SCALE_NUM_COLS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_manhattan[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((target_manhatan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the Life Satisfaction Values.\n",
        "avg = np.mean(shuffle_manhattan['CYC_KILL'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using Life Satisfaction Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhattan['CYC_KILL'][training_size_manhattan:] - avg) ** 2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n",
        "\n",
        "# As a test, use something which is known - this case the values for MANHATTAN on the 05/05/2017\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "        {\n",
        "         'Fri': [0],\n",
        "         'Mon': [0],\n",
        "         'Sat': [1],\n",
        "         'Sun': [0],\n",
        "         'Thu': [0],\n",
        "         'Tue': [0],\t\n",
        "         'Wed': [0],\t\n",
        "         'YEAR': [2021],\n",
        "         'Apr': [0],\t\n",
        "         'Aug': [0],\t\n",
        "         'Dec': [0],\t\n",
        "         'Feb': [0],\t\n",
        "         'Jan': [0],\t\n",
        "         'Jul': [0],\t\n",
        "         'Jun': [0],\t\n",
        "         'Mar': [0],\t\n",
        "         'May': [1],\t\n",
        "         'Nov': [0],\t\n",
        "         'Oct': [0],\t\n",
        "         'Sep': [0],\t\n",
        "         'DAY': [4],       \n",
        "         'TEMP' : [52.3],\n",
        "         'DEWP' : [42.2],\n",
        "         'SLP' : [1028.0],\n",
        "         'VISIB' : [10.0],\n",
        "         'WDSP' : [11.3],\n",
        "         'MXPSD' : [14],\n",
        "         'GUST' : [999.9],\n",
        "         'MAX' : [57.9],\n",
        "         'MIN' : [39],\n",
        "         'PRCP' : [0.0],\n",
        "         'SNDP' : [999.9],\n",
        "         'FOG' : [1]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir=model_dir, hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n",
        "print(predslistnorm)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Fri  Mon  Sat  Sun  Thu  Tue  ...   GUST   MAX   MIN  PRCP   SNDP  FOG\n",
            "4041     0    0    0    0    0    1  ...   24.1  55.9  45.0  0.55  999.9    1\n",
            "16886    1    0    0    0    0    0  ...   28.0  44.1  30.9  0.00  999.9    0\n",
            "7337     0    0    0    1    0    0  ...  999.9  66.9  54.0  0.00  999.9    0\n",
            "3910     0    0    0    0    0    0  ...   20.0  64.9  53.6  0.00  999.9    0\n",
            "9190     0    0    0    0    0    0  ...  999.9  80.1  64.0  0.00  999.9    1\n",
            "5265     0    0    1    0    0    0  ...  999.9  62.1  45.0  0.00  999.9    0\n",
            "\n",
            "[6 rows x 33 columns]\n",
            "       Unnamed: 0        DATE    BOROUGH  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "4041         4042  24-12-2014  MANHATTAN  ...          0         18        87\n",
            "16886       16887  06-02-2021  MANHATTAN  ...          1          9        37\n",
            "7337         7338  20-06-2016  MANHATTAN  ...          0         27       138\n",
            "3910         3911  15-05-2014  MANHATTAN  ...          0         32       148\n",
            "9190         9191  2017-07-13  MANHATTAN  ...          0         25       171\n",
            "\n",
            "[5 rows x 46 columns]\n",
            "4041     0\n",
            "16886    0\n",
            "7337     0\n",
            "3910     0\n",
            "9190     0\n",
            "5265     0\n",
            "Name: CYC_KILL, dtype: int64\n",
            "1.15.2\n",
            "\n",
            "// Removing old model directory ....\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f88855204d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Cyclist_killed', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Cyclist_killed/model.ckpt.\n",
            "INFO:tensorflow:loss = 123843.06, step = 1\n",
            "INFO:tensorflow:global_step/sec: 604.898\n",
            "INFO:tensorflow:loss = 1.4985051, step = 101 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 765.567\n",
            "INFO:tensorflow:loss = 0.43989742, step = 201 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.977\n",
            "INFO:tensorflow:loss = 0.33299467, step = 301 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 806.34\n",
            "INFO:tensorflow:loss = 0.20326139, step = 401 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 798.532\n",
            "INFO:tensorflow:loss = 0.20730844, step = 501 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 783.655\n",
            "INFO:tensorflow:loss = 0.14269981, step = 601 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 841.338\n",
            "INFO:tensorflow:loss = 8.284964, step = 701 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.649\n",
            "INFO:tensorflow:loss = 40.37532, step = 801 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 842.77\n",
            "INFO:tensorflow:loss = 0.042470574, step = 901 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 814.635\n",
            "INFO:tensorflow:loss = 0.032833733, step = 1001 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.712\n",
            "INFO:tensorflow:loss = 0.041222863, step = 1101 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 813.774\n",
            "INFO:tensorflow:loss = 0.05434374, step = 1201 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 768.957\n",
            "INFO:tensorflow:loss = 0.040607594, step = 1301 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.259\n",
            "INFO:tensorflow:loss = 0.03366439, step = 1401 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 825.767\n",
            "INFO:tensorflow:loss = 0.056858797, step = 1501 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 905.08\n",
            "INFO:tensorflow:loss = 0.1805746, step = 1601 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 856.454\n",
            "INFO:tensorflow:loss = 0.077222615, step = 1701 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 923.469\n",
            "INFO:tensorflow:loss = 0.024286509, step = 1801 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.786\n",
            "INFO:tensorflow:loss = 0.018095119, step = 1901 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.165\n",
            "INFO:tensorflow:loss = 0.31373066, step = 2001 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.221\n",
            "INFO:tensorflow:loss = 0.027436908, step = 2101 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 842.966\n",
            "INFO:tensorflow:loss = 0.041890964, step = 2201 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 799.922\n",
            "INFO:tensorflow:loss = 0.12660474, step = 2301 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 857.105\n",
            "INFO:tensorflow:loss = 0.06712225, step = 2401 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.115\n",
            "INFO:tensorflow:loss = 0.28843486, step = 2501 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.582\n",
            "INFO:tensorflow:loss = 0.25066647, step = 2601 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.565\n",
            "INFO:tensorflow:loss = 0.029062241, step = 2701 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 892.897\n",
            "INFO:tensorflow:loss = 0.065981545, step = 2801 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 827.383\n",
            "INFO:tensorflow:loss = 0.038142122, step = 2901 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.65\n",
            "INFO:tensorflow:loss = 0.8639809, step = 3001 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 858.421\n",
            "INFO:tensorflow:loss = 0.17584938, step = 3101 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 825.937\n",
            "INFO:tensorflow:loss = 0.024032164, step = 3201 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 868.72\n",
            "INFO:tensorflow:loss = 0.034869254, step = 3301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 883.225\n",
            "INFO:tensorflow:loss = 0.017589007, step = 3401 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.193\n",
            "INFO:tensorflow:loss = 0.089504495, step = 3501 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 888.417\n",
            "INFO:tensorflow:loss = 0.056729466, step = 3601 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.169\n",
            "INFO:tensorflow:loss = 0.10523057, step = 3701 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 768.137\n",
            "INFO:tensorflow:loss = 0.32459658, step = 3801 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 799.137\n",
            "INFO:tensorflow:loss = 0.18245697, step = 3901 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 804.453\n",
            "INFO:tensorflow:loss = 0.6340021, step = 4001 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 876.864\n",
            "INFO:tensorflow:loss = 0.048904248, step = 4101 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.443\n",
            "INFO:tensorflow:loss = 0.020738192, step = 4201 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.833\n",
            "INFO:tensorflow:loss = 0.06974876, step = 4301 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.213\n",
            "INFO:tensorflow:loss = 0.04764919, step = 4401 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.118\n",
            "INFO:tensorflow:loss = 0.035005506, step = 4501 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.392\n",
            "INFO:tensorflow:loss = 0.022094099, step = 4601 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 797.349\n",
            "INFO:tensorflow:loss = 0.018154984, step = 4701 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 878.556\n",
            "INFO:tensorflow:loss = 0.032634288, step = 4801 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.295\n",
            "INFO:tensorflow:loss = 0.018169124, step = 4901 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 786.677\n",
            "INFO:tensorflow:loss = 0.01318245, step = 5001 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.481\n",
            "INFO:tensorflow:loss = 0.04622458, step = 5101 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 869.461\n",
            "INFO:tensorflow:loss = 0.024791872, step = 5201 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.672\n",
            "INFO:tensorflow:loss = 0.06754305, step = 5301 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 838.755\n",
            "INFO:tensorflow:loss = 0.08164854, step = 5401 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 901.764\n",
            "INFO:tensorflow:loss = 0.024515238, step = 5501 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.417\n",
            "INFO:tensorflow:loss = 0.036256917, step = 5601 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 838.978\n",
            "INFO:tensorflow:loss = 0.14075154, step = 5701 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 827.294\n",
            "INFO:tensorflow:loss = 0.5692937, step = 5801 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 813.572\n",
            "INFO:tensorflow:loss = 0.023259744, step = 5901 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 799.402\n",
            "INFO:tensorflow:loss = 0.0083758775, step = 6001 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 848.787\n",
            "INFO:tensorflow:loss = 0.085709915, step = 6101 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.033\n",
            "INFO:tensorflow:loss = 0.02548866, step = 6201 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.343\n",
            "INFO:tensorflow:loss = 0.0071445275, step = 6301 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 783.345\n",
            "INFO:tensorflow:loss = 0.015287889, step = 6401 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 845.82\n",
            "INFO:tensorflow:loss = 0.03407672, step = 6501 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 780.228\n",
            "INFO:tensorflow:loss = 0.04485725, step = 6601 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 815.63\n",
            "INFO:tensorflow:loss = 0.078480944, step = 6701 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 863.971\n",
            "INFO:tensorflow:loss = 0.039571702, step = 6801 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 834.986\n",
            "INFO:tensorflow:loss = 0.024734577, step = 6901 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 890.233\n",
            "INFO:tensorflow:loss = 0.020366194, step = 7001 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.913\n",
            "INFO:tensorflow:loss = 0.06916235, step = 7101 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.18\n",
            "INFO:tensorflow:loss = 0.27705577, step = 7201 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 835.95\n",
            "INFO:tensorflow:loss = 0.009063253, step = 7301 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 870.437\n",
            "INFO:tensorflow:loss = 0.008244762, step = 7401 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 778.863\n",
            "INFO:tensorflow:loss = 0.00786128, step = 7501 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 842.524\n",
            "INFO:tensorflow:loss = 0.017301582, step = 7601 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 809.675\n",
            "INFO:tensorflow:loss = 0.0083975475, step = 7701 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.113\n",
            "INFO:tensorflow:loss = 0.008226845, step = 7801 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 861.466\n",
            "INFO:tensorflow:loss = 0.031700086, step = 7901 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 799.831\n",
            "INFO:tensorflow:loss = 0.01685151, step = 8001 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 827.865\n",
            "INFO:tensorflow:loss = 0.008673536, step = 8101 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.392\n",
            "INFO:tensorflow:loss = 0.008396967, step = 8201 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.505\n",
            "INFO:tensorflow:loss = 0.015711244, step = 8301 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 810.501\n",
            "INFO:tensorflow:loss = 0.04645814, step = 8401 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 827.307\n",
            "INFO:tensorflow:loss = 0.00934305, step = 8501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 851.227\n",
            "INFO:tensorflow:loss = 0.016328221, step = 8601 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 828.668\n",
            "INFO:tensorflow:loss = 0.04735887, step = 8701 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 817.857\n",
            "INFO:tensorflow:loss = 0.031951033, step = 8801 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 787.451\n",
            "INFO:tensorflow:loss = 0.007943792, step = 8901 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 851.257\n",
            "INFO:tensorflow:loss = 0.009071605, step = 9001 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 729.156\n",
            "INFO:tensorflow:loss = 0.016434425, step = 9101 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 800.941\n",
            "INFO:tensorflow:loss = 0.021188434, step = 9201 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 820.93\n",
            "INFO:tensorflow:loss = 0.0004653081, step = 9301 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 886.241\n",
            "INFO:tensorflow:loss = 0.034623444, step = 9401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 878.269\n",
            "INFO:tensorflow:loss = 0.030342543, step = 9501 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.542\n",
            "INFO:tensorflow:loss = 0.007984366, step = 9601 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 790.838\n",
            "INFO:tensorflow:loss = 0.0087146815, step = 9701 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 830.669\n",
            "INFO:tensorflow:loss = 0.0007770237, step = 9801 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 863.169\n",
            "INFO:tensorflow:loss = 0.023653109, step = 9901 (0.116 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Cyclist_killed/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.009055298.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Cyclist_killed/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "DNNRegression has RMSE of 0.09711527967872992\n",
            "Just using average = 0.013668267454746953 has RMSE of 0.08585133232873211\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f88855f4110>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Cyclist_killed', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Cyclist_killed/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[0.07594194]\n",
            "[0.07594194]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So95rfeCFFfO"
      },
      "source": [
        "Which returns **[0.07594194]** (essentially ) therefore the model predcts no cyclists would be killed on the 21/11/2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_EluALZFUEz"
      },
      "source": [
        "### Motorists Injured\n",
        "\n",
        "Rather than create models for each, the code will now attempt to look at the number of motorists injured."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-bpDrgXFf3j",
        "outputId": "02473856-caff-4a12-d30c-d4fef9efab90"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhattan = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "\n",
        "# setup predictors\n",
        "# Removing the data fields as the DNN should be able to extract this.  Also exluding the borough field as only dealing with Manhattan\n",
        "predictors_manhattan = shuffle_manhattan.iloc[:,[3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28,29,30,31,32,33,34,35,36]]\n",
        "\n",
        "# Check -1 (for all columns) has worked\n",
        "print(predictors_manhattan[:6])\n",
        "\n",
        "# print first 5 rows of the shuffle\n",
        "print(shuffle_manhattan[:5])\n",
        "\n",
        "# Define the target (the NUM_COLS)\n",
        "target_manhatan = shuffle_manhattan.iloc[:,40]\n",
        "\n",
        "# print the targets\n",
        "print(target_manhatan[:6])\n",
        "\n",
        "# Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "training_size_manhattan = int(len(shuffle_manhattan['MOTO_INJD'] ) *0.8)\n",
        "\n",
        "# The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "testing_size_manhattan = len(shuffle_manhattan['MOTO_INJD']) - training_size_manhattan\n",
        "\n",
        "# Define the number of input values (predictors) - won't be 27, it will not include the borough or date - but should it include the borough?\n",
        "no_predictors = 33\n",
        "\n",
        "# Define the number of output values (targets)\n",
        "no_outputs = 1\n",
        "\n",
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "model_dir = '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Motorists_injured'\n",
        "\n",
        "# remove the last training model - if it is present\n",
        "if os.path.isdir(model_dir):\n",
        "  print(\"\\n// Removing old model directory ....\")\n",
        "  shutil.rmtree(model_dir, ignore_errors=True)\n",
        "else:\n",
        "  print(\"\\n// No model directory to remove ....\")\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(\n",
        "    model_dir=model_dir, \n",
        "    hidden_units=[20,18,14], \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhattan.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Prints a log to show model is starting to train\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator.fit(predictors_manhattan[:training_size_manhattan].values, \n",
        "              target_manhatan[:training_size_manhattan].values.reshape(training_size_manhattan, no_outputs) / SCALE_NUM_COLS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_manhattan[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((target_manhatan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the Life Satisfaction Values.\n",
        "avg = np.mean(shuffle_manhattan['MOTO_INJD'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using Life Satisfaction Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhattan['MOTO_INJD'][training_size_manhattan:] - avg) ** 2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n",
        "\n",
        "# As a test, use something which is known - this case the values for MANHATTAN on the 05/05/2017\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "        {\n",
        "         'Fri': [0],\n",
        "         'Mon': [0],\n",
        "         'Sat': [1],\n",
        "         'Sun': [0],\n",
        "         'Thu': [0],\n",
        "         'Tue': [0],\t\n",
        "         'Wed': [0],\t\n",
        "         'YEAR': [2021],\n",
        "         'Apr': [0],\t\n",
        "         'Aug': [0],\t\n",
        "         'Dec': [0],\t\n",
        "         'Feb': [0],\t\n",
        "         'Jan': [0],\t\n",
        "         'Jul': [0],\t\n",
        "         'Jun': [0],\t\n",
        "         'Mar': [0],\t\n",
        "         'May': [1],\t\n",
        "         'Nov': [0],\t\n",
        "         'Oct': [0],\t\n",
        "         'Sep': [0],\t\n",
        "         'DAY': [4],       \n",
        "         'TEMP' : [52.3],\n",
        "         'DEWP' : [42.2],\n",
        "         'SLP' : [1028.0],\n",
        "         'VISIB' : [10.0],\n",
        "         'WDSP' : [11.3],\n",
        "         'MXPSD' : [14],\n",
        "         'GUST' : [999.9],\n",
        "         'MAX' : [57.9],\n",
        "         'MIN' : [39],\n",
        "         'PRCP' : [0.0],\n",
        "         'SNDP' : [999.9],\n",
        "         'FOG' : [1]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir=model_dir, hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n",
        "print(predslistnorm)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Fri  Mon  Sat  Sun  Thu  Tue  ...   GUST   MAX   MIN  PRCP   SNDP  FOG\n",
            "8716     0    0    1    0    0    0  ...   21.0  55.0  39.0   0.0  999.9    0\n",
            "14878    0    0    0    1    0    0  ...   22.9  75.0  60.1   0.0  999.9    1\n",
            "3067     0    1    0    0    0    0  ...   28.0  46.9  42.1   0.0  999.9    0\n",
            "3735     0    1    0    0    0    0  ...   20.0  37.0  18.0   0.0  999.9    0\n",
            "11695    0    0    0    0    1    0  ...   33.0  30.9  19.0   0.0  999.9    0\n",
            "3360     1    0    0    0    0    0  ...  999.9  78.1  60.1   0.0  999.9    0\n",
            "\n",
            "[6 rows x 33 columns]\n",
            "       Unnamed: 0        DATE    BOROUGH  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "8716         8717  2017-04-09  MANHATTAN  ...          0         21       111\n",
            "14878       14879  06-07-2020  MANHATTAN  ...          0         20        39\n",
            "3067         3068  29-04-2014  MANHATTAN  ...          0         20       123\n",
            "3735         3736  18-03-2014  MANHATTAN  ...          0         22       119\n",
            "11695       11696  23-11-2018  MANHATTAN  ...          0         11        76\n",
            "\n",
            "[5 rows x 46 columns]\n",
            "8716     11\n",
            "14878    13\n",
            "3067     12\n",
            "3735      8\n",
            "11695     7\n",
            "3360     14\n",
            "Name: MOTO_INJD, dtype: int64\n",
            "1.15.2\n",
            "\n",
            "// No model directory to remove ....\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f888af1c150>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Motorists_injured', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Motorists_injured/model.ckpt.\n",
            "INFO:tensorflow:loss = 5119.275, step = 1\n",
            "INFO:tensorflow:global_step/sec: 620.248\n",
            "INFO:tensorflow:loss = 36.492764, step = 101 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 847.296\n",
            "INFO:tensorflow:loss = 33.925278, step = 201 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.619\n",
            "INFO:tensorflow:loss = 33.375023, step = 301 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.191\n",
            "INFO:tensorflow:loss = 35.448368, step = 401 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 803.002\n",
            "INFO:tensorflow:loss = 27.265743, step = 501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 821.01\n",
            "INFO:tensorflow:loss = 27.9385, step = 601 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 841.365\n",
            "INFO:tensorflow:loss = 29.54826, step = 701 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 784.981\n",
            "INFO:tensorflow:loss = 31.034115, step = 801 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 827.615\n",
            "INFO:tensorflow:loss = 24.32766, step = 901 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 851.246\n",
            "INFO:tensorflow:loss = 35.924614, step = 1001 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 917.668\n",
            "INFO:tensorflow:loss = 23.540316, step = 1101 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 801.91\n",
            "INFO:tensorflow:loss = 30.131084, step = 1201 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 740.885\n",
            "INFO:tensorflow:loss = 35.807793, step = 1301 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 807.098\n",
            "INFO:tensorflow:loss = 35.837826, step = 1401 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 883.221\n",
            "INFO:tensorflow:loss = 34.00497, step = 1501 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 776.346\n",
            "INFO:tensorflow:loss = 32.023296, step = 1601 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.663\n",
            "INFO:tensorflow:loss = 30.632767, step = 1701 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.292\n",
            "INFO:tensorflow:loss = 29.257507, step = 1801 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.442\n",
            "INFO:tensorflow:loss = 26.531662, step = 1901 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 877.165\n",
            "INFO:tensorflow:loss = 30.69838, step = 2001 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 775.654\n",
            "INFO:tensorflow:loss = 30.867361, step = 2101 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 802.616\n",
            "INFO:tensorflow:loss = 24.894493, step = 2201 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 806.027\n",
            "INFO:tensorflow:loss = 33.592945, step = 2301 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 840.237\n",
            "INFO:tensorflow:loss = 28.832287, step = 2401 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 817.284\n",
            "INFO:tensorflow:loss = 17.654192, step = 2501 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.617\n",
            "INFO:tensorflow:loss = 35.00626, step = 2601 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 867.16\n",
            "INFO:tensorflow:loss = 28.694069, step = 2701 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 813.799\n",
            "INFO:tensorflow:loss = 25.557425, step = 2801 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 807.255\n",
            "INFO:tensorflow:loss = 20.2344, step = 2901 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 755.056\n",
            "INFO:tensorflow:loss = 32.73295, step = 3001 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 821.153\n",
            "INFO:tensorflow:loss = 24.150642, step = 3101 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 827.002\n",
            "INFO:tensorflow:loss = 26.029087, step = 3201 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 828.017\n",
            "INFO:tensorflow:loss = 27.18024, step = 3301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 877.947\n",
            "INFO:tensorflow:loss = 31.588314, step = 3401 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 897.287\n",
            "INFO:tensorflow:loss = 42.331104, step = 3501 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.628\n",
            "INFO:tensorflow:loss = 32.346397, step = 3601 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 870.128\n",
            "INFO:tensorflow:loss = 32.24021, step = 3701 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 817.852\n",
            "INFO:tensorflow:loss = 27.770914, step = 3801 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.603\n",
            "INFO:tensorflow:loss = 32.642822, step = 3901 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.926\n",
            "INFO:tensorflow:loss = 25.329983, step = 4001 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 779.835\n",
            "INFO:tensorflow:loss = 27.544603, step = 4101 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 842.529\n",
            "INFO:tensorflow:loss = 34.787704, step = 4201 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 797.546\n",
            "INFO:tensorflow:loss = 24.145481, step = 4301 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 881.46\n",
            "INFO:tensorflow:loss = 24.586012, step = 4401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.964\n",
            "INFO:tensorflow:loss = 29.257587, step = 4501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 781.296\n",
            "INFO:tensorflow:loss = 36.882504, step = 4601 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 817.625\n",
            "INFO:tensorflow:loss = 27.277126, step = 4701 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 827.702\n",
            "INFO:tensorflow:loss = 40.13263, step = 4801 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 840.766\n",
            "INFO:tensorflow:loss = 23.88809, step = 4901 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 834.395\n",
            "INFO:tensorflow:loss = 26.76506, step = 5001 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 839.111\n",
            "INFO:tensorflow:loss = 20.001122, step = 5101 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 892.671\n",
            "INFO:tensorflow:loss = 39.51345, step = 5201 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 919.594\n",
            "INFO:tensorflow:loss = 31.649849, step = 5301 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.462\n",
            "INFO:tensorflow:loss = 28.789906, step = 5401 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 769.222\n",
            "INFO:tensorflow:loss = 31.439442, step = 5501 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 802.635\n",
            "INFO:tensorflow:loss = 29.662123, step = 5601 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.643\n",
            "INFO:tensorflow:loss = 29.03213, step = 5701 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 778.044\n",
            "INFO:tensorflow:loss = 27.393435, step = 5801 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.263\n",
            "INFO:tensorflow:loss = 32.238903, step = 5901 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 833.704\n",
            "INFO:tensorflow:loss = 29.497782, step = 6001 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 850.628\n",
            "INFO:tensorflow:loss = 23.326138, step = 6101 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 838.551\n",
            "INFO:tensorflow:loss = 25.835535, step = 6201 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 759.062\n",
            "INFO:tensorflow:loss = 30.729374, step = 6301 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 783.906\n",
            "INFO:tensorflow:loss = 24.021276, step = 6401 (0.126 sec)\n",
            "INFO:tensorflow:global_step/sec: 821.29\n",
            "INFO:tensorflow:loss = 26.435669, step = 6501 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 822.864\n",
            "INFO:tensorflow:loss = 24.792007, step = 6601 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 777.284\n",
            "INFO:tensorflow:loss = 27.77823, step = 6701 (0.128 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.291\n",
            "INFO:tensorflow:loss = 32.707787, step = 6801 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 872\n",
            "INFO:tensorflow:loss = 38.67264, step = 6901 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.969\n",
            "INFO:tensorflow:loss = 31.415672, step = 7001 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.034\n",
            "INFO:tensorflow:loss = 28.711742, step = 7101 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 797.549\n",
            "INFO:tensorflow:loss = 29.898178, step = 7201 (0.125 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.077\n",
            "INFO:tensorflow:loss = 30.253357, step = 7301 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 810.24\n",
            "INFO:tensorflow:loss = 25.066963, step = 7401 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 731.792\n",
            "INFO:tensorflow:loss = 30.958782, step = 7501 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 843.122\n",
            "INFO:tensorflow:loss = 27.585285, step = 7601 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 815.652\n",
            "INFO:tensorflow:loss = 34.601677, step = 7701 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 815.346\n",
            "INFO:tensorflow:loss = 33.181866, step = 7801 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 831.23\n",
            "INFO:tensorflow:loss = 31.70158, step = 7901 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 848.134\n",
            "INFO:tensorflow:loss = 36.71927, step = 8001 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 811.444\n",
            "INFO:tensorflow:loss = 28.465458, step = 8101 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 835.975\n",
            "INFO:tensorflow:loss = 25.574379, step = 8201 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.321\n",
            "INFO:tensorflow:loss = 33.627167, step = 8301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 821.166\n",
            "INFO:tensorflow:loss = 27.70327, step = 8401 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.039\n",
            "INFO:tensorflow:loss = 32.665237, step = 8501 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.209\n",
            "INFO:tensorflow:loss = 27.521978, step = 8601 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.968\n",
            "INFO:tensorflow:loss = 32.86454, step = 8701 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 840.727\n",
            "INFO:tensorflow:loss = 26.226122, step = 8801 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 876.13\n",
            "INFO:tensorflow:loss = 24.716972, step = 8901 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.16\n",
            "INFO:tensorflow:loss = 27.588636, step = 9001 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 769.48\n",
            "INFO:tensorflow:loss = 23.40581, step = 9101 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 746.614\n",
            "INFO:tensorflow:loss = 30.625843, step = 9201 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 841.397\n",
            "INFO:tensorflow:loss = 24.405342, step = 9301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 881.931\n",
            "INFO:tensorflow:loss = 24.50215, step = 9401 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 849.096\n",
            "INFO:tensorflow:loss = 27.549377, step = 9501 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 791.032\n",
            "INFO:tensorflow:loss = 36.945175, step = 9601 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 774.235\n",
            "INFO:tensorflow:loss = 32.231342, step = 9701 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 728.073\n",
            "INFO:tensorflow:loss = 22.967628, step = 9801 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.375\n",
            "INFO:tensorflow:loss = 34.38434, step = 9901 (0.119 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Motorists_injured/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 31.664942.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Motorists_injured/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "DNNRegression has RMSE of 9.557851214337683\n",
            "Just using average = 11.592537864794975 has RMSE of 5.500738768591871\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f888ad80910>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Motorists_injured', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model_Motorists_injured/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[10.064178]\n",
            "[10.064178]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyCVP__qGlkW"
      },
      "source": [
        "The model predicts 10 motorists would be injured in the accidents on that day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMnV5BCbhnJw"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "This notebook has attemted to document the creation of both a linear and a DNN regressor using TensorFlow."
      ]
    }
  ]
}