{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J_Adams_Assignment_Part_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2YM-cY3XAb1"
      },
      "source": [
        "# Training a linear regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4OkOIjgXImQ"
      },
      "source": [
        "### Background\n",
        "\n",
        "The dataset which was created for part 1 has been constructed so that each borough can be identified.  This means that a linear regressor could be made for each indivual borough.  As the code uses the dataset with the same structure, what works for one, would work for all.  However, in order to simplifiy this notebook, only one borough will be used.  That borough is Manhatten.\n",
        "\n",
        "To begin with, the data must first be loaded.  Once loaded, using the query method of the pandas dataframe the rows which are in Mahattan can be extracted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUkPRKJw1mm6"
      },
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load the data as per normal\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv', index_col=0)\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv')\n",
        "\n",
        "# now setup to query the dataframe for only the boroughs noted\n",
        "manhat_df = df.query('BOROUGH==\"MANHATTAN\"').head()\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYJbRFX5YExF"
      },
      "source": [
        "#### Data Verification\n",
        "\n",
        "Once the data has been loaded, it is a good idea to check this.  Printing only 6 rows shows that all are Manhattan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNzPMAL314nG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1457a9ec-8793-4108-e085-9db7b6e71683"
      },
      "source": [
        "# check the data had loaded by printing it\n",
        "print(manhat_df[:6])\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "0   2012-08-21  MANHATTAN        2  ...          0         28       109\n",
            "6   2012-10-27  MANHATTAN        6  ...          0         20       122\n",
            "13  2012-08-25  MANHATTAN        6  ...          0         22        97\n",
            "16  2012-09-09  MANHATTAN        7  ...          0         29       109\n",
            "20  2012-09-17  MANHATTAN        1  ...          1         27       123\n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSW7NtK4dBAj"
      },
      "source": [
        "## Import numpy and shuffle\n",
        "\n",
        "Create a new shuffled data by using the random permutation function of numpy using the length of the original mahattan data frame.  In this particular data set this is important as the data is time series (or time series derived) and there could be patterns within the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-NlRVds2BEM"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "shuffle_manhatten = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "shuffle_manhatten[:5]\n",
        "\n",
        "# setup constant for use later\n",
        "SCALE_NUM_COLS = 1"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFG25By8dtfc"
      },
      "source": [
        "## Predictors, Training set and Testing set\n",
        "\n",
        "Firstly the predictors are created.  These are created from the shuffled data and only the third, fourth, fifth, seventh and last column is used.  These are, in order, year, month, day, temp and num_cols (number of collisions).  If the data was not being filtered by borough at the start, then the borough would need to be brought in also.\n",
        "\n",
        "The Target is then defined - this is the last column in the shuffled dataset.\n",
        "\n",
        "The training set will be 80% of the full data set (0.8) and the testing data will be the remainder - so in this case, 100 - 80 = 20%\n",
        "\n",
        "Constants are setup for the number of predictors (3 in this case: year, month and day) and the number of outputs (or targets, which is 1 here.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01AcNdrBh3o"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[3,4,5,7,-1]]\n",
        "\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month and year = 3 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 4\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9cyW1wjfAIk"
      },
      "source": [
        "### Verification\n",
        "\n",
        "Just a simple print to ensure the predictor and values are populated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYOnh5yUElQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8701ecd6-fe06-40ae-d493-811778250b2e"
      },
      "source": [
        "print(predictors_manhatten.values)\n",
        "print(predictors_manhatten)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2012.     9.    17.    66.5  123. ]\n",
            " [2012.     8.    25.    75.7   97. ]\n",
            " [2012.     8.    21.    72.8  109. ]\n",
            " [2012.    10.    27.    61.9  122. ]\n",
            " [2012.     9.     9.    68.4  109. ]]\n",
            "    YEAR  MONTH  DAY  TEMP  NUM_COLS\n",
            "20  2012      9   17  66.5       123\n",
            "13  2012      8   25  75.7        97\n",
            "0   2012      8   21  72.8       109\n",
            "6   2012     10   27  61.9       122\n",
            "16  2012      9    9  68.4       109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axySTDY1fKHw"
      },
      "source": [
        "## THe Tensorflow bit.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIj_sLztBlsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a75823-5be0-4978-fe96-b58f892f552e"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model'\n",
        "\n",
        "# remove the last training model\n",
        "shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    hidden_units=[20,18,14], \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan, \n",
        "    NO_TARGETS)/SCALE_NUM_COLS, \n",
        "    steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale)**2))\n",
        "print('// DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg)**2))\n",
        "print('// Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f92a92d1e10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "// Starting to train Manhattan model............\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 15237.231, step = 1\n",
            "INFO:tensorflow:global_step/sec: 507.215\n",
            "INFO:tensorflow:loss = 65.83978, step = 101 (0.204 sec)\n",
            "INFO:tensorflow:global_step/sec: 702.121\n",
            "INFO:tensorflow:loss = 49.85949, step = 201 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.531\n",
            "INFO:tensorflow:loss = 34.09765, step = 301 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 700.968\n",
            "INFO:tensorflow:loss = 20.941723, step = 401 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 739.659\n",
            "INFO:tensorflow:loss = 11.147496, step = 501 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.291\n",
            "INFO:tensorflow:loss = 4.6439013, step = 601 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 632.545\n",
            "INFO:tensorflow:loss = 5.747966, step = 701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.59\n",
            "INFO:tensorflow:loss = 0.99155885, step = 801 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.936\n",
            "INFO:tensorflow:loss = 23.212008, step = 901 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.893\n",
            "INFO:tensorflow:loss = 15.905375, step = 1001 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.86\n",
            "INFO:tensorflow:loss = 0.32650876, step = 1101 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.402\n",
            "INFO:tensorflow:loss = 0.007576381, step = 1201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 650.727\n",
            "INFO:tensorflow:loss = 36.056267, step = 1301 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.55\n",
            "INFO:tensorflow:loss = 0.25747415, step = 1401 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.646\n",
            "INFO:tensorflow:loss = 0.018242784, step = 1501 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.523\n",
            "INFO:tensorflow:loss = 0.10058913, step = 1601 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 677.714\n",
            "INFO:tensorflow:loss = 4.5114975, step = 1701 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.936\n",
            "INFO:tensorflow:loss = 0.003709134, step = 1801 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 629.136\n",
            "INFO:tensorflow:loss = 0.001493158, step = 1901 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.516\n",
            "INFO:tensorflow:loss = 0.0009011773, step = 2001 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 690.581\n",
            "INFO:tensorflow:loss = 0.0005411788, step = 2101 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.115\n",
            "INFO:tensorflow:loss = 16.393923, step = 2201 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 607.228\n",
            "INFO:tensorflow:loss = 1.1177737, step = 2301 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 678.847\n",
            "INFO:tensorflow:loss = 0.21507758, step = 2401 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 695.089\n",
            "INFO:tensorflow:loss = 0.03745785, step = 2501 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.604\n",
            "INFO:tensorflow:loss = 0.18601257, step = 2601 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 647.535\n",
            "INFO:tensorflow:loss = 0.014575459, step = 2701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.961\n",
            "INFO:tensorflow:loss = 0.0034065393, step = 2801 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 708.314\n",
            "INFO:tensorflow:loss = 0.050321892, step = 2901 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 630.024\n",
            "INFO:tensorflow:loss = 0.0018372403, step = 3001 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.617\n",
            "INFO:tensorflow:loss = 0.00028332887, step = 3101 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.18\n",
            "INFO:tensorflow:loss = 0.00013422153, step = 3201 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.253\n",
            "INFO:tensorflow:loss = 6.121307e-05, step = 3301 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.203\n",
            "INFO:tensorflow:loss = 2.7418006e-05, step = 3401 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 613.934\n",
            "INFO:tensorflow:loss = 21.921232, step = 3501 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.434\n",
            "INFO:tensorflow:loss = 2.6191936, step = 3601 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 703.361\n",
            "INFO:tensorflow:loss = 0.3416499, step = 3701 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.163\n",
            "INFO:tensorflow:loss = 0.06427182, step = 3801 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 680.37\n",
            "INFO:tensorflow:loss = 0.010781165, step = 3901 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.95\n",
            "INFO:tensorflow:loss = 0.002552888, step = 4001 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 588.532\n",
            "INFO:tensorflow:loss = 0.0014832707, step = 4101 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 696.277\n",
            "INFO:tensorflow:loss = 0.0013574556, step = 4201 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.206\n",
            "INFO:tensorflow:loss = 0.0013370216, step = 4301 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 690.494\n",
            "INFO:tensorflow:loss = 0.001326276, step = 4401 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 644.889\n",
            "INFO:tensorflow:loss = 0.0013163846, step = 4501 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.007\n",
            "INFO:tensorflow:loss = 0.0013065448, step = 4601 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 602.322\n",
            "INFO:tensorflow:loss = 0.0012980622, step = 4701 (0.165 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.965\n",
            "INFO:tensorflow:loss = 0.1116185, step = 4801 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.513\n",
            "INFO:tensorflow:loss = 0.0021399169, step = 4901 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.95\n",
            "INFO:tensorflow:loss = 0.03338318, step = 5001 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 652.278\n",
            "INFO:tensorflow:loss = 0.009495071, step = 5101 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.922\n",
            "INFO:tensorflow:loss = 0.0014836123, step = 5201 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 683.933\n",
            "INFO:tensorflow:loss = 2.054638, step = 5301 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.278\n",
            "INFO:tensorflow:loss = 0.004240999, step = 5401 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 659.568\n",
            "INFO:tensorflow:loss = 0.0013498779, step = 5501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 663.651\n",
            "INFO:tensorflow:loss = 1.563147, step = 5601 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 617.214\n",
            "INFO:tensorflow:loss = 0.0028211325, step = 5701 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.761\n",
            "INFO:tensorflow:loss = 0.001274664, step = 5801 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 702.656\n",
            "INFO:tensorflow:loss = 0.071437776, step = 5901 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.543\n",
            "INFO:tensorflow:loss = 0.0019116824, step = 6001 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 625.702\n",
            "INFO:tensorflow:loss = 0.0012323072, step = 6101 (0.158 sec)\n",
            "INFO:tensorflow:global_step/sec: 649.87\n",
            "INFO:tensorflow:loss = 0.111694105, step = 6201 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 697.77\n",
            "INFO:tensorflow:loss = 0.0016388001, step = 6301 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 679.563\n",
            "INFO:tensorflow:loss = 0.0012353405, step = 6401 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 677.075\n",
            "INFO:tensorflow:loss = 0.007654571, step = 6501 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.831\n",
            "INFO:tensorflow:loss = 0.0013870787, step = 6601 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.688\n",
            "INFO:tensorflow:loss = 33.550713, step = 6701 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 687.785\n",
            "INFO:tensorflow:loss = 0.003733363, step = 6801 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 697.604\n",
            "INFO:tensorflow:loss = 0.0012619353, step = 6901 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.584\n",
            "INFO:tensorflow:loss = 0.5066774, step = 7001 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.618\n",
            "INFO:tensorflow:loss = 0.0066182963, step = 7101 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 653.333\n",
            "INFO:tensorflow:loss = 0.4575506, step = 7201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 710.482\n",
            "INFO:tensorflow:loss = 0.0013463597, step = 7301 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 623.768\n",
            "INFO:tensorflow:loss = 1.0657308, step = 7401 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 680.268\n",
            "INFO:tensorflow:loss = 0.001395286, step = 7501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 577.227\n",
            "INFO:tensorflow:loss = 15.322344, step = 7601 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 706.887\n",
            "INFO:tensorflow:loss = 0.0024628728, step = 7701 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.736\n",
            "INFO:tensorflow:loss = 0.0011428468, step = 7801 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.124\n",
            "INFO:tensorflow:loss = 0.051249772, step = 7901 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 681.334\n",
            "INFO:tensorflow:loss = 0.0012029604, step = 8001 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 626.346\n",
            "INFO:tensorflow:loss = 239.20389, step = 8101 (0.163 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.717\n",
            "INFO:tensorflow:loss = 1.0375758, step = 8201 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 691.973\n",
            "INFO:tensorflow:loss = 0.0031193784, step = 8301 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 663.558\n",
            "INFO:tensorflow:loss = 0.0052819275, step = 8401 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 707.44\n",
            "INFO:tensorflow:loss = 0.0025703355, step = 8501 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 627.233\n",
            "INFO:tensorflow:loss = 0.0055000987, step = 8601 (0.164 sec)\n",
            "INFO:tensorflow:global_step/sec: 663.204\n",
            "INFO:tensorflow:loss = 0.0022390657, step = 8701 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 618.07\n",
            "INFO:tensorflow:loss = 0.00278, step = 8801 (0.162 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.618\n",
            "INFO:tensorflow:loss = 0.008799015, step = 8901 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 628.329\n",
            "INFO:tensorflow:loss = 0.0022903213, step = 9001 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 551.101\n",
            "INFO:tensorflow:loss = 0.0021080622, step = 9101 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 690.66\n",
            "INFO:tensorflow:loss = 0.736367, step = 9201 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 685.523\n",
            "INFO:tensorflow:loss = 0.0026061859, step = 9301 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.141\n",
            "INFO:tensorflow:loss = 0.0021056277, step = 9401 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.172\n",
            "INFO:tensorflow:loss = 0.8764621, step = 9501 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.723\n",
            "INFO:tensorflow:loss = 0.0026183317, step = 9601 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 673.384\n",
            "INFO:tensorflow:loss = 0.0020798724, step = 9701 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 641.612\n",
            "INFO:tensorflow:loss = 0.18948978, step = 9801 (0.160 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.155\n",
            "INFO:tensorflow:loss = 0.0024735504, step = 9901 (0.150 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0020537102.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "DNNRegression has RMSE of 0.38750457763671875\n",
            "Just using average = 109.5 has RMSE of 12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZjS3zTafVMB8",
        "outputId": "0f67f0a7-ae05-4178-be1a-c7be762443ec"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'DAY' : [1,1,1],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'YEAR' : [2013, 2016, 2022]\n",
        "        })\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model', enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "# Assume number of trips scale value is 600000 when at a maximum, based on the analysis from Tutorial 2\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores']*600000\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f92ab922f10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key linear//weight not found in checkpoint\n\t [[{{node save/RestoreV2}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1290\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1291\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key linear//weight not found in checkpoint\n\t [[node save/RestoreV2 (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-44-2ef5a217c02d>\", line 9, in <module>\n    preds = estimator_manhattan.predict(x=input.values)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py\", line 1567, in predict\n    iterate_batches=True))\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py\", line 974, in _infer_model\n    config=self._session_config))\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 1014, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 725, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 1207, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 1212, in _create_session\n    return self._sess_creator.create_session()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 878, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 638, in create_session\n    self._scaffold.finalize()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 229, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 599, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 502, in _build_internal\n    restore_sequentially, reshape)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 381, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1299\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1617\u001b[0m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m   \u001b[0mobject_graph_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader_GetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-2ef5a217c02d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mestimator_manhattan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSKCompat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/tmp/linear_regression_trained_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_centered_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_real_valued_columns_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator_manhattan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# Assume number of trips scale value is 600000 when at a maximum, based on the analysis from Tutorial 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpredslistnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, outputs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mas_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m             iterate_batches=True))\n\u001b[0m\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_infer_model\u001b[0;34m(self, input_fn, feed_fn, outputs, as_iterable, iterate_batches)\u001b[0m\n\u001b[1;32m    972\u001b[0m               \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m               \u001b[0mscaffold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfer_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaffold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m               config=self._session_config))\n\u001b[0m\u001b[1;32m    975\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mas_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    723\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \"\"\"\n\u001b[1;32m   1206\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         logging.info(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[0;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         config=config)\n\u001b[0m\u001b[1;32m    291\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_loaded_from_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_init_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/session_manager.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1306\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey linear//weight not found in checkpoint\n\t [[node save/RestoreV2 (defined at /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-44-2ef5a217c02d>\", line 9, in <module>\n    preds = estimator_manhattan.predict(x=input.values)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py\", line 1567, in predict\n    iterate_batches=True))\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py\", line 974, in _infer_model\n    config=self._session_config))\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 1014, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 725, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 1207, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 1212, in _create_session\n    return self._sess_creator.create_session()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 878, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 638, in create_session\n    self._scaffold.finalize()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/monitored_session.py\", line 229, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 599, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 502, in _build_internal\n    restore_sequentially, reshape)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 381, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    }
  ]
}