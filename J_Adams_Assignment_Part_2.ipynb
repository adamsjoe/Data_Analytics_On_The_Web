{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J_Adams_Assignment_Part_2--.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2YM-cY3XAb1"
      },
      "source": [
        "# Training a linear regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4OkOIjgXImQ"
      },
      "source": [
        "### Background\n",
        "\n",
        "The dataset which was created for part 1 has been constructed so that each borough can be identified.  This means that a linear regressor could be made for each indivual borough.  As the code uses the dataset with the same structure, what works for one, would work for all.  However, in order to simplifiy this notebook, only one borough will be used.  That borough is **Manhatten**.\n",
        "\n",
        "To begin with, the data must first be loaded.  Once loaded, using the query method of the pandas dataframe the rows which are in Mahattan can be extracted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUkPRKJw1mm6"
      },
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load the data as per normal\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv', index_col=0)\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv')\n",
        "\n",
        "# now setup to query the dataframe for only the borough noted\n",
        "borough_df = df.query('BOROUGH==\"MANHATTAN\"')\n",
        "\n",
        "# ignore this for now\n",
        "# remove 2012\n",
        "remove_2012 = borough_df.query('YEAR!=2012')\n",
        "\n",
        "# remove 2020\n",
        "remove_2020 = remove_2012.query('YEAR!=2020')\n",
        "\n",
        "#remove 2021\n",
        "remove_2021 = remove_2020.query('YEAR!=2021')\n",
        "\n",
        "# make a new dataframe, which by now shall only contain data for Manhattan in the years 2013 to 2019\n",
        "manhat_df = remove_2021\n",
        "\n",
        "year_2013 = manhat_df.query(\"YEAR==2013\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYJbRFX5YExF"
      },
      "source": [
        "#### Data Verification\n",
        "\n",
        "Once the data has been loaded, it is a good idea to check this.  Printing only 6 rows shows that all are Manhattan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNzPMAL314nG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33adc1b-0447-4805-c914-1297f14c2ee1"
      },
      "source": [
        "# check the data had loaded by printing it\n",
        "print(manhat_df[:6])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "924  04-02-2013  MANHATTAN        1  ...          0         14        93\n",
            "929  19-01-2013  MANHATTAN        6  ...          0         19       108\n",
            "931  24-01-2013  MANHATTAN        4  ...          0         31       125\n",
            "936  24-05-2013  MANHATTAN        5  ...          0         41       153\n",
            "941  24-04-2013  MANHATTAN        3  ...          1         21       117\n",
            "946  07-03-2013  MANHATTAN        4  ...          0         18       110\n",
            "\n",
            "[6 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSW7NtK4dBAj"
      },
      "source": [
        "## Import numpy and shuffle\n",
        "\n",
        "Create a new shuffled data by using the random permutation function of numpy using the length of the original mahattan data frame.  In this particular data set this is important as the data is time series (or time series derived) and there could be patterns within the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-NlRVds2BEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde9c512-0fa9-486a-9a91-799e47a07b22"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhatten = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "print(shuffle_manhatten[:5])\n",
        "\n",
        "# setup constant for use later\n",
        "SCALE_NUM_COLS = 1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "941    24-04-2013  MANHATTAN        3  ...          1         21       117\n",
            "4916   10-02-2015  MANHATTAN        2  ...          0         15       116\n",
            "11328  30-08-2018  MANHATTAN        4  ...          0         24       127\n",
            "1364   06-05-2013  MANHATTAN        1  ...          0         25       122\n",
            "12958  28-12-2019  MANHATTAN        6  ...          0         11        58\n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFG25By8dtfc"
      },
      "source": [
        "## Predictors, Training set and Testing set\n",
        "\n",
        "Firstly the predictors are created.  These are created from the shuffled data and only the third, fourth, fifth, seventh and last column is used.  These are, in order, year, month, day, temp and num_cols (number of collisions).  If the data was not being filtered by borough at the start, then the borough would need to be brought in also.\n",
        "\n",
        "The Target is then defined - this is the last column in the shuffled dataset.\n",
        "\n",
        "The training set will be 80% of the full data set (0.8) and the testing data will be the remainder - so in this case, 100 - 80 = 20%\n",
        "\n",
        "Constants are setup for the number of predictors (3 in this case: year, month and day) and the number of outputs (or targets, which is 1 here.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01AcNdrBh3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "229b280c-61f2-48c8-b1f9-2309f76d015a"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[3,4,5]]\n",
        "print(predictors_manhatten[:6])\n",
        "\n",
        "# We want the last column (the NUM_COLS)\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "print(targets_manhattan[:6])\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month and year = 3 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 3\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       YEAR  MONTH  DAY\n",
            "941    2013      4   24\n",
            "4916   2015      2   10\n",
            "11328  2018      8   30\n",
            "1364   2013      5    6\n",
            "12958  2019     12   28\n",
            "10554  2018      8   25\n",
            "941      117\n",
            "4916     116\n",
            "11328    127\n",
            "1364     122\n",
            "12958     58\n",
            "10554     86\n",
            "Name: NUM_COLS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9cyW1wjfAIk"
      },
      "source": [
        "### Verification\n",
        "\n",
        "Just a simple print to ensure the predictor and values are populated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYOnh5yUElQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c120de-5db2-441b-a860-43fa32b89d93"
      },
      "source": [
        "print(predictors_manhatten.values)\n",
        "print(predictors_manhatten)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2013    4   24]\n",
            " [2015    2   10]\n",
            " [2018    8   30]\n",
            " ...\n",
            " [2016    1    9]\n",
            " [2015    6   19]\n",
            " [2018   10   24]]\n",
            "       YEAR  MONTH  DAY\n",
            "941    2013      4   24\n",
            "4916   2015      2   10\n",
            "11328  2018      8   30\n",
            "1364   2013      5    6\n",
            "12958  2019     12   28\n",
            "...     ...    ...  ...\n",
            "9812   2017     11   14\n",
            "12578  2019      8   21\n",
            "7483   2016      1    9\n",
            "5247   2015      6   19\n",
            "11731  2018     10   24\n",
            "\n",
            "[2556 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axySTDY1fKHw"
      },
      "source": [
        "## The Tensorflow bit.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIj_sLztBlsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "800b2059-c015-4d6f-83e5-fc94dfda1f0d"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model'\n",
        "\n",
        "# remove the last training model - if it is present\n",
        "if os.path.isdir(manhattan_dir):\n",
        "  print(\"\\n// Removing old model directory ....\")\n",
        "  shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "else:\n",
        "  print(\"\\n// No model directory to remove ....\")\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.1), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\\n\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan,NO_TARGETS)/SCALE_NUM_COLS, steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - predslistscale)**2))\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('\\n\\n// Lnear Regression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('\\n\\n// Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "\n",
            "// No model directory to remove ....\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-6-9488ecbb1cd5>:28: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please convert numpy dtypes explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/linear.py:740: regression_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.contrib.estimator.*_head.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f78496acb10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:From <ipython-input-6-9488ecbb1cd5>:28: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to the Estimator interface.\n",
            "// Starting to train Manhattan model............\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 14762.602, step = 1\n",
            "INFO:tensorflow:global_step/sec: 842.682\n",
            "INFO:tensorflow:loss = 629.393, step = 101 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 1015.45\n",
            "INFO:tensorflow:loss = 755.7883, step = 201 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 915.11\n",
            "INFO:tensorflow:loss = 903.7566, step = 301 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 969.111\n",
            "INFO:tensorflow:loss = 704.24, step = 401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.815\n",
            "INFO:tensorflow:loss = 845.8783, step = 501 (0.103 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 501 vs previous value: 501. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 981.594\n",
            "INFO:tensorflow:loss = 652.1168, step = 601 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.218\n",
            "INFO:tensorflow:loss = 806.68024, step = 701 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1002.51\n",
            "INFO:tensorflow:loss = 750.968, step = 801 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1033.29\n",
            "INFO:tensorflow:loss = 656.5027, step = 901 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 935.368\n",
            "INFO:tensorflow:loss = 905.1747, step = 1001 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 971.867\n",
            "INFO:tensorflow:loss = 702.381, step = 1101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.175\n",
            "INFO:tensorflow:loss = 742.8661, step = 1201 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.104\n",
            "INFO:tensorflow:loss = 907.5992, step = 1301 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 840.368\n",
            "INFO:tensorflow:loss = 870.23645, step = 1401 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.989\n",
            "INFO:tensorflow:loss = 509.0074, step = 1501 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 824.377\n",
            "INFO:tensorflow:loss = 731.32587, step = 1601 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.617\n",
            "INFO:tensorflow:loss = 605.4393, step = 1701 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 902.954\n",
            "INFO:tensorflow:loss = 767.6675, step = 1801 (0.109 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1801 vs previous value: 1801. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 950.4\n",
            "INFO:tensorflow:loss = 748.6507, step = 1901 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.432\n",
            "INFO:tensorflow:loss = 515.9198, step = 2001 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1031.99\n",
            "INFO:tensorflow:loss = 527.41675, step = 2101 (0.098 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2194 vs previous value: 2194. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 913.955\n",
            "INFO:tensorflow:loss = 695.7865, step = 2201 (0.109 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2201 vs previous value: 2201. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 900.672\n",
            "INFO:tensorflow:loss = 741.2113, step = 2301 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 927.699\n",
            "INFO:tensorflow:loss = 666.5209, step = 2401 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 917.454\n",
            "INFO:tensorflow:loss = 569.07513, step = 2501 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 932.646\n",
            "INFO:tensorflow:loss = 705.4353, step = 2601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.749\n",
            "INFO:tensorflow:loss = 652.5769, step = 2701 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 1048.08\n",
            "INFO:tensorflow:loss = 783.71045, step = 2801 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.404\n",
            "INFO:tensorflow:loss = 916.8384, step = 2901 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 977.333\n",
            "INFO:tensorflow:loss = 659.28436, step = 3001 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1018.81\n",
            "INFO:tensorflow:loss = 818.3142, step = 3101 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 951.782\n",
            "INFO:tensorflow:loss = 644.04315, step = 3201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 977.299\n",
            "INFO:tensorflow:loss = 723.4606, step = 3301 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1008.28\n",
            "INFO:tensorflow:loss = 795.34937, step = 3401 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 969.49\n",
            "INFO:tensorflow:loss = 735.2826, step = 3501 (0.107 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3501 vs previous value: 3501. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 847.85\n",
            "INFO:tensorflow:loss = 560.96783, step = 3601 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.13\n",
            "INFO:tensorflow:loss = 878.7563, step = 3701 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.854\n",
            "INFO:tensorflow:loss = 614.2926, step = 3801 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 968.632\n",
            "INFO:tensorflow:loss = 735.8584, step = 3901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.11\n",
            "INFO:tensorflow:loss = 797.32605, step = 4001 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.16\n",
            "INFO:tensorflow:loss = 630.62415, step = 4101 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 864.855\n",
            "INFO:tensorflow:loss = 613.0751, step = 4201 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 990.779\n",
            "INFO:tensorflow:loss = 623.46185, step = 4301 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 857.577\n",
            "INFO:tensorflow:loss = 907.3392, step = 4401 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.68\n",
            "INFO:tensorflow:loss = 718.8444, step = 4501 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.39\n",
            "INFO:tensorflow:loss = 702.4252, step = 4601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 925.65\n",
            "INFO:tensorflow:loss = 699.14136, step = 4701 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.38\n",
            "INFO:tensorflow:loss = 617.1759, step = 4801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 909.186\n",
            "INFO:tensorflow:loss = 752.86554, step = 4901 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1040.97\n",
            "INFO:tensorflow:loss = 982.65686, step = 5001 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 919.731\n",
            "INFO:tensorflow:loss = 980.2146, step = 5101 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1057.17\n",
            "INFO:tensorflow:loss = 751.1383, step = 5201 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 971.923\n",
            "INFO:tensorflow:loss = 730.8425, step = 5301 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.91\n",
            "INFO:tensorflow:loss = 650.67426, step = 5401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 999.744\n",
            "INFO:tensorflow:loss = 1194.6614, step = 5501 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.44\n",
            "INFO:tensorflow:loss = 862.20154, step = 5601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 954.479\n",
            "INFO:tensorflow:loss = 696.7798, step = 5701 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.718\n",
            "INFO:tensorflow:loss = 651.5758, step = 5801 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 977.345\n",
            "INFO:tensorflow:loss = 804.869, step = 5901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1004.65\n",
            "INFO:tensorflow:loss = 869.26514, step = 6001 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 910.999\n",
            "INFO:tensorflow:loss = 1066.1659, step = 6101 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.932\n",
            "INFO:tensorflow:loss = 673.53455, step = 6201 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.227\n",
            "INFO:tensorflow:loss = 941.0093, step = 6301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 977.723\n",
            "INFO:tensorflow:loss = 756.3241, step = 6401 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 959.047\n",
            "INFO:tensorflow:loss = 543.5305, step = 6501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 996.861\n",
            "INFO:tensorflow:loss = 794.4685, step = 6601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.601\n",
            "INFO:tensorflow:loss = 658.7626, step = 6701 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 957.956\n",
            "INFO:tensorflow:loss = 581.8423, step = 6801 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 974.248\n",
            "INFO:tensorflow:loss = 704.4842, step = 6901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 981.93\n",
            "INFO:tensorflow:loss = 822.51416, step = 7001 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.945\n",
            "INFO:tensorflow:loss = 733.45984, step = 7101 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.458\n",
            "INFO:tensorflow:loss = 678.4849, step = 7201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 951.67\n",
            "INFO:tensorflow:loss = 682.2364, step = 7301 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 891.713\n",
            "INFO:tensorflow:loss = 738.4684, step = 7401 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 1005.07\n",
            "INFO:tensorflow:loss = 722.0895, step = 7501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.442\n",
            "INFO:tensorflow:loss = 1125.8451, step = 7601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 963.94\n",
            "INFO:tensorflow:loss = 698.1316, step = 7701 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.106\n",
            "INFO:tensorflow:loss = 661.0985, step = 7801 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 976.101\n",
            "INFO:tensorflow:loss = 940.7504, step = 7901 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.517\n",
            "INFO:tensorflow:loss = 661.16113, step = 8001 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.521\n",
            "INFO:tensorflow:loss = 686.74756, step = 8101 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.482\n",
            "INFO:tensorflow:loss = 591.8878, step = 8201 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.904\n",
            "INFO:tensorflow:loss = 867.1627, step = 8301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.915\n",
            "INFO:tensorflow:loss = 692.83264, step = 8401 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 881.306\n",
            "INFO:tensorflow:loss = 892.45593, step = 8501 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 935.064\n",
            "INFO:tensorflow:loss = 750.0399, step = 8601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.912\n",
            "INFO:tensorflow:loss = 861.8292, step = 8701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1013.93\n",
            "INFO:tensorflow:loss = 669.5449, step = 8801 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.77\n",
            "INFO:tensorflow:loss = 849.7454, step = 8901 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 923.491\n",
            "INFO:tensorflow:loss = 734.7668, step = 9001 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.574\n",
            "INFO:tensorflow:loss = 1033.0925, step = 9101 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.306\n",
            "INFO:tensorflow:loss = 806.9807, step = 9201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 969.221\n",
            "INFO:tensorflow:loss = 762.0518, step = 9301 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.822\n",
            "INFO:tensorflow:loss = 839.7376, step = 9401 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1021.94\n",
            "INFO:tensorflow:loss = 935.3286, step = 9501 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.623\n",
            "INFO:tensorflow:loss = 707.73804, step = 9601 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1033.88\n",
            "INFO:tensorflow:loss = 721.7951, step = 9701 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 999.741\n",
            "INFO:tensorflow:loss = 758.5647, step = 9801 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1033.03\n",
            "INFO:tensorflow:loss = 824.7234, step = 9901 (0.096 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1189.3518.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "// Lnear Regression has RMSE of 24.734756683528197\n",
            "\n",
            "\n",
            "// Just using average = 120.6771037181996 has RMSE of 24.94511498186387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t23ehycblB5R"
      },
      "source": [
        "## Initial Output\n",
        "\n",
        "The RSME is quite large, which would indicate a not accurate model - however this model is only trying to predict based on a day.  Not using any extra conditions.  Temperature could be added in and this may affect the the output.\n",
        "\n",
        "The model needs to be tested first, to do this some values will be fed in to be the target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pizTrw7Aks8S"
      },
      "source": [
        "## Inital Prediction\n",
        "\n",
        "```python\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'DAY' : [1, 1, 1]\n",
        "        })\n",
        "\n",
        "```\n",
        "\n",
        "Setting up the values for preduction, 3 have been chosen.  1/1/2013, 1/6/2016 and 1.12/2022 will be fed into model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjS3zTafVMB8",
        "outputId": "0e1199a2-1f94-4718-c9a9-8e2130eb9592"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'DAY' : [1, 1, 1]\n",
        "        })\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)\n",
        "                                                                                 )\n",
        ")\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 1.0\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f789f62c410>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[112.72989 119.20929 127.11712]\n",
            "[112.72989 119.20929 127.11712]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hnzo1hOFa-l"
      },
      "source": [
        "### Result of First Run\n",
        "\n",
        "The output (at the time of writing) was \n",
        "\n",
        "[117.42061  123.957085 131.939   ]\n",
        "\n",
        "The model is being asked to predict 3 dates.  Two of these dates are known, these can be used as \"control\" dates - the number of collisions is known - so these should be fairly accurate (or at least, that is the theory...)\n",
        "\n",
        "The dates are:\n",
        "\n",
        "Date|Prediction|Actual\n",
        ":--:|:--------:|:----:\n",
        "1/1/2013|117|78\n",
        "1/6/2016|123|121\n",
        "1/12/2020|131|N/A\n",
        "\n",
        "While the trend is, generally, going upwards, which does **sort of** look ok.. As noted above, it would be a good idea to try to add in an additional predictor.  The Temp value should suffice.\n",
        "\n",
        "**Note** these values may change if the notebook is run at a later stage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65w8sb15lZj3"
      },
      "source": [
        "## Adding in Temp\n",
        "\n",
        "The code cells will be copied from above, this time the predictors will be ammeded to include temperature.\n",
        "\n",
        "**Note:** For brevity, the additional prints will not be inluded and all code will be added to the one cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxd35_S4ln2-",
        "outputId": "a48a5924-0a9d-4a26-a6fb-8d1f11007468"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[3,4,5,7]]\n",
        "print(predictors_manhatten[:6])\n",
        "\n",
        "# We want the last column (the NUM_COLS)\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "print(targets_manhattan[:6])\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month, year and now temp = 4 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 4\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model_including_temp'\n",
        "\n",
        "# remove the last training model\n",
        "shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.1), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\\n\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan,NO_TARGETS)/SCALE_NUM_COLS, steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - predslistscale)**2))\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('\\n\\n// Lnear Regression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('\\n\\n// Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       YEAR  MONTH  DAY  TEMP\n",
            "941    2013      4   24  47.5\n",
            "4916   2015      2   10  36.4\n",
            "11328  2018      8   30  76.2\n",
            "1364   2013      5    6  49.2\n",
            "12958  2019     12   28  44.5\n",
            "10554  2018      8   25  66.5\n",
            "941      117\n",
            "4916     116\n",
            "11328    127\n",
            "1364     122\n",
            "12958     58\n",
            "10554     86\n",
            "Name: NUM_COLS, dtype: int64\n",
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7841e57590>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp', '_session_creation_timeout_secs': 7200}\n",
            "// Starting to train Manhattan model............\n",
            "\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_including_temp/model.ckpt.\n",
            "INFO:tensorflow:loss = 14762.602, step = 1\n",
            "INFO:tensorflow:global_step/sec: 791.861\n",
            "INFO:tensorflow:loss = 615.1487, step = 101 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.19\n",
            "INFO:tensorflow:loss = 756.8539, step = 201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.349\n",
            "INFO:tensorflow:loss = 930.65906, step = 301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1015.61\n",
            "INFO:tensorflow:loss = 672.6621, step = 401 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.165\n",
            "INFO:tensorflow:loss = 862.8113, step = 501 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 757.137\n",
            "INFO:tensorflow:loss = 724.3727, step = 601 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 971.804\n",
            "INFO:tensorflow:loss = 802.8023, step = 701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 976.582\n",
            "INFO:tensorflow:loss = 693.2456, step = 801 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.563\n",
            "INFO:tensorflow:loss = 724.7899, step = 901 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1002.96\n",
            "INFO:tensorflow:loss = 776.7742, step = 1001 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.792\n",
            "INFO:tensorflow:loss = 690.9961, step = 1101 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.036\n",
            "INFO:tensorflow:loss = 770.89087, step = 1201 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1020.3\n",
            "INFO:tensorflow:loss = 848.7262, step = 1301 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 860.139\n",
            "INFO:tensorflow:loss = 1015.8308, step = 1401 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.336\n",
            "INFO:tensorflow:loss = 483.36328, step = 1501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 940.743\n",
            "INFO:tensorflow:loss = 675.255, step = 1601 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 1020.36\n",
            "INFO:tensorflow:loss = 595.1169, step = 1701 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 989.591\n",
            "INFO:tensorflow:loss = 704.0319, step = 1801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.39\n",
            "INFO:tensorflow:loss = 874.20593, step = 1901 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 908.743\n",
            "INFO:tensorflow:loss = 522.9331, step = 2001 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.808\n",
            "INFO:tensorflow:loss = 543.6886, step = 2101 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.38\n",
            "INFO:tensorflow:loss = 689.7809, step = 2201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 980.644\n",
            "INFO:tensorflow:loss = 689.1333, step = 2301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1024.49\n",
            "INFO:tensorflow:loss = 634.4846, step = 2401 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.501\n",
            "INFO:tensorflow:loss = 527.2357, step = 2501 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.216\n",
            "INFO:tensorflow:loss = 720.52747, step = 2601 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.249\n",
            "INFO:tensorflow:loss = 658.1537, step = 2701 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.635\n",
            "INFO:tensorflow:loss = 719.00946, step = 2801 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 903.604\n",
            "INFO:tensorflow:loss = 868.2385, step = 2901 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.626\n",
            "INFO:tensorflow:loss = 628.0205, step = 3001 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.523\n",
            "INFO:tensorflow:loss = 771.90625, step = 3101 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 1011.48\n",
            "INFO:tensorflow:loss = 614.24506, step = 3201 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.275\n",
            "INFO:tensorflow:loss = 693.75024, step = 3301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1017.29\n",
            "INFO:tensorflow:loss = 832.61035, step = 3401 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 992.265\n",
            "INFO:tensorflow:loss = 675.1918, step = 3501 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1030.9\n",
            "INFO:tensorflow:loss = 544.72144, step = 3601 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.844\n",
            "INFO:tensorflow:loss = 901.12915, step = 3701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1008.62\n",
            "INFO:tensorflow:loss = 576.59564, step = 3801 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1036.95\n",
            "INFO:tensorflow:loss = 814.8556, step = 3901 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 819.504\n",
            "INFO:tensorflow:loss = 632.61804, step = 4001 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.918\n",
            "INFO:tensorflow:loss = 655.38513, step = 4101 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 962.564\n",
            "INFO:tensorflow:loss = 569.6105, step = 4201 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 959.9\n",
            "INFO:tensorflow:loss = 644.30707, step = 4301 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 910.659\n",
            "INFO:tensorflow:loss = 983.9054, step = 4401 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 947.446\n",
            "INFO:tensorflow:loss = 684.1272, step = 4501 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.544\n",
            "INFO:tensorflow:loss = 654.3607, step = 4601 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.017\n",
            "INFO:tensorflow:loss = 733.7844, step = 4701 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1023.18\n",
            "INFO:tensorflow:loss = 614.1881, step = 4801 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 974.031\n",
            "INFO:tensorflow:loss = 696.89417, step = 4901 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.35\n",
            "INFO:tensorflow:loss = 790.46643, step = 5001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 914.728\n",
            "INFO:tensorflow:loss = 894.10095, step = 5101 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 980.397\n",
            "INFO:tensorflow:loss = 718.7567, step = 5201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 902.568\n",
            "INFO:tensorflow:loss = 700.6593, step = 5301 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.367\n",
            "INFO:tensorflow:loss = 619.3683, step = 5401 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.358\n",
            "INFO:tensorflow:loss = 1244.7394, step = 5501 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1008.54\n",
            "INFO:tensorflow:loss = 742.9154, step = 5601 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.119\n",
            "INFO:tensorflow:loss = 670.83673, step = 5701 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 998.682\n",
            "INFO:tensorflow:loss = 686.099, step = 5801 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 810.487\n",
            "INFO:tensorflow:loss = 813.6594, step = 5901 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 965.06\n",
            "INFO:tensorflow:loss = 881.1411, step = 6001 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.63\n",
            "INFO:tensorflow:loss = 969.05994, step = 6101 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.534\n",
            "INFO:tensorflow:loss = 617.1762, step = 6201 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.388\n",
            "INFO:tensorflow:loss = 932.807, step = 6301 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.54\n",
            "INFO:tensorflow:loss = 631.23615, step = 6401 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1020.29\n",
            "INFO:tensorflow:loss = 528.8199, step = 6501 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.716\n",
            "INFO:tensorflow:loss = 732.14026, step = 6601 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 982.116\n",
            "INFO:tensorflow:loss = 622.00446, step = 6701 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 981.817\n",
            "INFO:tensorflow:loss = 604.0605, step = 6801 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 854.547\n",
            "INFO:tensorflow:loss = 679.7788, step = 6901 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.4\n",
            "INFO:tensorflow:loss = 839.21436, step = 7001 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 968.583\n",
            "INFO:tensorflow:loss = 820.2644, step = 7101 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 977.094\n",
            "INFO:tensorflow:loss = 664.69604, step = 7201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 970.181\n",
            "INFO:tensorflow:loss = 650.9408, step = 7301 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.388\n",
            "INFO:tensorflow:loss = 747.7637, step = 7401 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.279\n",
            "INFO:tensorflow:loss = 686.35736, step = 7501 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.54\n",
            "INFO:tensorflow:loss = 1015.6771, step = 7601 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.759\n",
            "INFO:tensorflow:loss = 560.35034, step = 7701 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 978.231\n",
            "INFO:tensorflow:loss = 677.4335, step = 7801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 888.748\n",
            "INFO:tensorflow:loss = 1000.9015, step = 7901 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 941.351\n",
            "INFO:tensorflow:loss = 634.9276, step = 8001 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 861.149\n",
            "INFO:tensorflow:loss = 693.84827, step = 8101 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 900.403\n",
            "INFO:tensorflow:loss = 590.19543, step = 8201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.643\n",
            "INFO:tensorflow:loss = 848.6885, step = 8301 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 962.266\n",
            "INFO:tensorflow:loss = 669.32263, step = 8401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1011.18\n",
            "INFO:tensorflow:loss = 754.94006, step = 8501 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.395\n",
            "INFO:tensorflow:loss = 753.57385, step = 8601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 909.867\n",
            "INFO:tensorflow:loss = 817.563, step = 8701 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 803.022\n",
            "INFO:tensorflow:loss = 627.7336, step = 8801 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 981.976\n",
            "INFO:tensorflow:loss = 931.9141, step = 8901 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 981.636\n",
            "INFO:tensorflow:loss = 668.662, step = 9001 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1019.59\n",
            "INFO:tensorflow:loss = 849.3571, step = 9101 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 872.483\n",
            "INFO:tensorflow:loss = 691.9881, step = 9201 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 998.782\n",
            "INFO:tensorflow:loss = 949.1396, step = 9301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 897.137\n",
            "INFO:tensorflow:loss = 737.82697, step = 9401 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.749\n",
            "INFO:tensorflow:loss = 817.53467, step = 9501 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.996\n",
            "INFO:tensorflow:loss = 618.4917, step = 9601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.76\n",
            "INFO:tensorflow:loss = 709.1323, step = 9701 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 891.811\n",
            "INFO:tensorflow:loss = 736.73956, step = 9801 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 1002.93\n",
            "INFO:tensorflow:loss = 684.44635, step = 9901 (0.097 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_including_temp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1296.36.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "// Lnear Regression has RMSE of 26.30446476630212\n",
            "\n",
            "\n",
            "// Just using average = 120.6771037181996 has RMSE of 24.94511498186387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMnfjCXRmT_D",
        "outputId": "68f9fc52-59dc-491d-f9e1-5d8b1d1259fb"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'DAY' : [1, 1, 1],\n",
        "         'TEMP': [35,60,30]\n",
        "        })\n",
        "\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)\n",
        "                                                                                 )\n",
        ")\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "# print(preds)\n",
        "\n",
        "# The Number of collisions scale will be 106.072969 - which is the average number of collisions in Manhattan (359057 (collisions)/ 3385 (days))\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 106.072969\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7841e51e50>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp', '_session_creation_timeout_secs': 7200}\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[119.509476 132.55205  125.548935]\n",
            "[12676.725 14060.189 13317.348]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M1tZRi3mxmo"
      },
      "source": [
        "### After Temp\n",
        "\n",
        "After adding in the temp, the values have changed:\n",
        "\n",
        "\n",
        "Date|Prediction (no temp)|Prediction (with temp)|Actual\n",
        ":--:|:------------------:|:--------------------:|:----:\n",
        "1/1/2013|122|112|78|\n",
        "1/6/2016|128|125|121|\n",
        "1/12/2020|135|119|N/A|\n",
        "\n",
        "So while the values are pulling closer (on this current run) they are not **exact**\n",
        "\n",
        "Looking at the data from part 1 of the assignment, year, month and day do not affect the outputs, at least not directly.  Temperature and Weekday do.  So, the model could be changed to use these as predictors. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtiQ7GRssxjM"
      },
      "source": [
        "## Using Temperature and Weekday \n",
        "\n",
        "Taking the code from above, it will be modified to use these two parameters as predictors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yIdAco-s8Dn",
        "outputId": "3fa0128d-0f42-4310-b0cb-e4efa3e9c027"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[2,7]]\n",
        "print(\"// Printing predictors ...\")\n",
        "print(predictors_manhatten[:6])\n",
        "\n",
        "# We want the last column (the NUM_COLS)\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "print(\"// Printing targets .....\")\n",
        "print(targets_manhattan[:6])\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month, year and now temp = 4 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 2\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model_including_temp_and_weekday'\n",
        "\n",
        "# remove the last training model\n",
        "shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.1), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\\n\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan,NO_TARGETS)/SCALE_NUM_COLS, steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - predslistscale)**2))\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('\\n\\n// Lnear Regression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('\\n\\n// Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "// Printing predictors ...\n",
            "       WEEKDAY  TEMP\n",
            "941          3  47.5\n",
            "4916         2  36.4\n",
            "11328        4  76.2\n",
            "1364         1  49.2\n",
            "12958        6  44.5\n",
            "10554        6  66.5\n",
            "// Printing targets .....\n",
            "941      117\n",
            "4916     116\n",
            "11328    127\n",
            "1364     122\n",
            "12958     58\n",
            "10554     86\n",
            "Name: NUM_COLS, dtype: int64\n",
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f789f624690>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp_and_weekday', '_session_creation_timeout_secs': 7200}\n",
            "// Starting to train Manhattan model............\n",
            "\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt.\n",
            "INFO:tensorflow:loss = 14762.602, step = 1\n",
            "INFO:tensorflow:global_step/sec: 812.9\n",
            "INFO:tensorflow:loss = 1171.4901, step = 101 (0.127 sec)\n",
            "INFO:tensorflow:global_step/sec: 893.3\n",
            "INFO:tensorflow:loss = 1314.4143, step = 201 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.956\n",
            "INFO:tensorflow:loss = 1409.33, step = 301 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 1004.93\n",
            "INFO:tensorflow:loss = 1052.0826, step = 401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 965.08\n",
            "INFO:tensorflow:loss = 1338.9034, step = 501 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.626\n",
            "INFO:tensorflow:loss = 1226.79, step = 601 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 815.551\n",
            "INFO:tensorflow:loss = 1143.2411, step = 701 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 1020.65\n",
            "INFO:tensorflow:loss = 1039.0514, step = 801 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.22\n",
            "INFO:tensorflow:loss = 892.349, step = 901 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.494\n",
            "INFO:tensorflow:loss = 829.08936, step = 1001 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 881.675\n",
            "INFO:tensorflow:loss = 967.43274, step = 1101 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 837.372\n",
            "INFO:tensorflow:loss = 999.4412, step = 1201 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.264\n",
            "INFO:tensorflow:loss = 977.8959, step = 1301 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.224\n",
            "INFO:tensorflow:loss = 913.17285, step = 1401 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 998.575\n",
            "INFO:tensorflow:loss = 672.15356, step = 1501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 990.653\n",
            "INFO:tensorflow:loss = 767.30475, step = 1601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 851.322\n",
            "INFO:tensorflow:loss = 612.3353, step = 1701 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.009\n",
            "INFO:tensorflow:loss = 773.15015, step = 1801 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.907\n",
            "INFO:tensorflow:loss = 696.4342, step = 1901 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.274\n",
            "INFO:tensorflow:loss = 621.3545, step = 2001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.82\n",
            "INFO:tensorflow:loss = 591.7518, step = 2101 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1023.92\n",
            "INFO:tensorflow:loss = 776.4116, step = 2201 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.4\n",
            "INFO:tensorflow:loss = 683.02515, step = 2301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 848.404\n",
            "INFO:tensorflow:loss = 616.34717, step = 2401 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.449\n",
            "INFO:tensorflow:loss = 530.8165, step = 2501 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.815\n",
            "INFO:tensorflow:loss = 551.3696, step = 2601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 953.218\n",
            "INFO:tensorflow:loss = 608.4513, step = 2701 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.555\n",
            "INFO:tensorflow:loss = 682.6868, step = 2801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 942.06\n",
            "INFO:tensorflow:loss = 740.4558, step = 2901 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 910.436\n",
            "INFO:tensorflow:loss = 611.51654, step = 3001 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.579\n",
            "INFO:tensorflow:loss = 697.5106, step = 3101 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1022.5\n",
            "INFO:tensorflow:loss = 614.1271, step = 3201 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.213\n",
            "INFO:tensorflow:loss = 686.4756, step = 3301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1001.32\n",
            "INFO:tensorflow:loss = 784.70624, step = 3401 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 914.838\n",
            "INFO:tensorflow:loss = 661.2809, step = 3501 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 855.35\n",
            "INFO:tensorflow:loss = 470.54642, step = 3601 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 908.084\n",
            "INFO:tensorflow:loss = 853.1201, step = 3701 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.935\n",
            "INFO:tensorflow:loss = 555.59467, step = 3801 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 926.898\n",
            "INFO:tensorflow:loss = 707.63135, step = 3901 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1015.61\n",
            "INFO:tensorflow:loss = 605.9529, step = 4001 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 968.357\n",
            "INFO:tensorflow:loss = 680.0216, step = 4101 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 935.329\n",
            "INFO:tensorflow:loss = 590.6234, step = 4201 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 969.474\n",
            "INFO:tensorflow:loss = 594.80896, step = 4301 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 868.052\n",
            "INFO:tensorflow:loss = 569.52185, step = 4401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.801\n",
            "INFO:tensorflow:loss = 656.0217, step = 4501 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 943.917\n",
            "INFO:tensorflow:loss = 606.91364, step = 4601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 915.855\n",
            "INFO:tensorflow:loss = 668.9868, step = 4701 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.354\n",
            "INFO:tensorflow:loss = 576.3146, step = 4801 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.423\n",
            "INFO:tensorflow:loss = 631.88043, step = 4901 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.217\n",
            "INFO:tensorflow:loss = 588.1358, step = 5001 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.264\n",
            "INFO:tensorflow:loss = 660.6167, step = 5101 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 976.503\n",
            "INFO:tensorflow:loss = 695.8375, step = 5201 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.99\n",
            "INFO:tensorflow:loss = 636.3425, step = 5301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1027.25\n",
            "INFO:tensorflow:loss = 594.1731, step = 5401 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 891.106\n",
            "INFO:tensorflow:loss = 731.92346, step = 5501 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.852\n",
            "INFO:tensorflow:loss = 602.1571, step = 5601 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 957.982\n",
            "INFO:tensorflow:loss = 643.3373, step = 5701 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.127\n",
            "INFO:tensorflow:loss = 643.961, step = 5801 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.803\n",
            "INFO:tensorflow:loss = 677.5961, step = 5901 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.612\n",
            "INFO:tensorflow:loss = 678.98096, step = 6001 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 937.576\n",
            "INFO:tensorflow:loss = 713.34045, step = 6101 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 968.098\n",
            "INFO:tensorflow:loss = 613.349, step = 6201 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 986.287\n",
            "INFO:tensorflow:loss = 819.6243, step = 6301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 966.254\n",
            "INFO:tensorflow:loss = 429.6792, step = 6401 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 940.119\n",
            "INFO:tensorflow:loss = 454.47485, step = 6501 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 929.793\n",
            "INFO:tensorflow:loss = 700.0568, step = 6601 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 927.162\n",
            "INFO:tensorflow:loss = 654.86707, step = 6701 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.665\n",
            "INFO:tensorflow:loss = 500.83392, step = 6801 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.993\n",
            "INFO:tensorflow:loss = 672.26587, step = 6901 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 938.981\n",
            "INFO:tensorflow:loss = 759.79236, step = 7001 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.188\n",
            "INFO:tensorflow:loss = 519.631, step = 7101 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 941.793\n",
            "INFO:tensorflow:loss = 637.74365, step = 7201 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.997\n",
            "INFO:tensorflow:loss = 574.75964, step = 7301 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 846.261\n",
            "INFO:tensorflow:loss = 592.59845, step = 7401 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 968.621\n",
            "INFO:tensorflow:loss = 678.1248, step = 7501 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.224\n",
            "INFO:tensorflow:loss = 708.1465, step = 7601 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 886.985\n",
            "INFO:tensorflow:loss = 521.18823, step = 7701 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 965.624\n",
            "INFO:tensorflow:loss = 531.6781, step = 7801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1007.19\n",
            "INFO:tensorflow:loss = 662.32, step = 7901 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.791\n",
            "INFO:tensorflow:loss = 595.81604, step = 8001 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.613\n",
            "INFO:tensorflow:loss = 661.94025, step = 8101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1038\n",
            "INFO:tensorflow:loss = 508.3703, step = 8201 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.987\n",
            "INFO:tensorflow:loss = 746.2078, step = 8301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 901.696\n",
            "INFO:tensorflow:loss = 523.2098, step = 8401 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.155\n",
            "INFO:tensorflow:loss = 641.28845, step = 8501 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.785\n",
            "INFO:tensorflow:loss = 738.6915, step = 8601 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.297\n",
            "INFO:tensorflow:loss = 782.99536, step = 8701 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 999.4\n",
            "INFO:tensorflow:loss = 603.5445, step = 8801 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.096\n",
            "INFO:tensorflow:loss = 610.73737, step = 8901 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1001.25\n",
            "INFO:tensorflow:loss = 643.0637, step = 9001 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 938.447\n",
            "INFO:tensorflow:loss = 586.0049, step = 9101 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.485\n",
            "INFO:tensorflow:loss = 578.6399, step = 9201 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 934.418\n",
            "INFO:tensorflow:loss = 693.3042, step = 9301 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 912.478\n",
            "INFO:tensorflow:loss = 672.76514, step = 9401 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.437\n",
            "INFO:tensorflow:loss = 595.88, step = 9501 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.551\n",
            "INFO:tensorflow:loss = 598.6002, step = 9601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 868.312\n",
            "INFO:tensorflow:loss = 685.3684, step = 9701 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.857\n",
            "INFO:tensorflow:loss = 637.30835, step = 9801 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 996.385\n",
            "INFO:tensorflow:loss = 688.8728, step = 9901 (0.097 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 704.7888.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "// Lnear Regression has RMSE of 24.000986424566985\n",
            "\n",
            "\n",
            "// Just using average = 120.6771037181996 has RMSE of 24.94511498186387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI3IEPqTuMcs"
      },
      "source": [
        "This still has quite a large RMSE.  However, running a prediction, again using a day which is known (but picking the weekday and temp values)\n",
        "\n",
        "Using 24-10-2018 in the Mathattan borough, the *WEEKDAY* was **3** and the *TEMP*  was **48.4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8KC5G76uW_5",
        "outputId": "29369144-7fda-4bd0-c379-ef47ca125827"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'WEEKDAY' : [3],\n",
        "         'TEMP' : [48.4]\n",
        "        })\n",
        "\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)\n",
        "                                                                                 )\n",
        ")\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "# print(preds)\n",
        "\n",
        "# The Number of collisions scale will be 106.072969 - which is the average number of collisions in Manhattan (359057 (collisions)/ 3385 (days))\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 1\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f78475fdb10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp_and_weekday', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp_and_weekday/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[121.44889]\n",
            "[121.44889]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5rrtbTyvoPQ"
      },
      "source": [
        "Which returns [120.53093] - the actual value of collisions was **120**  \n",
        "\n",
        "One thing to note is that the model always returns slightly more accidents than happened - in this case, that is probably a wise thing, better to be prepared for too many than too few accidents..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVR7uKHFqUKR"
      },
      "source": [
        "# Training a DNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uoa-o_t7N6BP"
      },
      "source": [
        "## Background\n",
        "\n",
        "The same dataset which was constructed during the first part of this assignment will be used here.  As before, the data will be limited to the Manhattan borough.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qcMkg_eOL_p"
      },
      "source": [
        "# Import pandas to use dataframes\n",
        "import pandas as pd\n",
        "\n",
        "# create data frame from csv file we hosted on our github\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv')\n",
        "\n",
        "# now setup to query the dataframe for only the boroughs noted\n",
        "manhat_df = df.query('BOROUGH==\"MANHATTAN\"')\n",
        "\n",
        "SCALE_NUM_COLS = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV_YzN53OPBA"
      },
      "source": [
        "### Checking data loaded\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyHZeT4GOTab",
        "outputId": "739e6d58-d954-41b4-98c0-91c08a655a88"
      },
      "source": [
        "# Ensure data has loaded\n",
        "print(manhat_df[:6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "0   21-08-2012  MANHATTAN        2  ...          0         28       109\n",
            "6   27-10-2012  MANHATTAN        6  ...          0         20       122\n",
            "13  25-08-2012  MANHATTAN        6  ...          0         22        97\n",
            "16  09-09-2012  MANHATTAN        7  ...          0         29       109\n",
            "20  17-09-2012  MANHATTAN        1  ...          1         27       123\n",
            "28  23-11-2012  MANHATTAN        5  ...          0          5        66\n",
            "\n",
            "[6 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLEekZptOsNp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGRIp8ghOYNO"
      },
      "source": [
        "## Importing Numpy and setting preductors\n",
        "\n",
        "For the predictors, all the columns which have integer values are used.  The borough has been excluded (as only Manhattan is being selected) and the collision_date is being exluded (but those values are present in the DAY, MONTH and YEAR columns)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jmqYqn2OpMw",
        "outputId": "03192a2f-ccb4-4924-d3d2-ac5ab37d5322"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhattan = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "\n",
        "# setup predictors\n",
        "# Removing the data fields as the DNN should be able to extract this.  Also exluding the borough field as only dealing with Manhattan\n",
        "predictors_manhattan = shuffle_manhattan.iloc[:,[2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18]]\n",
        "\n",
        "# Check -1 (for all columns) has worked\n",
        "print(predictors_manhattan[:6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       WEEKDAY  YEAR  MONTH  DAY  TEMP  ...   MAX   MIN  PRCP   SNDP  FOG\n",
            "6113         6  2015      6    6  58.0  ...  63.0  46.9  0.05  999.9    1\n",
            "12922        7  2019     11   10  48.3  ...  54.0  32.0  0.00  999.9    0\n",
            "4916         2  2015      2   10  36.4  ...  37.9  35.1  0.07  999.9    0\n",
            "8454         3  2017      2   15  36.6  ...  44.1  21.9  0.00  999.9    0\n",
            "8456         4  2017      2   16  36.1  ...  44.1  21.9  0.63  999.9    1\n",
            "16223        3  2021      6    9  68.9  ...  81.0  62.1  0.00  999.9    1\n",
            "\n",
            "[6 rows x 16 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTJoKhCuOvL5",
        "outputId": "03b201bb-d108-4609-f611-17eaafb4db85"
      },
      "source": [
        "# print first 5 rows of the shuffle\n",
        "print(shuffle_manhattan[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "6113   06-06-2015  MANHATTAN        6  ...          0         18       112\n",
            "12922  10-11-2019  MANHATTAN        7  ...          0         15        84\n",
            "4916   10-02-2015  MANHATTAN        2  ...          0         15       116\n",
            "8454   2017-02-15  MANHATTAN        3  ...          0         18       111\n",
            "8456   2017-02-16  MANHATTAN        4  ...          0         23       112\n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQQdhn5aOyQI"
      },
      "source": [
        "### Defining the target\n",
        "\n",
        "For this test model, only the number of collisions (NUM_COLS) is of interest.  This needs to be defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6R6mCNoO7oE",
        "outputId": "b4d57a9b-66c8-47ee-807c-fb0e6b0044b2"
      },
      "source": [
        "# Define the target (the NUM_COLS)\n",
        "target_manhatan = shuffle_manhattan.iloc[:,-1]\n",
        "\n",
        "# print the targets\n",
        "print(target_manhatan[:6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6113     112\n",
            "12922     84\n",
            "4916     116\n",
            "8454     111\n",
            "8456     112\n",
            "16223     51\n",
            "Name: NUM_COLS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46NkBLJCPAb7"
      },
      "source": [
        "### Training and Testing dataset\n",
        "\n",
        "As with the linear regressor, a training and testing dataset of 80% and 20% of the results is defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMrFGPmSPIm_"
      },
      "source": [
        "# Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "training_size_manhattan = int(len(shuffle_manhattan['NUM_COLS'] ) *0.8)\n",
        "\n",
        "# The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "testing_size_manhattan = len(shuffle_manhattan['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# Define the number of input values (predictors) - won't be 27, it will not include the borough or date - but should it include the borough?\n",
        "no_predictors = 17\n",
        "\n",
        "# Define the number of output values (targets)\n",
        "no_outputs = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnmGlJyXPTtq"
      },
      "source": [
        "## The tensorflow bit...\n",
        "\n",
        "Now the tensorflow model can be setup.  This is mostly the same as the regressor (except the DNN uses the DNNRegressor, of course.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyMqMtXiPjr1",
        "outputId": "207c3bbf-e969-40c0-b1f0-6fe16491e449"
      },
      "source": [
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "model_dir = '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model'\n",
        "\n",
        "# remove the last training model - if it is present\n",
        "if os.path.isdir(model_dir):\n",
        "  print(\"\\n// Removing old model directory ....\")\n",
        "  shutil.rmtree(model_dir, ignore_errors=True)\n",
        "else:\n",
        "  print(\"\\n// No model directory to remove ....\")\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(\n",
        "    model_dir=model_dir, \n",
        "    hidden_units=[20,18,14], \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhattan.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Prints a log to show model is starting to train\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator.fit(predictors_manhattan[:training_size_manhattan].values, \n",
        "              target_manhatan[:training_size_manhattan].values.reshape(training_size_manhattan, no_outputs) / SCALE_NUM_COLS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_manhattan[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((target_manhatan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the Life Satisfaction Values.\n",
        "avg = np.mean(shuffle_manhattan['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using Life Satisfaction Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhattan['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "\n",
            "// No model directory to remove ....\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-9-276d5dbf16c5>:30: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please convert numpy dtypes explicitly.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/dnn.py:660: regression_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.contrib.estimator.*_head.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa5100912d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:From <ipython-input-9-276d5dbf16c5>:30: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to the Estimator interface.\n",
            "starting to train\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 23018.61, step = 1\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 45 vs previous value: 45. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 80 vs previous value: 80. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 505.804\n",
            "INFO:tensorflow:loss = 1361.8286, step = 101 (0.199 sec)\n",
            "INFO:tensorflow:global_step/sec: 728.757\n",
            "INFO:tensorflow:loss = 1525.8065, step = 201 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 684.876\n",
            "INFO:tensorflow:loss = 1477.7588, step = 301 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.73\n",
            "INFO:tensorflow:loss = 1383.5, step = 401 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 724.819\n",
            "INFO:tensorflow:loss = 1727.5922, step = 501 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 718.232\n",
            "INFO:tensorflow:loss = 1527.3286, step = 601 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 730.406\n",
            "INFO:tensorflow:loss = 1341.4261, step = 701 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 727.539\n",
            "INFO:tensorflow:loss = 1407.9537, step = 801 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 638.566\n",
            "INFO:tensorflow:loss = 1404.5808, step = 901 (0.154 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 901 vs previous value: 901. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 689.863\n",
            "INFO:tensorflow:loss = 1362.5253, step = 1001 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 703.89\n",
            "INFO:tensorflow:loss = 1731.5428, step = 1101 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 658.517\n",
            "INFO:tensorflow:loss = 1721.6194, step = 1201 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.317\n",
            "INFO:tensorflow:loss = 1018.78284, step = 1301 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 737.764\n",
            "INFO:tensorflow:loss = 1270.5637, step = 1401 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 762.595\n",
            "INFO:tensorflow:loss = 1376.6337, step = 1501 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 722.387\n",
            "INFO:tensorflow:loss = 1547.5784, step = 1601 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 737.782\n",
            "INFO:tensorflow:loss = 1169.3894, step = 1701 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 708.282\n",
            "INFO:tensorflow:loss = 1445.3202, step = 1801 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 702.157\n",
            "INFO:tensorflow:loss = 1515.9, step = 1901 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 740.457\n",
            "INFO:tensorflow:loss = 1445.4341, step = 2001 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.169\n",
            "INFO:tensorflow:loss = 1422.2002, step = 2101 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 655.419\n",
            "INFO:tensorflow:loss = 1324.9796, step = 2201 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 698.655\n",
            "INFO:tensorflow:loss = 1378.596, step = 2301 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 735.765\n",
            "INFO:tensorflow:loss = 989.1859, step = 2401 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 693.849\n",
            "INFO:tensorflow:loss = 1657.79, step = 2501 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 712.24\n",
            "INFO:tensorflow:loss = 1108.863, step = 2601 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 728.721\n",
            "INFO:tensorflow:loss = 1344.602, step = 2701 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 712.574\n",
            "INFO:tensorflow:loss = 1588.1294, step = 2801 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 731.661\n",
            "INFO:tensorflow:loss = 1108.0388, step = 2901 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 751.799\n",
            "INFO:tensorflow:loss = 1296.113, step = 3001 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 715.716\n",
            "INFO:tensorflow:loss = 1522.206, step = 3101 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 691.781\n",
            "INFO:tensorflow:loss = 1441.9783, step = 3201 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 695.931\n",
            "INFO:tensorflow:loss = 1089.4203, step = 3301 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.397\n",
            "INFO:tensorflow:loss = 1246.3928, step = 3401 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.261\n",
            "INFO:tensorflow:loss = 1314.866, step = 3501 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 639.147\n",
            "INFO:tensorflow:loss = 1310.9801, step = 3601 (0.156 sec)\n",
            "INFO:tensorflow:global_step/sec: 715.229\n",
            "INFO:tensorflow:loss = 1345.7238, step = 3701 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 651.183\n",
            "INFO:tensorflow:loss = 1520.9902, step = 3801 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 704.214\n",
            "INFO:tensorflow:loss = 1302.7533, step = 3901 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 671.316\n",
            "INFO:tensorflow:loss = 1580.8796, step = 4001 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 712.523\n",
            "INFO:tensorflow:loss = 1298.3406, step = 4101 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 709.065\n",
            "INFO:tensorflow:loss = 1498.0145, step = 4201 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 707.211\n",
            "INFO:tensorflow:loss = 1524.8127, step = 4301 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 734.55\n",
            "INFO:tensorflow:loss = 1452.1948, step = 4401 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 689.83\n",
            "INFO:tensorflow:loss = 1492.614, step = 4501 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.092\n",
            "INFO:tensorflow:loss = 1374.2402, step = 4601 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 695.983\n",
            "INFO:tensorflow:loss = 1598.9739, step = 4701 (0.145 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4735 vs previous value: 4735. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 627.513\n",
            "INFO:tensorflow:loss = 1298.5408, step = 4801 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 693.386\n",
            "INFO:tensorflow:loss = 1497.8346, step = 4901 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 730.3\n",
            "INFO:tensorflow:loss = 1441.8403, step = 5001 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 758.656\n",
            "INFO:tensorflow:loss = 1741.4346, step = 5101 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 716.849\n",
            "INFO:tensorflow:loss = 1285.6863, step = 5201 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.643\n",
            "INFO:tensorflow:loss = 1400.8286, step = 5301 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 706.062\n",
            "INFO:tensorflow:loss = 1063.3595, step = 5401 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 723.794\n",
            "INFO:tensorflow:loss = 1226.1932, step = 5501 (0.138 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 5501 vs previous value: 5501. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 689.82\n",
            "INFO:tensorflow:loss = 1055.2483, step = 5601 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 663.948\n",
            "INFO:tensorflow:loss = 1377.9692, step = 5701 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 730.002\n",
            "INFO:tensorflow:loss = 1322.7878, step = 5801 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 685.505\n",
            "INFO:tensorflow:loss = 1603.4319, step = 5901 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 737.84\n",
            "INFO:tensorflow:loss = 1370.4525, step = 6001 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.478\n",
            "INFO:tensorflow:loss = 1491.3068, step = 6101 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 755.042\n",
            "INFO:tensorflow:loss = 1274.1785, step = 6201 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 696.441\n",
            "INFO:tensorflow:loss = 1657.6353, step = 6301 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 785.852\n",
            "INFO:tensorflow:loss = 1174.8064, step = 6401 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 727.556\n",
            "INFO:tensorflow:loss = 1367.251, step = 6501 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 752.936\n",
            "INFO:tensorflow:loss = 1261.4003, step = 6601 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 707.411\n",
            "INFO:tensorflow:loss = 1131.4462, step = 6701 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 716.155\n",
            "INFO:tensorflow:loss = 1338.3625, step = 6801 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 744.78\n",
            "INFO:tensorflow:loss = 1170.4813, step = 6901 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 720.255\n",
            "INFO:tensorflow:loss = 1528.696, step = 7001 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 727.602\n",
            "INFO:tensorflow:loss = 1165.6531, step = 7101 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 736.871\n",
            "INFO:tensorflow:loss = 1267.4723, step = 7201 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 712.262\n",
            "INFO:tensorflow:loss = 1548.6323, step = 7301 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 715.318\n",
            "INFO:tensorflow:loss = 1490.8147, step = 7401 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 676.46\n",
            "INFO:tensorflow:loss = 1397.604, step = 7501 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 704.221\n",
            "INFO:tensorflow:loss = 1464.9355, step = 7601 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 740.692\n",
            "INFO:tensorflow:loss = 1241.459, step = 7701 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 729.486\n",
            "INFO:tensorflow:loss = 1176.9485, step = 7801 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 755.037\n",
            "INFO:tensorflow:loss = 1305.8661, step = 7901 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 700.519\n",
            "INFO:tensorflow:loss = 1483.3113, step = 8001 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 672.04\n",
            "INFO:tensorflow:loss = 1185.5535, step = 8101 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 701.624\n",
            "INFO:tensorflow:loss = 1472.9498, step = 8201 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 677.24\n",
            "INFO:tensorflow:loss = 1126.9153, step = 8301 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.125\n",
            "INFO:tensorflow:loss = 1357.8555, step = 8401 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 741.629\n",
            "INFO:tensorflow:loss = 1110.2983, step = 8501 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 716.319\n",
            "INFO:tensorflow:loss = 1604.2598, step = 8601 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 716.864\n",
            "INFO:tensorflow:loss = 1244.9917, step = 8701 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 734.098\n",
            "INFO:tensorflow:loss = 1228.8467, step = 8801 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 703.013\n",
            "INFO:tensorflow:loss = 1496.8522, step = 8901 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 715.21\n",
            "INFO:tensorflow:loss = 1353.3462, step = 9001 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 687.219\n",
            "INFO:tensorflow:loss = 1197.7712, step = 9101 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 771.502\n",
            "INFO:tensorflow:loss = 1753.1349, step = 9201 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 711.996\n",
            "INFO:tensorflow:loss = 1287.5935, step = 9301 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 735.794\n",
            "INFO:tensorflow:loss = 1393.2476, step = 9401 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 636.323\n",
            "INFO:tensorflow:loss = 1154.219, step = 9501 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 695.083\n",
            "INFO:tensorflow:loss = 1261.5923, step = 9601 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 689.362\n",
            "INFO:tensorflow:loss = 1170.8463, step = 9701 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 764.801\n",
            "INFO:tensorflow:loss = 1472.1353, step = 9801 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 686.994\n",
            "INFO:tensorflow:loss = 1375.4807, step = 9901 (0.141 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1068.3044.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "DNNRegression has RMSE of 179.54581248443063\n",
            "Just using average = 105.93572220169929 has RMSE of 38.48039547507388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ52I5cuQOQV"
      },
      "source": [
        "### Testing the model\n",
        "\n",
        "As a test for the model, a date is selected from the data and the values plugged in.  For this test, the 05/05/2017 in MANHATTAN has been selected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agdZ-ef2Qa_b",
        "outputId": "8dcdfa3f-d15d-4eae-f447-2c14469fbd42"
      },
      "source": [
        "# As a test, use something which is known - this case the values for MANHATTAN on the 05/05/2017\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'WEEKDAY' : [5],\n",
        "         'YEAR' : [2017],\n",
        "         'MONTH' : [5],\n",
        "         'DAY' : [5],\n",
        "         'TEMP' : [49.4],\n",
        "         'DEWP' : [44],\n",
        "         'SLP' : [1019.6],\n",
        "         'VISIB' : [7.6],\n",
        "         'WDSP' : [14.9],\n",
        "         'MXPSD' : [25.1],\n",
        "         'GUST' : [31.1],\n",
        "         'MAX' : [57.9],\n",
        "         'MIN' : [45],\n",
        "         'PRCP' : [0],\n",
        "         'SNDP' : [999.9],\n",
        "         'FOG' : [0]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir=model_dir, hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n",
        "print(predslistnorm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa508643690>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[110.7177]\n",
            "[110.7177]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_da79fqQe5f"
      },
      "source": [
        "This returns **110.7177]** (the value may change on subsequent runs) - and this value is a little lower than the recorded value of **172**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "081Vz4aoQvMb"
      },
      "source": [
        "### Testing an unknown date.\n",
        "\n",
        "When the data was constructed the year 2021 was removed (due to covid) however, the weather data for 2021 is still available.  Selecting a more recent date (in this case 21-11-2021) and using the weather data from then will give a different result.\n",
        "\n",
        "date      |year|mo|da|temp|dewp|slp   |visib|wdsp|mxpsd|gust |max |min|prcp|sndp |fog\n",
        "----------|----|--|--|----|----|------|-----|----|-----|-----|----|---|----|-----|---\n",
        "2021-11-21|2021|11|21|52.3|42.2|1028.0|10.0 |11.3|14   |999.9|57.9|39.0|0.0|999.9|1\n",
        "\n",
        "This will result in an ```input``` which looks like this:\n",
        "\n",
        "```python\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{\n",
        "         'WEEKDAY' : [7],\n",
        "         'YEAR' : [2021],\n",
        "         'MONTH' : [11],\n",
        "         'DAY' : [21],\n",
        "         'TEMP' : [52.3],\n",
        "         'DEWP' : [42.2],\n",
        "         'SLP' : [1028.0],\n",
        "         'VISIB' : [10.0],\n",
        "         'WDSP' : [11.3],\n",
        "         'MXPSD' : [14],\n",
        "         'GUST' : [999.9],\n",
        "         'MAX' : [57.9],\n",
        "         'MIN' : [39],\n",
        "         'PRCP' : [0.0],\n",
        "         'SNDP' : [999.9],\n",
        "         'FOG' : [1]\n",
        "        })\n",
        "```\n",
        "\n",
        "creating a new code block which incorporates all the above code items (for brevity) is below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inshwx5eU_Ut",
        "outputId": "a3080d34-0806-4a69-f45b-ea48a2638bff"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhattan = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "\n",
        "# setup predictors\n",
        "# Removing the data fields as the DNN should be able to extract this.  Also exluding the borough field as only dealing with Manhattan\n",
        "predictors_manhattan = shuffle_manhattan.iloc[:,[2,3,4,5,7,8,9,10,11,12,13,14,15,16,17,18]]\n",
        "\n",
        "# Check -1 (for all columns) has worked\n",
        "print(predictors_manhattan[:6])\n",
        "\n",
        "# print first 5 rows of the shuffle\n",
        "print(shuffle_manhattan[:5])\n",
        "\n",
        "# Define the target (the NUM_COLS)\n",
        "target_manhatan = shuffle_manhattan.iloc[:,-1]\n",
        "\n",
        "# print the targets\n",
        "print(target_manhatan[:6])\n",
        "\n",
        "# Split our data into a training set i.e. 80% of the length of the shuffle array\n",
        "training_size_manhattan = int(len(shuffle_manhattan['NUM_COLS'] ) *0.8)\n",
        "\n",
        "# The test set size is 100% - 80% = 20% of the length of the shuffle array.\n",
        "testing_size_manhattan = len(shuffle_manhattan['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# Define the number of input values (predictors) - won't be 27, it will not include the borough or date - but should it include the borough?\n",
        "no_predictors = 17\n",
        "\n",
        "# Define the number of output values (targets)\n",
        "no_outputs = 1\n",
        "\n",
        "# import tensorflow\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# check the version\n",
        "print(tf.__version__)\n",
        "\n",
        "# needed for high-level file management\n",
        "import shutil  \n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# removes a saved model from the last training attempt.\n",
        "model_dir = '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model'\n",
        "\n",
        "# remove the last training model - if it is present\n",
        "if os.path.isdir(model_dir):\n",
        "  print(\"\\n// Removing old model directory ....\")\n",
        "  shutil.rmtree(model_dir, ignore_errors=True)\n",
        "else:\n",
        "  print(\"\\n// No model directory to remove ....\")\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(\n",
        "    model_dir=model_dir, \n",
        "    hidden_units=[20,18,14], \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.01), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhattan.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Prints a log to show model is starting to train\n",
        "print(\"starting to train\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator.fit(predictors_manhattan[:training_size_manhattan].values, \n",
        "              target_manhatan[:training_size_manhattan].values.reshape(training_size_manhattan, no_outputs) / SCALE_NUM_COLS, steps=10000)\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator.predict(x=predictors_manhattan[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((target_manhatan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the Life Satisfaction Values.\n",
        "avg = np.mean(shuffle_manhattan['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using Life Satisfaction Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhattan['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('Just using average = {0} has RMSE of {1}'.format(avg, rmse));\n",
        "\n",
        "# As a test, use something which is known - this case the values for MANHATTAN on the 05/05/2017\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "        {\n",
        "         'WEEKDAY' : [7],\n",
        "         'YEAR' : [2021],\n",
        "         'MONTH' : [11],\n",
        "         'DAY' : [21],\n",
        "         'TEMP' : [52.3],\n",
        "         'DEWP' : [42.2],\n",
        "         'SLP' : [1028.0],\n",
        "         'VISIB' : [10.0],\n",
        "         'WDSP' : [11.3],\n",
        "         'MXPSD' : [14],\n",
        "         'GUST' : [999.9],\n",
        "         'MAX' : [57.9],\n",
        "         'MIN' : [39],\n",
        "         'PRCP' : [0.0],\n",
        "         'SNDP' : [999.9],\n",
        "         'FOG' : [1]\n",
        "        })\n",
        "\n",
        "estimator = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(model_dir=model_dir, hidden_units=[20,18,14], enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator.predict(x=input.values)\n",
        "\n",
        "predslistnorm = preds['scores']\n",
        "prednorm = format(str(predslistnorm))\n",
        "print(prednorm)\n",
        "print(predslistnorm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       WEEKDAY  YEAR  MONTH  DAY  TEMP  ...   MAX   MIN  PRCP   SNDP  FOG\n",
            "460          5  2012      7    6  81.9  ...  91.0  66.9  0.00  999.9    0\n",
            "10896        3  2018      5    9  51.2  ...  61.0  46.9  0.00  999.9    1\n",
            "5846         1  2015      6   15  57.8  ...  59.0  55.0  0.00  999.9    0\n",
            "15251        4  2020      4    9  43.0  ...  51.1  30.0  0.27  999.9    1\n",
            "14308        4  2020      1   23  32.3  ...  45.0  17.1  0.00  999.9    0\n",
            "10335        1  2018     12   24  35.2  ...  39.9  28.9  0.00  999.9    0\n",
            "\n",
            "[6 rows x 16 columns]\n",
            "             DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "460    06-07-2012  MANHATTAN        5  ...          0         37       154\n",
            "10896  09-05-2018  MANHATTAN        3  ...          0         22       132\n",
            "5846   15-06-2015  MANHATTAN        1  ...          1         19       118\n",
            "15251  09-04-2020  MANHATTAN        4  ...          0          6        12\n",
            "14308  23-01-2020  MANHATTAN        4  ...          0         23        79\n",
            "\n",
            "[5 rows x 28 columns]\n",
            "460      154\n",
            "10896    132\n",
            "5846     118\n",
            "15251     12\n",
            "14308     79\n",
            "10335     79\n",
            "Name: NUM_COLS, dtype: int64\n",
            "1.15.2\n",
            "\n",
            "// Removing old model directory ....\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa50dc0f990>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "starting to train\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 25753.615, step = 1\n",
            "INFO:tensorflow:global_step/sec: 547.694\n",
            "INFO:tensorflow:loss = 1182.8491, step = 101 (0.188 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.589\n",
            "INFO:tensorflow:loss = 1406.7935, step = 201 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 712.464\n",
            "INFO:tensorflow:loss = 1466.7983, step = 301 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.75\n",
            "INFO:tensorflow:loss = 1251.1348, step = 401 (0.155 sec)\n",
            "INFO:tensorflow:global_step/sec: 688.874\n",
            "INFO:tensorflow:loss = 1572.2727, step = 501 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 715.204\n",
            "INFO:tensorflow:loss = 1617.9066, step = 601 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 738.52\n",
            "INFO:tensorflow:loss = 1583.033, step = 701 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 721.483\n",
            "INFO:tensorflow:loss = 1441.7688, step = 801 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 708.52\n",
            "INFO:tensorflow:loss = 1508.2427, step = 901 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 690.234\n",
            "INFO:tensorflow:loss = 1264.0122, step = 1001 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 691.037\n",
            "INFO:tensorflow:loss = 1429.1178, step = 1101 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 646.74\n",
            "INFO:tensorflow:loss = 1658.5889, step = 1201 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 678\n",
            "INFO:tensorflow:loss = 1359.5173, step = 1301 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 674.962\n",
            "INFO:tensorflow:loss = 1598.9861, step = 1401 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 700.249\n",
            "INFO:tensorflow:loss = 1379.2755, step = 1501 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 715.045\n",
            "INFO:tensorflow:loss = 1253.3767, step = 1601 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 694.977\n",
            "INFO:tensorflow:loss = 1336.2554, step = 1701 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.665\n",
            "INFO:tensorflow:loss = 1812.6194, step = 1801 (0.157 sec)\n",
            "INFO:tensorflow:global_step/sec: 744.583\n",
            "INFO:tensorflow:loss = 1235.5044, step = 1901 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 703.636\n",
            "INFO:tensorflow:loss = 1184.8641, step = 2001 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 729.966\n",
            "INFO:tensorflow:loss = 1325.4255, step = 2101 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 717.426\n",
            "INFO:tensorflow:loss = 1436.063, step = 2201 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 742.016\n",
            "INFO:tensorflow:loss = 1277.9053, step = 2301 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 666.285\n",
            "INFO:tensorflow:loss = 1523.3398, step = 2401 (0.150 sec)\n",
            "INFO:tensorflow:global_step/sec: 684.713\n",
            "INFO:tensorflow:loss = 1202.2341, step = 2501 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 707.162\n",
            "INFO:tensorflow:loss = 1196.9689, step = 2601 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 708.156\n",
            "INFO:tensorflow:loss = 1362.9584, step = 2701 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 700.997\n",
            "INFO:tensorflow:loss = 1322.325, step = 2801 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 714.269\n",
            "INFO:tensorflow:loss = 1481.7748, step = 2901 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 735.46\n",
            "INFO:tensorflow:loss = 1308.5026, step = 3001 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 684.226\n",
            "INFO:tensorflow:loss = 1351.6565, step = 3101 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 732.687\n",
            "INFO:tensorflow:loss = 1292.6425, step = 3201 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 689.915\n",
            "INFO:tensorflow:loss = 1357.1326, step = 3301 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 730.071\n",
            "INFO:tensorflow:loss = 1194.5825, step = 3401 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 716.13\n",
            "INFO:tensorflow:loss = 1233.7549, step = 3501 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 737.897\n",
            "INFO:tensorflow:loss = 1645.0205, step = 3601 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 711.771\n",
            "INFO:tensorflow:loss = 1358.5961, step = 3701 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 727.087\n",
            "INFO:tensorflow:loss = 1273.7141, step = 3801 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 715.886\n",
            "INFO:tensorflow:loss = 1488.5563, step = 3901 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 717.434\n",
            "INFO:tensorflow:loss = 1305.7866, step = 4001 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 725.631\n",
            "INFO:tensorflow:loss = 1554.6284, step = 4101 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 721.051\n",
            "INFO:tensorflow:loss = 1781.382, step = 4201 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 761\n",
            "INFO:tensorflow:loss = 1084.6759, step = 4301 (0.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 720.469\n",
            "INFO:tensorflow:loss = 1321.7377, step = 4401 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 725.644\n",
            "INFO:tensorflow:loss = 1459.7864, step = 4501 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 670.771\n",
            "INFO:tensorflow:loss = 1264.9642, step = 4601 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 717.996\n",
            "INFO:tensorflow:loss = 1511.0507, step = 4701 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 660.03\n",
            "INFO:tensorflow:loss = 1380.1642, step = 4801 (0.149 sec)\n",
            "INFO:tensorflow:global_step/sec: 718.004\n",
            "INFO:tensorflow:loss = 1212.2411, step = 4901 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 754.07\n",
            "INFO:tensorflow:loss = 1351.8953, step = 5001 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 728.484\n",
            "INFO:tensorflow:loss = 1277.6702, step = 5101 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 745.848\n",
            "INFO:tensorflow:loss = 1326.7808, step = 5201 (0.131 sec)\n",
            "INFO:tensorflow:global_step/sec: 694.442\n",
            "INFO:tensorflow:loss = 1500.9927, step = 5301 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 743.883\n",
            "INFO:tensorflow:loss = 1390.0001, step = 5401 (0.134 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.875\n",
            "INFO:tensorflow:loss = 1362.6904, step = 5501 (0.153 sec)\n",
            "INFO:tensorflow:global_step/sec: 744.13\n",
            "INFO:tensorflow:loss = 1311.0845, step = 5601 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 728.182\n",
            "INFO:tensorflow:loss = 1322.2417, step = 5701 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 719.296\n",
            "INFO:tensorflow:loss = 1644.3402, step = 5801 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 725.98\n",
            "INFO:tensorflow:loss = 1196.0676, step = 5901 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 642.572\n",
            "INFO:tensorflow:loss = 1611.65, step = 6001 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 685.613\n",
            "INFO:tensorflow:loss = 1157.3318, step = 6101 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 682.762\n",
            "INFO:tensorflow:loss = 1304.6403, step = 6201 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 739.976\n",
            "INFO:tensorflow:loss = 1248.5717, step = 6301 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 739.17\n",
            "INFO:tensorflow:loss = 1451.487, step = 6401 (0.133 sec)\n",
            "INFO:tensorflow:global_step/sec: 713.818\n",
            "INFO:tensorflow:loss = 1273.8997, step = 6501 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 705.741\n",
            "INFO:tensorflow:loss = 1084.553, step = 6601 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 732.75\n",
            "INFO:tensorflow:loss = 1504.621, step = 6701 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 665.963\n",
            "INFO:tensorflow:loss = 1345.4769, step = 6801 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 698.194\n",
            "INFO:tensorflow:loss = 1332.4324, step = 6901 (0.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 714.901\n",
            "INFO:tensorflow:loss = 982.5477, step = 7001 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 746.347\n",
            "INFO:tensorflow:loss = 1296.521, step = 7101 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 693.328\n",
            "INFO:tensorflow:loss = 1233.7336, step = 7201 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.392\n",
            "INFO:tensorflow:loss = 897.16064, step = 7301 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 692.783\n",
            "INFO:tensorflow:loss = 1229.7748, step = 7401 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 697.763\n",
            "INFO:tensorflow:loss = 1251.6902, step = 7501 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 678.835\n",
            "INFO:tensorflow:loss = 1299.5521, step = 7601 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 741.038\n",
            "INFO:tensorflow:loss = 1374.0037, step = 7701 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 709.298\n",
            "INFO:tensorflow:loss = 1528.2305, step = 7801 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 737.456\n",
            "INFO:tensorflow:loss = 1314.6888, step = 7901 (0.136 sec)\n",
            "INFO:tensorflow:global_step/sec: 699.243\n",
            "INFO:tensorflow:loss = 1147.3513, step = 8001 (0.147 sec)\n",
            "INFO:tensorflow:global_step/sec: 681.429\n",
            "INFO:tensorflow:loss = 1394.1636, step = 8101 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 681.059\n",
            "INFO:tensorflow:loss = 1045.6991, step = 8201 (0.146 sec)\n",
            "INFO:tensorflow:global_step/sec: 717.719\n",
            "INFO:tensorflow:loss = 1255.7166, step = 8301 (0.142 sec)\n",
            "INFO:tensorflow:global_step/sec: 729.367\n",
            "INFO:tensorflow:loss = 1213.3274, step = 8401 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 689.056\n",
            "INFO:tensorflow:loss = 947.8937, step = 8501 (0.145 sec)\n",
            "INFO:tensorflow:global_step/sec: 716.284\n",
            "INFO:tensorflow:loss = 1468.8993, step = 8601 (0.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 714.945\n",
            "INFO:tensorflow:loss = 1215.6611, step = 8701 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 747.617\n",
            "INFO:tensorflow:loss = 1475.9353, step = 8801 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 701.567\n",
            "INFO:tensorflow:loss = 1364.4841, step = 8901 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 677.051\n",
            "INFO:tensorflow:loss = 932.776, step = 9001 (0.148 sec)\n",
            "INFO:tensorflow:global_step/sec: 652.133\n",
            "INFO:tensorflow:loss = 1203.5076, step = 9101 (0.151 sec)\n",
            "INFO:tensorflow:global_step/sec: 740.852\n",
            "INFO:tensorflow:loss = 1226.8423, step = 9201 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 693.268\n",
            "INFO:tensorflow:loss = 1146.9174, step = 9301 (0.141 sec)\n",
            "INFO:tensorflow:global_step/sec: 741.308\n",
            "INFO:tensorflow:loss = 1206.7266, step = 9401 (0.135 sec)\n",
            "INFO:tensorflow:global_step/sec: 702.22\n",
            "INFO:tensorflow:loss = 1303.0813, step = 9501 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 738.204\n",
            "INFO:tensorflow:loss = 1454.0073, step = 9601 (0.137 sec)\n",
            "INFO:tensorflow:global_step/sec: 716.75\n",
            "INFO:tensorflow:loss = 1305.2009, step = 9701 (0.140 sec)\n",
            "INFO:tensorflow:global_step/sec: 643.265\n",
            "INFO:tensorflow:loss = 919.24146, step = 9801 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 717.404\n",
            "INFO:tensorflow:loss = 1437.8357, step = 9901 (0.140 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1024.7576.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "DNNRegression has RMSE of 38.309031284981884\n",
            "Just using average = 106.45216106390839 has RMSE of 38.84550843800256\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa50d9c4f90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/DNN_NY_ALL_BOROUGHS_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[87.57121]\n",
            "[87.57121]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTPPF1pmXATF"
      },
      "source": [
        "### Prediction\n",
        "\n",
        "This returns [87.57121]  - while there is no way to tell if this is correct or not, and with covid still a large part of daily lives, the NY collisions data has been updated to show 27 accidents have been recorded in the Manhattan area on the date selected.\n",
        "\n",
        "To validate this, a simple query was ran on the New York Collisions dataset:\n",
        "\n",
        "```sql\n",
        "SELECT *  FROM `bigquery-public-data.new_york_mv_collisions.nypd_mv_collisions`\n",
        "where timestamp between '2021-11-20'  and '2021-11-22'\n",
        "ORDER BY timestamp DESC\n",
        "```\n",
        "\n",
        "The result of this was saved (file name \"pred_check_results.csv\" and the location column removed (as this was a comma seperated value it caused issues) as well as the header.  A new python script was created (check_results.py) which used the getBoroghFromLatLong function used when creating the data.  The result was saved to a new file which then had the header inserted and the data filtered.\n",
        "\n",
        "While the result obtained is less than the \"recorded\" result, COVID is still very mich a factor in people's daily lives and the result be affected by this."
      ]
    }
  ]
}