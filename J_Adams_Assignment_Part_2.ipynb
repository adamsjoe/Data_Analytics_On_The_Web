{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J_Adams_Assignment_Part_2--.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2YM-cY3XAb1"
      },
      "source": [
        "# Training a linear regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4OkOIjgXImQ"
      },
      "source": [
        "### Background\n",
        "\n",
        "The dataset which was created for part 1 has been constructed so that each borough can be identified.  This means that a linear regressor could be made for each indivual borough.  As the code uses the dataset with the same structure, what works for one, would work for all.  However, in order to simplifiy this notebook, only one borough will be used.  That borough is Manhatten.\n",
        "\n",
        "To begin with, the data must first be loaded.  Once loaded, using the query method of the pandas dataframe the rows which are in Mahattan can be extracted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUkPRKJw1mm6"
      },
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load the data as per normal\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv', index_col=0)\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv')\n",
        "\n",
        "# now setup to query the dataframe for only the borough noted\n",
        "borough_df = df.query('BOROUGH==\"MANHATTAN\"')\n",
        "\n",
        "# remove 2012\n",
        "remove_2012 = borough_df.query('YEAR!=2012')\n",
        "\n",
        "# remove 2020\n",
        "remove_2020 = remove_2012.query('YEAR!=2020')\n",
        "\n",
        "#remove 2021\n",
        "remove_2021 = remove_2020.query('YEAR!=2021')\n",
        "\n",
        "manhat_df = remove_2021\n",
        "\n",
        "year_2013 = manhat_df.query(\"YEAR==2013\")\n",
        "# year_2014 = manhat_df.query(\"YEAR==2014\")\n",
        "# year_2015 = manhat_df.query(\"YEAR==2015\")\n",
        "# year_2016 = manhat_df.query(\"YEAR==2016\")\n",
        "# year_2017 = manhat_df.query(\"YEAR==2017\")\n",
        "# year_2018 = manhat_df.query(\"YEAR==2018\")\n",
        "# year_2019 = manhat_df.query(\"YEAR==2019\")\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYJbRFX5YExF"
      },
      "source": [
        "#### Data Verification\n",
        "\n",
        "Once the data has been loaded, it is a good idea to check this.  Printing only 6 rows shows that all are Manhattan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNzPMAL314nG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b5c024b-0bae-4dfa-dd57-10e8bffd8dd5"
      },
      "source": [
        "# check the data had loaded by printing it\n",
        "print(manhat_df[:6])\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "2   01-01-2017  MANHATTAN        7  ...          0         24        84\n",
            "8   01-02-2017  MANHATTAN        3  ...          0         23       135\n",
            "13  01-03-2017  MANHATTAN        3  ...          0         20       120\n",
            "17  01-04-2017  MANHATTAN        6  ...          0         14       109\n",
            "22  01-05-2017  MANHATTAN        1  ...          0         28       119\n",
            "26  01-06-2017  MANHATTAN        4  ...          0         31       141\n",
            "\n",
            "[6 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSW7NtK4dBAj"
      },
      "source": [
        "## Import numpy and shuffle\n",
        "\n",
        "Create a new shuffled data by using the random permutation function of numpy using the length of the original mahattan data frame.  In this particular data set this is important as the data is time series (or time series derived) and there could be patterns within the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-NlRVds2BEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199c2e94-cd09-4270-c3e6-a50767d8ab1d"
      },
      "source": [
        "import numpy as np\n",
        "shuffle_manhatten = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "print(shuffle_manhatten[:5])\n",
        "\n",
        "# setup constant for use later\n",
        "SCALE_NUM_COLS = 1.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "8621   2016-07-24  MANHATTAN        7  ...          0         17        96\n",
            "3625   2013-10-29  MANHATTAN        2  ...          0         22       128\n",
            "16593  25-12-2017  MANHATTAN        1  ...          0         11        45\n",
            "1018   17-12-2017  MANHATTAN        7  ...          0         14       100\n",
            "2973   2013-06-20  MANHATTAN        4  ...          0         19       123\n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFG25By8dtfc"
      },
      "source": [
        "## Predictors, Training set and Testing set\n",
        "\n",
        "Firstly the predictors are created.  These are created from the shuffled data and only the third, fourth, fifth, seventh and last column is used.  These are, in order, year, month, day, temp and num_cols (number of collisions).  If the data was not being filtered by borough at the start, then the borough would need to be brought in also.\n",
        "\n",
        "The Target is then defined - this is the last column in the shuffled dataset.\n",
        "\n",
        "The training set will be 80% of the full data set (0.8) and the testing data will be the remainder - so in this case, 100 - 80 = 20%\n",
        "\n",
        "Constants are setup for the number of predictors (3 in this case: year, month and day) and the number of outputs (or targets, which is 1 here.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01AcNdrBh3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a4ffcb-820b-4bb1-819c-5a296737372f"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[3,4,5]]\n",
        "print(predictors_manhatten[:6])\n",
        "\n",
        "# We want the last column (the NUM_COLS)\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "print(targets_manhattan[:6])\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month and year = 3 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 3\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       YEAR  MONTH  DAY\n",
            "8621   2016      7   24\n",
            "3625   2013     10   29\n",
            "16593  2017     12   25\n",
            "1018   2017     12   17\n",
            "2973   2013      6   20\n",
            "10176  2018      5   31\n",
            "8621      96\n",
            "3625     128\n",
            "16593     45\n",
            "1018     100\n",
            "2973     123\n",
            "10176    129\n",
            "Name: NUM_COLS, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9cyW1wjfAIk"
      },
      "source": [
        "### Verification\n",
        "\n",
        "Just a simple print to ensure the predictor and values are populated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYOnh5yUElQO"
      },
      "source": [
        "print(predictors_manhatten.values)\n",
        "print(predictors_manhatten)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axySTDY1fKHw"
      },
      "source": [
        "## The Tensorflow bit.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIj_sLztBlsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e1c737-547c-4977-a4d3-9007900d0c40"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model'\n",
        "\n",
        "# remove the last training model\n",
        "shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.1), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\\n\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan,NO_TARGETS)/SCALE_NUM_COLS, steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - predslistscale)**2))\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('\\n\\n// Lnear Regression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('\\n\\n// Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-6-40571ecafc0b>:23: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please convert numpy dtypes explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/linear.py:740: regression_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.contrib.estimator.*_head.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc5ce761c90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:From <ipython-input-6-40571ecafc0b>:23: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to the Estimator interface.\n",
            "// Starting to train Manhattan model............\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 14377.93, step = 1\n",
            "INFO:tensorflow:global_step/sec: 786.045\n",
            "INFO:tensorflow:loss = 594.99554, step = 101 (0.129 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.474\n",
            "INFO:tensorflow:loss = 509.33386, step = 201 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.097\n",
            "INFO:tensorflow:loss = 561.8303, step = 301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 868.179\n",
            "INFO:tensorflow:loss = 973.5773, step = 401 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 850.937\n",
            "INFO:tensorflow:loss = 700.7554, step = 501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 887.058\n",
            "INFO:tensorflow:loss = 663.47815, step = 601 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.578\n",
            "INFO:tensorflow:loss = 771.8787, step = 701 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.147\n",
            "INFO:tensorflow:loss = 693.1472, step = 801 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 926.904\n",
            "INFO:tensorflow:loss = 693.8771, step = 901 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 932.814\n",
            "INFO:tensorflow:loss = 559.61664, step = 1001 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 966.031\n",
            "INFO:tensorflow:loss = 662.7099, step = 1101 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 857.691\n",
            "INFO:tensorflow:loss = 618.69135, step = 1201 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 944.438\n",
            "INFO:tensorflow:loss = 786.1016, step = 1301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 967.049\n",
            "INFO:tensorflow:loss = 708.27356, step = 1401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1011.3\n",
            "INFO:tensorflow:loss = 865.474, step = 1501 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 907.53\n",
            "INFO:tensorflow:loss = 721.2954, step = 1601 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 905.966\n",
            "INFO:tensorflow:loss = 980.94995, step = 1701 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 956.047\n",
            "INFO:tensorflow:loss = 861.77905, step = 1801 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 913.135\n",
            "INFO:tensorflow:loss = 756.4154, step = 1901 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1007\n",
            "INFO:tensorflow:loss = 497.40094, step = 2001 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.274\n",
            "INFO:tensorflow:loss = 692.02344, step = 2101 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.749\n",
            "INFO:tensorflow:loss = 945.2992, step = 2201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 938.071\n",
            "INFO:tensorflow:loss = 724.0498, step = 2301 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.873\n",
            "INFO:tensorflow:loss = 846.51514, step = 2401 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.595\n",
            "INFO:tensorflow:loss = 865.0222, step = 2501 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 829.122\n",
            "INFO:tensorflow:loss = 679.43726, step = 2601 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.087\n",
            "INFO:tensorflow:loss = 892.23975, step = 2701 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 921.985\n",
            "INFO:tensorflow:loss = 792.176, step = 2801 (0.110 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2801 vs previous value: 2801. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 863.1\n",
            "INFO:tensorflow:loss = 700.86206, step = 2901 (0.117 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2901 vs previous value: 2901. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 761.609\n",
            "INFO:tensorflow:loss = 870.0916, step = 3001 (0.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.021\n",
            "INFO:tensorflow:loss = 885.21497, step = 3101 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 848.32\n",
            "INFO:tensorflow:loss = 810.642, step = 3201 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 826.767\n",
            "INFO:tensorflow:loss = 525.15155, step = 3301 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 965.7\n",
            "INFO:tensorflow:loss = 731.3435, step = 3401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 871.578\n",
            "INFO:tensorflow:loss = 845.5406, step = 3501 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.283\n",
            "INFO:tensorflow:loss = 747.5636, step = 3601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 886.655\n",
            "INFO:tensorflow:loss = 585.5874, step = 3701 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 889.244\n",
            "INFO:tensorflow:loss = 669.4839, step = 3801 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.553\n",
            "INFO:tensorflow:loss = 748.06, step = 3901 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 960.201\n",
            "INFO:tensorflow:loss = 833.7274, step = 4001 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 818.051\n",
            "INFO:tensorflow:loss = 783.2151, step = 4101 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.583\n",
            "INFO:tensorflow:loss = 773.84924, step = 4201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 869.079\n",
            "INFO:tensorflow:loss = 722.63025, step = 4301 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 894.357\n",
            "INFO:tensorflow:loss = 1047.0336, step = 4401 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 859.135\n",
            "INFO:tensorflow:loss = 637.14404, step = 4501 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 853.735\n",
            "INFO:tensorflow:loss = 690.8537, step = 4601 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 835.9\n",
            "INFO:tensorflow:loss = 849.96155, step = 4701 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.644\n",
            "INFO:tensorflow:loss = 1170.1016, step = 4801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 932.82\n",
            "INFO:tensorflow:loss = 699.29663, step = 4901 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 909.303\n",
            "INFO:tensorflow:loss = 584.3854, step = 5001 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 956.889\n",
            "INFO:tensorflow:loss = 590.2904, step = 5101 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 880.733\n",
            "INFO:tensorflow:loss = 1226.9304, step = 5201 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 901.565\n",
            "INFO:tensorflow:loss = 768.7676, step = 5301 (0.113 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 5301 vs previous value: 5301. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 873.142\n",
            "INFO:tensorflow:loss = 878.8083, step = 5401 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.227\n",
            "INFO:tensorflow:loss = 718.3598, step = 5501 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 945.566\n",
            "INFO:tensorflow:loss = 602.02856, step = 5601 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.01\n",
            "INFO:tensorflow:loss = 916.5223, step = 5701 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 1008.23\n",
            "INFO:tensorflow:loss = 1198.4243, step = 5801 (0.102 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 5801 vs previous value: 5801. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 853.954\n",
            "INFO:tensorflow:loss = 822.12585, step = 5901 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 885.048\n",
            "INFO:tensorflow:loss = 1058.8916, step = 6001 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 860.831\n",
            "INFO:tensorflow:loss = 696.9828, step = 6101 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 873.398\n",
            "INFO:tensorflow:loss = 682.4811, step = 6201 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 941.068\n",
            "INFO:tensorflow:loss = 615.8556, step = 6301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 964.931\n",
            "INFO:tensorflow:loss = 782.27594, step = 6401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 907.039\n",
            "INFO:tensorflow:loss = 629.96405, step = 6501 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 963.585\n",
            "INFO:tensorflow:loss = 709.87946, step = 6601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 971.518\n",
            "INFO:tensorflow:loss = 715.7108, step = 6701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 848.356\n",
            "INFO:tensorflow:loss = 739.0529, step = 6801 (0.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 917.48\n",
            "INFO:tensorflow:loss = 623.0346, step = 6901 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.619\n",
            "INFO:tensorflow:loss = 986.2368, step = 7001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.727\n",
            "INFO:tensorflow:loss = 654.589, step = 7101 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 816.623\n",
            "INFO:tensorflow:loss = 794.3562, step = 7201 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 926.99\n",
            "INFO:tensorflow:loss = 633.7671, step = 7301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.716\n",
            "INFO:tensorflow:loss = 632.5032, step = 7401 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1020.12\n",
            "INFO:tensorflow:loss = 832.34973, step = 7501 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 886.882\n",
            "INFO:tensorflow:loss = 630.8567, step = 7601 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 974.117\n",
            "INFO:tensorflow:loss = 944.59314, step = 7701 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.295\n",
            "INFO:tensorflow:loss = 614.55945, step = 7801 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 887.208\n",
            "INFO:tensorflow:loss = 694.68616, step = 7901 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.603\n",
            "INFO:tensorflow:loss = 583.2998, step = 8001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 841.466\n",
            "INFO:tensorflow:loss = 755.39355, step = 8101 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 908.629\n",
            "INFO:tensorflow:loss = 838.182, step = 8201 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 928.706\n",
            "INFO:tensorflow:loss = 927.46497, step = 8301 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 962.018\n",
            "INFO:tensorflow:loss = 854.35913, step = 8401 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 896.727\n",
            "INFO:tensorflow:loss = 616.8119, step = 8501 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 913.919\n",
            "INFO:tensorflow:loss = 550.7373, step = 8601 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 846.932\n",
            "INFO:tensorflow:loss = 770.42145, step = 8701 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 890.276\n",
            "INFO:tensorflow:loss = 766.7519, step = 8801 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 923.961\n",
            "INFO:tensorflow:loss = 708.8989, step = 8901 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 812.074\n",
            "INFO:tensorflow:loss = 757.85815, step = 9001 (0.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 979.243\n",
            "INFO:tensorflow:loss = 786.13165, step = 9101 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 894.649\n",
            "INFO:tensorflow:loss = 645.14233, step = 9201 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 988.647\n",
            "INFO:tensorflow:loss = 551.4441, step = 9301 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1016.84\n",
            "INFO:tensorflow:loss = 1245.1937, step = 9401 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.281\n",
            "INFO:tensorflow:loss = 773.3009, step = 9501 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 863.333\n",
            "INFO:tensorflow:loss = 687.22455, step = 9601 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 911.544\n",
            "INFO:tensorflow:loss = 630.38904, step = 9701 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 926.443\n",
            "INFO:tensorflow:loss = 1262.6857, step = 9801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 856.72\n",
            "INFO:tensorflow:loss = 705.3638, step = 9901 (0.118 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 991.7403.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "// Lnear Regression has RMSE of 29.92991502816066\n",
            "\n",
            "\n",
            "// Just using average = 120.4481409001957 has RMSE of 25.53645562873909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t23ehycblB5R"
      },
      "source": [
        "## Initial Output\n",
        "\n",
        "The RSME is quite large, which would indicate a not accurate model - however this model is only trying to predict based on a day.  Not using any extra conditions.  Temperature could be added in and this may affect the the output.\n",
        "\n",
        "The model needs to be tested first, to do this some values will be fed in to be the target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pizTrw7Aks8S"
      },
      "source": [
        "## Inital Prediction\n",
        "\n",
        "```python\n",
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'DAY' : [1, 1, 1]\n",
        "        })\n",
        "\n",
        "```\n",
        "\n",
        "Setting up the values for preduction, 3 have been chosen.  1/1/2013, 1/6/2016 and 1.12/2022 will be fed into model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjS3zTafVMB8",
        "outputId": "5761ab67-bd87-4a2e-9909-c07a28148621"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'DAY' : [1, 1, 1]\n",
        "        })\n",
        "\n",
        "# create a copy of 2013\n",
        "cpy = year_2013\n",
        "\n",
        "# # now drop all the fields we don't need\n",
        "trmmed = cpy.drop(columns=[\"DATE\",\"BOROUGH\",\"WEEKDAY\",\"COLLISION_DATE\",\"TEMP\",\"DEWP\",\"SLP\",\"VISIB\",\"WDSP\",\"MXPSD\",\"GUST\",\"MAX\",\"MIN\",\"PRCP\",\"SNDP\",\"FOG\",\"CYC_KILL\",\"CYC_INJD\",\"MOTO_KILL\",\"MOTO_INJD\",\"PEDS_KILL\",\"PEDS_INJD\",\"PERS_KILL\",\"PERS_INJD\",\"NUM_COLS\"])\n",
        "\n",
        "# print(trmmed)\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)\n",
        "                                                                                 )\n",
        ")\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "# print(preds)\n",
        "\n",
        "# The Number of collisions scale will be 106.072969 - which is the average number of collisions in Manhattan (359057 (collisions)/ 3385 (days))\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 106.072969\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc5ce720550>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[130.69444 136.68161 144.02034]\n",
            "[13863.147 14498.224 15276.665]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hnzo1hOFa-l"
      },
      "source": [
        "### Result of First Run\n",
        "\n",
        "The model is being asked to predict 3 dates.  Two of these dates are known, these can be used as \"control\" dates - the number of collisions is known - so these should be fairly accurate (or at least, that is the theory...)\n",
        "\n",
        "The dates are:\n",
        "\n",
        "Date|Prediction|Actual\n",
        ":--:|:--------:|:----:\n",
        "1/1/2013|130|78\n",
        "1/6/2016|136|121\n",
        "1/12/2020|144|N/A\n",
        "\n",
        "While the trend is, generally, going upwards, which does **sort of** look ok.. As noted above, it would be a good idea to try to add in an additional predictor.  The Temp value should suffice.\n",
        "\n",
        "**Note** these values may change if the notebook is run at a later stage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65w8sb15lZj3"
      },
      "source": [
        "## Adding in Temp\n",
        "\n",
        "The code cells will be copied from above, this time the predictors will be ammeded to include temperature.\n",
        "\n",
        "**Note:** For brevity, the additional prints will not be inluded and all code will be added to the one cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxd35_S4ln2-",
        "outputId": "df034782-4728-4abc-90da-522e81ed3629"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[3,4,5,7]]\n",
        "print(predictors_manhatten[:6])\n",
        "\n",
        "# We want the last column (the NUM_COLS)\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "print(targets_manhattan[:6])\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month, year and now temp = 4 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 4\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model_including_temp'\n",
        "\n",
        "# remove the last training model\n",
        "shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "\n",
        "# estimators for each borough\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(\n",
        "    model_dir=manhattan_dir, \n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.1), \n",
        "    enable_centered_bias=False, \n",
        "    feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "    )\n",
        ")\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\\n\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan,NO_TARGETS)/SCALE_NUM_COLS, steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - predslistscale)**2))\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale) ** 2))\n",
        "print('\\n\\n// Lnear Regression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg) ** 2))\n",
        "print('\\n\\n// Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       YEAR  MONTH  DAY  TEMP\n",
            "8621   2016      7   24  73.2\n",
            "3625   2013     10   29  47.5\n",
            "16593  2017     12   25  41.1\n",
            "1018   2017     12   17  27.6\n",
            "2973   2013      6   20  60.6\n",
            "10176  2018      5   31  55.1\n",
            "8621      96\n",
            "3625     128\n",
            "16593     45\n",
            "1018     100\n",
            "2973     123\n",
            "10176    129\n",
            "Name: NUM_COLS, dtype: int64\n",
            "1.15.2\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc5cb2b9950>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp', '_session_creation_timeout_secs': 7200}\n",
            "// Starting to train Manhattan model............\n",
            "\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model_including_temp/model.ckpt.\n",
            "INFO:tensorflow:loss = 14377.93, step = 1\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1 vs previous value: 1. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 725.341\n",
            "INFO:tensorflow:loss = 542.2197, step = 101 (0.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 984.262\n",
            "INFO:tensorflow:loss = 513.24225, step = 201 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 913.841\n",
            "INFO:tensorflow:loss = 535.5951, step = 301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 906.784\n",
            "INFO:tensorflow:loss = 930.56305, step = 401 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 921.025\n",
            "INFO:tensorflow:loss = 661.5848, step = 501 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 897.732\n",
            "INFO:tensorflow:loss = 649.0418, step = 601 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.247\n",
            "INFO:tensorflow:loss = 696.3821, step = 701 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 860.326\n",
            "INFO:tensorflow:loss = 738.2445, step = 801 (0.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 965.106\n",
            "INFO:tensorflow:loss = 630.58704, step = 901 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 937.082\n",
            "INFO:tensorflow:loss = 573.26587, step = 1001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.526\n",
            "INFO:tensorflow:loss = 697.34406, step = 1101 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.258\n",
            "INFO:tensorflow:loss = 601.0256, step = 1201 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 963.059\n",
            "INFO:tensorflow:loss = 752.7862, step = 1301 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 879.243\n",
            "INFO:tensorflow:loss = 692.1664, step = 1401 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.133\n",
            "INFO:tensorflow:loss = 750.49, step = 1501 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1014.63\n",
            "INFO:tensorflow:loss = 734.8532, step = 1601 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 876.223\n",
            "INFO:tensorflow:loss = 986.69824, step = 1701 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 914.593\n",
            "INFO:tensorflow:loss = 771.04065, step = 1801 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 973.028\n",
            "INFO:tensorflow:loss = 807.63806, step = 1901 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 938.642\n",
            "INFO:tensorflow:loss = 500.0745, step = 2001 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 987.339\n",
            "INFO:tensorflow:loss = 661.60803, step = 2101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 938.995\n",
            "INFO:tensorflow:loss = 774.17053, step = 2201 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 922.908\n",
            "INFO:tensorflow:loss = 773.8601, step = 2301 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 934.487\n",
            "INFO:tensorflow:loss = 834.0952, step = 2401 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1001.15\n",
            "INFO:tensorflow:loss = 753.2267, step = 2501 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 885.928\n",
            "INFO:tensorflow:loss = 686.16833, step = 2601 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 915.05\n",
            "INFO:tensorflow:loss = 1091.9525, step = 2701 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.624\n",
            "INFO:tensorflow:loss = 770.00055, step = 2801 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 941.816\n",
            "INFO:tensorflow:loss = 668.3123, step = 2901 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 911.797\n",
            "INFO:tensorflow:loss = 828.2936, step = 3001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.87\n",
            "INFO:tensorflow:loss = 808.5254, step = 3101 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.952\n",
            "INFO:tensorflow:loss = 753.7384, step = 3201 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 842.313\n",
            "INFO:tensorflow:loss = 521.6911, step = 3301 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.366\n",
            "INFO:tensorflow:loss = 733.0217, step = 3401 (0.108 sec)\n",
            "INFO:tensorflow:global_step/sec: 949.32\n",
            "INFO:tensorflow:loss = 818.9491, step = 3501 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 817.28\n",
            "INFO:tensorflow:loss = 673.2246, step = 3601 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.286\n",
            "INFO:tensorflow:loss = 572.4359, step = 3701 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 982.648\n",
            "INFO:tensorflow:loss = 625.32556, step = 3801 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1014.47\n",
            "INFO:tensorflow:loss = 770.7981, step = 3901 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 971.968\n",
            "INFO:tensorflow:loss = 823.1068, step = 4001 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.807\n",
            "INFO:tensorflow:loss = 727.0371, step = 4101 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 830.346\n",
            "INFO:tensorflow:loss = 783.7716, step = 4201 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.825\n",
            "INFO:tensorflow:loss = 637.834, step = 4301 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 961.904\n",
            "INFO:tensorflow:loss = 966.9698, step = 4401 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 957.597\n",
            "INFO:tensorflow:loss = 698.4629, step = 4501 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 907.408\n",
            "INFO:tensorflow:loss = 656.7649, step = 4601 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 904.385\n",
            "INFO:tensorflow:loss = 824.1846, step = 4701 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 994.399\n",
            "INFO:tensorflow:loss = 1265.9652, step = 4801 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 942.722\n",
            "INFO:tensorflow:loss = 672.6726, step = 4901 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.093\n",
            "INFO:tensorflow:loss = 567.81134, step = 5001 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 800.946\n",
            "INFO:tensorflow:loss = 569.9404, step = 5101 (0.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 917.313\n",
            "INFO:tensorflow:loss = 1247.6921, step = 5201 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 915.523\n",
            "INFO:tensorflow:loss = 729.07214, step = 5301 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 996.956\n",
            "INFO:tensorflow:loss = 933.9381, step = 5401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 885.263\n",
            "INFO:tensorflow:loss = 673.8086, step = 5501 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.601\n",
            "INFO:tensorflow:loss = 562.0004, step = 5601 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.176\n",
            "INFO:tensorflow:loss = 842.1742, step = 5701 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 965.049\n",
            "INFO:tensorflow:loss = 1065.2762, step = 5801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 983.966\n",
            "INFO:tensorflow:loss = 697.50574, step = 5901 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 974.71\n",
            "INFO:tensorflow:loss = 1176.5295, step = 6001 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 927.076\n",
            "INFO:tensorflow:loss = 718.07965, step = 6101 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 916.255\n",
            "INFO:tensorflow:loss = 801.57605, step = 6201 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 812.651\n",
            "INFO:tensorflow:loss = 624.2477, step = 6301 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 845.357\n",
            "INFO:tensorflow:loss = 704.16, step = 6401 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 827.163\n",
            "INFO:tensorflow:loss = 594.6397, step = 6501 (0.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 933.478\n",
            "INFO:tensorflow:loss = 704.9591, step = 6601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 986.259\n",
            "INFO:tensorflow:loss = 666.9367, step = 6701 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 918.991\n",
            "INFO:tensorflow:loss = 748.79626, step = 6801 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 877.973\n",
            "INFO:tensorflow:loss = 592.7495, step = 6901 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 828.308\n",
            "INFO:tensorflow:loss = 1123.8163, step = 7001 (0.121 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.859\n",
            "INFO:tensorflow:loss = 596.9319, step = 7101 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 954.164\n",
            "INFO:tensorflow:loss = 772.78204, step = 7201 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 870.616\n",
            "INFO:tensorflow:loss = 629.69836, step = 7301 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 853.469\n",
            "INFO:tensorflow:loss = 541.0117, step = 7401 (0.120 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.753\n",
            "INFO:tensorflow:loss = 867.4608, step = 7501 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 977.224\n",
            "INFO:tensorflow:loss = 650.8612, step = 7601 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 952.718\n",
            "INFO:tensorflow:loss = 838.8803, step = 7701 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 846.209\n",
            "INFO:tensorflow:loss = 644.7523, step = 7801 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 875.956\n",
            "INFO:tensorflow:loss = 654.1332, step = 7901 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.92\n",
            "INFO:tensorflow:loss = 560.80115, step = 8001 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 924.831\n",
            "INFO:tensorflow:loss = 694.80493, step = 8101 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 935.483\n",
            "INFO:tensorflow:loss = 984.3589, step = 8201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 948.798\n",
            "INFO:tensorflow:loss = 986.74023, step = 8301 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 995.598\n",
            "INFO:tensorflow:loss = 772.1818, step = 8401 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 962.186\n",
            "INFO:tensorflow:loss = 686.64734, step = 8501 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 978.195\n",
            "INFO:tensorflow:loss = 515.2197, step = 8601 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 942.72\n",
            "INFO:tensorflow:loss = 831.7264, step = 8701 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 946.336\n",
            "INFO:tensorflow:loss = 927.06683, step = 8801 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 904.682\n",
            "INFO:tensorflow:loss = 659.5438, step = 8901 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 874.413\n",
            "INFO:tensorflow:loss = 766.4855, step = 9001 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 957.814\n",
            "INFO:tensorflow:loss = 706.2861, step = 9101 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 931.322\n",
            "INFO:tensorflow:loss = 611.4877, step = 9201 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.192\n",
            "INFO:tensorflow:loss = 645.3656, step = 9301 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.871\n",
            "INFO:tensorflow:loss = 1238.1587, step = 9401 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 921.801\n",
            "INFO:tensorflow:loss = 702.30884, step = 9501 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 823.545\n",
            "INFO:tensorflow:loss = 691.7969, step = 9601 (0.118 sec)\n",
            "INFO:tensorflow:global_step/sec: 919.975\n",
            "INFO:tensorflow:loss = 622.9862, step = 9701 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 885.358\n",
            "INFO:tensorflow:loss = 1092.25, step = 9801 (0.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 976.357\n",
            "INFO:tensorflow:loss = 782.3403, step = 9901 (0.104 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model_including_temp/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 932.36206.\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "\n",
            "// Lnear Regression has RMSE of 29.885361749251835\n",
            "\n",
            "\n",
            "// Just using average = 120.4481409001957 has RMSE of 25.53645562873909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMnfjCXRmT_D",
        "outputId": "8155b97e-6e48-4e45-b829-2335dc6207c4"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'YEAR' : [2013,2016,2022],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'DAY' : [1, 1, 1],\n",
        "         'TEMP': [35,60,30]\n",
        "        })\n",
        "\n",
        "# create a copy of 2013\n",
        "cpy = year_2013\n",
        "\n",
        "# # now drop all the fields we don't need\n",
        "trmmed = cpy.drop(columns=[\"DATE\",\"BOROUGH\",\"WEEKDAY\",\"COLLISION_DATE\",\"TEMP\",\"DEWP\",\"SLP\",\"VISIB\",\"WDSP\",\"MXPSD\",\"GUST\",\"MAX\",\"MIN\",\"PRCP\",\"SNDP\",\"FOG\",\"CYC_KILL\",\"CYC_INJD\",\"MOTO_KILL\",\"MOTO_INJD\",\"PEDS_KILL\",\"PEDS_INJD\",\"PERS_KILL\",\"PERS_INJD\",\"NUM_COLS\"])\n",
        "\n",
        "# print(trmmed)\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)\n",
        "                                                                                 )\n",
        ")\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "# print(preds)\n",
        "\n",
        "# The Number of collisions scale will be 106.072969 - which is the average number of collisions in Manhattan (359057 (collisions)/ 3385 (days))\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 106.072969\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n",
        "\n",
        "print(prednorm)\n",
        "print(pred)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc5cb1f6b10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model_including_temp', '_session_creation_timeout_secs': 7200}\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model_including_temp/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[128.71606 141.06412 133.82452]\n",
            "[13653.295 14963.09  14195.164]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M1tZRi3mxmo"
      },
      "source": [
        "### After Temp\n",
        "\n",
        "After adding in the temp, the values have changed:\n",
        "\n",
        "\n",
        "Date|Prediction (no temp)|Prediction (with temp)|Actual\n",
        ":--:|:------------------:|:--------------------:|:----:\n",
        "1/1/2013|122|117|78|\n",
        "1/6/2016|128|129|121|\n",
        "1/12/2020|135|121|N/A|\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBjBlx73xEyn"
      },
      "source": [
        "\n",
        "# # trying to graph a full year of \"real\" data against a full year of \"predicted\" data - and it shows it is a terrible model :(\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import matplotlib.dates as mdates\n",
        "# from matplotlib.dates import DateFormatter\n",
        "# import seaborn as sns\n",
        "# import pandas as pd\n",
        "\n",
        "# # Handle date time conversions between pandas and matplotlib\n",
        "# from pandas.plotting import register_matplotlib_converters\n",
        "# register_matplotlib_converters()\n",
        "\n",
        "# # Use white grid plot background from seaborn\n",
        "# sns.set(font_scale=1.5, style=\"whitegrid\")\n",
        "\n",
        "# # load the data as per normal\n",
        "# model_df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv', parse_dates=['DATE'], index_col=['DATE'])\n",
        "\n",
        "# # now setup to query the dataframe for only the borough noted\n",
        "# model_borough_df = model_df.query('BOROUGH==\"MANHATTAN\"')\n",
        "\n",
        "# # remove 2012\n",
        "# model_remove_2012 = model_borough_df.query('YEAR!=2012')\n",
        "\n",
        "# # remove 2020\n",
        "# model_remove_2020 = model_remove_2012.query('YEAR!=2020')\n",
        "\n",
        "# #remove 2021\n",
        "# model_remove_2021 = model_remove_2020.query('YEAR!=2021')\n",
        "\n",
        "# model_manhat_df = model_remove_2021\n",
        "\n",
        "# model_year_2013 = model_manhat_df.query(\"YEAR==2013\")\n",
        "\n",
        "# model_trimmed_2013 = model_year_2013.drop(columns=[\"BOROUGH\",\"YEAR\",\"MONTH\",\"DAY\",\"WEEKDAY\",\"COLLISION_DATE\",\"TEMP\",\"DEWP\",\"SLP\",\"VISIB\",\"WDSP\",\"MXPSD\",\"GUST\",\"MAX\",\"MIN\",\"PRCP\",\"SNDP\",\"FOG\",\"CYC_KILL\",\"CYC_INJD\",\"MOTO_KILL\",\"MOTO_INJD\",\"PEDS_KILL\",\"PEDS_INJD\",\"PERS_KILL\",\"PERS_INJD\"])\n",
        "\n",
        "# predictions_list = prednorm.split()\n",
        "# # predictions_list = pred.split()\n",
        "\n",
        "# model_pred_data = pd.DataFrame(columns=['DATE', 'NUM_COLS'])\n",
        "\n",
        "# for x in range(len(trmmed)):\n",
        "#   valYear = trmmed['YEAR'].values[x]\n",
        "#   valMonth = trmmed['MONTH'].values[x]   \n",
        "#   valDay = trmmed['DAY'].values[x]\n",
        "#   if valMonth < 10:\n",
        "#     valMonth = '0%s' % (valMonth)\n",
        "#   if valDay < 10:\n",
        "#     valDay = '0%s' % (valDay)\n",
        "#   date_string = '%s-%s-%s' % (valYear, valMonth, valDay)  \n",
        "#   # print(f\"Row {x} - Year will be {valYear}, Month will be {valMonth}, Day will be {valDay}\")\n",
        "\n",
        "#   temp_collisions = predictions_list[x]\n",
        "#   valCols = temp_collisions.replace('[', '')\n",
        "#   temp_cols = float(valCols)\n",
        "  \n",
        "#   model_pred_data = model_pred_data.append({'DATE': date_string, 'NUM_COLS': int(temp_cols)},ignore_index=True)\n",
        "\n",
        "# # adding an index\n",
        "# date_time_index = pd.to_datetime(model_pred_data['DATE'])\n",
        "# datetime_index = pd.DatetimeIndex(date_time_index.values)\n",
        "# new_things = model_pred_data.set_index(datetime_index)\n",
        "\n",
        "# # converting the num_cols to ints as this wasn't explicit enough above.\n",
        "# new_things[\"NUM_COLS\"] = new_things[\"NUM_COLS\"].astype(str).astype(int)\n",
        "# print(\"model post set\")\n",
        "# print(new_things)\n",
        "# # print(new_things.info())\n",
        "# # print(new_things.index.dtype)\n",
        "\n",
        "# print(\"\\n\\nother one\")\n",
        "# print(model_trimmed_2013)\n",
        "# # print(model_trimmed_2013.info())\n",
        "# # print(model_trimmed_2013.index.dtype)\n",
        "\n",
        "# # Create figure and plot space\n",
        "# fig, ax = plt.subplots(figsize=(24, 24))\n",
        "# ax = plt.axes()\n",
        "\n",
        "# ax.plot(model_trimmed_2013['NUM_COLS'], label=\"Accidents from the data\")\n",
        "# ax.plot(new_things['NUM_COLS'], label=\"Accidents from model\")\n",
        "# ax.legend()\n",
        "# ax.set(xlabel=\"Date\",\n",
        "#        ylabel=\"Number Collisions\",\n",
        "#        title=\"2013 Accidents\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVR7uKHFqUKR"
      },
      "source": [
        "now maybe add in a second model - this one with 4 predictors (the temp being the other one)"
      ]
    }
  ]
}