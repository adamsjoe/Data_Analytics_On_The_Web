{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J_Adams_Assignment_Part_2--.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "s4OkOIjgXImQ",
        "YYJbRFX5YExF",
        "I9cyW1wjfAIk"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2YM-cY3XAb1"
      },
      "source": [
        "# Training a linear regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4OkOIjgXImQ"
      },
      "source": [
        "### Background\n",
        "\n",
        "The dataset which was created for part 1 has been constructed so that each borough can be identified.  This means that a linear regressor could be made for each indivual borough.  As the code uses the dataset with the same structure, what works for one, would work for all.  However, in order to simplifiy this notebook, only one borough will be used.  That borough is Manhatten.\n",
        "\n",
        "To begin with, the data must first be loaded.  Once loaded, using the query method of the pandas dataframe the rows which are in Mahattan can be extracted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUkPRKJw1mm6"
      },
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load the data as per normal\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv', index_col=0)\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv')\n",
        "\n",
        "# now setup to query the dataframe for only the boroughs noted\n",
        "manhat_df = df.query('BOROUGH==\"MANHATTAN\"').head()\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYJbRFX5YExF"
      },
      "source": [
        "#### Data Verification\n",
        "\n",
        "Once the data has been loaded, it is a good idea to check this.  Printing only 6 rows shows that all are Manhattan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNzPMAL314nG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e0908b-c5de-4aa5-a2eb-964f8e7e478a"
      },
      "source": [
        "# check the data had loaded by printing it\n",
        "print(manhat_df[:6])\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "0   2012-08-21  MANHATTAN        2  ...          0         28       109\n",
            "6   2012-10-27  MANHATTAN        6  ...          0         20       122\n",
            "13  2012-08-25  MANHATTAN        6  ...          0         22        97\n",
            "16  2012-09-09  MANHATTAN        7  ...          0         29       109\n",
            "20  2012-09-17  MANHATTAN        1  ...          1         27       123\n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSW7NtK4dBAj"
      },
      "source": [
        "## Import numpy and shuffle\n",
        "\n",
        "Create a new shuffled data by using the random permutation function of numpy using the length of the original mahattan data frame.  In this particular data set this is important as the data is time series (or time series derived) and there could be patterns within the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-NlRVds2BEM"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "shuffle_manhatten = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "shuffle_manhatten[:5]\n",
        "\n",
        "# setup constant for use later\n",
        "SCALE_NUM_COLS = 1"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFG25By8dtfc"
      },
      "source": [
        "## Predictors, Training set and Testing set\n",
        "\n",
        "Firstly the predictors are created.  These are created from the shuffled data and only the third, fourth, fifth, seventh and last column is used.  These are, in order, year, month, day, temp and num_cols (number of collisions).  If the data was not being filtered by borough at the start, then the borough would need to be brought in also.\n",
        "\n",
        "The Target is then defined - this is the last column in the shuffled dataset.\n",
        "\n",
        "The training set will be 80% of the full data set (0.8) and the testing data will be the remainder - so in this case, 100 - 80 = 20%\n",
        "\n",
        "Constants are setup for the number of predictors (3 in this case: year, month and day) and the number of outputs (or targets, which is 1 here.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01AcNdrBh3o"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[3,4,5]]\n",
        "\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month and year = 3 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 3\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9cyW1wjfAIk"
      },
      "source": [
        "### Verification\n",
        "\n",
        "Just a simple print to ensure the predictor and values are populated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYOnh5yUElQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf9b1e19-bc28-411b-ec67-2d304148f4e5"
      },
      "source": [
        "print(predictors_manhatten.values)\n",
        "print(predictors_manhatten)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2012    8   21]\n",
            " [2012    9    9]\n",
            " [2012    8   25]\n",
            " [2012    9   17]\n",
            " [2012   10   27]]\n",
            "    YEAR  MONTH  DAY\n",
            "0   2012      8   21\n",
            "16  2012      9    9\n",
            "13  2012      8   25\n",
            "20  2012      9   17\n",
            "6   2012     10   27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axySTDY1fKHw"
      },
      "source": [
        "## The Tensorflow bit.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIj_sLztBlsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0176b7f9-11e7-4a8b-ff14-47fc81596105"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model'\n",
        "\n",
        "# remove the last training model\n",
        "shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "\n",
        "# estimators for each borough\n",
        "# estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(\n",
        "#     model_dir=manhattan_dir, \n",
        "#     hidden_units=[20,18,14], \n",
        "#     optimizer=tf.train.AdamOptimizer(learning_rate=0.01), \n",
        "#     enable_centered_bias=False, \n",
        "#     feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "#     )\n",
        "# )\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, optimizer=tf.train.AdamOptimizer(learning_rate=0.1), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)))\n",
        "\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan, \n",
        "    NO_TARGETS)/SCALE_NUM_COLS, \n",
        "    steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale)**2))\n",
        "print('// DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg)**2))\n",
        "print('// Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7750997810>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "// Starting to train Manhattan model............\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 12075.0, step = 1\n",
            "INFO:tensorflow:global_step/sec: 857.541\n",
            "INFO:tensorflow:loss = 73.93711, step = 101 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 720.501\n",
            "INFO:tensorflow:loss = 67.52806, step = 201 (0.138 sec)\n",
            "INFO:tensorflow:global_step/sec: 1117.88\n",
            "INFO:tensorflow:loss = 66.41782, step = 301 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.617\n",
            "INFO:tensorflow:loss = 65.983215, step = 401 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1016.69\n",
            "INFO:tensorflow:loss = 65.53395, step = 501 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1065.5\n",
            "INFO:tensorflow:loss = 65.033066, step = 601 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1167.88\n",
            "INFO:tensorflow:loss = 64.48336, step = 701 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1099.42\n",
            "INFO:tensorflow:loss = 63.888256, step = 801 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1060.75\n",
            "INFO:tensorflow:loss = 63.250847, step = 901 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1044.47\n",
            "INFO:tensorflow:loss = 62.57393, step = 1001 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 994.403\n",
            "INFO:tensorflow:loss = 61.86023, step = 1101 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1068.32\n",
            "INFO:tensorflow:loss = 61.11242, step = 1201 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1008.18\n",
            "INFO:tensorflow:loss = 63.04312, step = 1301 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1146.45\n",
            "INFO:tensorflow:loss = 59.721485, step = 1401 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.6\n",
            "INFO:tensorflow:loss = 59.04766, step = 1501 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1096.73\n",
            "INFO:tensorflow:loss = 61.063114, step = 1601 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.12\n",
            "INFO:tensorflow:loss = 57.76712, step = 1701 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1140.45\n",
            "INFO:tensorflow:loss = 57.12228, step = 1801 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1056\n",
            "INFO:tensorflow:loss = 56.495182, step = 1901 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1042.98\n",
            "INFO:tensorflow:loss = 56.161514, step = 2001 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1127.56\n",
            "INFO:tensorflow:loss = 55.355507, step = 2101 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1066.38\n",
            "INFO:tensorflow:loss = 54.779526, step = 2201 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1155.79\n",
            "INFO:tensorflow:loss = 55.692253, step = 2301 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1006.99\n",
            "INFO:tensorflow:loss = 53.736385, step = 2401 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1141.25\n",
            "INFO:tensorflow:loss = 53.2169, step = 2501 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 977.823\n",
            "INFO:tensorflow:loss = 86.10609, step = 2601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1125.95\n",
            "INFO:tensorflow:loss = 52.244358, step = 2701 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1115.88\n",
            "INFO:tensorflow:loss = 51.769585, step = 2801 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1134.15\n",
            "INFO:tensorflow:loss = 86.019585, step = 2901 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1149.97\n",
            "INFO:tensorflow:loss = 50.88264, step = 3001 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1067.85\n",
            "INFO:tensorflow:loss = 50.44931, step = 3101 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1029.16\n",
            "INFO:tensorflow:loss = 1426.8085, step = 3201 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1059.14\n",
            "INFO:tensorflow:loss = 49.63745, step = 3301 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1125.63\n",
            "INFO:tensorflow:loss = 49.24583, step = 3401 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1120.43\n",
            "INFO:tensorflow:loss = 48.852386, step = 3501 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1173.63\n",
            "INFO:tensorflow:loss = 51.249664, step = 3601 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1125.96\n",
            "INFO:tensorflow:loss = 48.135513, step = 3701 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1006.16\n",
            "INFO:tensorflow:loss = 47.780037, step = 3801 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1151.44\n",
            "INFO:tensorflow:loss = 49.860535, step = 3901 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1068.29\n",
            "INFO:tensorflow:loss = 47.117073, step = 4001 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1073.2\n",
            "INFO:tensorflow:loss = 46.79354, step = 4101 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1129.69\n",
            "INFO:tensorflow:loss = 238.1141, step = 4201 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1178.62\n",
            "INFO:tensorflow:loss = 46.210037, step = 4301 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1107.43\n",
            "INFO:tensorflow:loss = 45.89898, step = 4401 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1138.87\n",
            "INFO:tensorflow:loss = 45.606663, step = 4501 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1144.64\n",
            "INFO:tensorflow:loss = 45.328568, step = 4601 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1107.43\n",
            "INFO:tensorflow:loss = 45.070213, step = 4701 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1183.07\n",
            "INFO:tensorflow:loss = 44.806236, step = 4801 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1089.89\n",
            "INFO:tensorflow:loss = 46.977623, step = 4901 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1119.85\n",
            "INFO:tensorflow:loss = 44.31427, step = 5001 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1082.34\n",
            "INFO:tensorflow:loss = 44.073082, step = 5101 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1081.78\n",
            "INFO:tensorflow:loss = 45.256012, step = 5201 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1037.38\n",
            "INFO:tensorflow:loss = 43.695766, step = 5301 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1147.69\n",
            "INFO:tensorflow:loss = 43.40006, step = 5401 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1115.58\n",
            "INFO:tensorflow:loss = 43.181213, step = 5501 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 963.862\n",
            "INFO:tensorflow:loss = 45.932728, step = 5601 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1118.08\n",
            "INFO:tensorflow:loss = 42.784256, step = 5701 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1053.31\n",
            "INFO:tensorflow:loss = 42.58827, step = 5801 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1121.94\n",
            "INFO:tensorflow:loss = 598.6491, step = 5901 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1029.01\n",
            "INFO:tensorflow:loss = 42.233276, step = 6001 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1125.89\n",
            "INFO:tensorflow:loss = 42.046146, step = 6101 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1146.83\n",
            "INFO:tensorflow:loss = 41.869244, step = 6201 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1009.12\n",
            "INFO:tensorflow:loss = 53.459038, step = 6301 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1106.17\n",
            "INFO:tensorflow:loss = 41.543377, step = 6401 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1042.87\n",
            "INFO:tensorflow:loss = 41.383713, step = 6501 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1162.64\n",
            "INFO:tensorflow:loss = 882.1758, step = 6601 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1106.77\n",
            "INFO:tensorflow:loss = 41.13992, step = 6701 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1160.69\n",
            "INFO:tensorflow:loss = 40.945114, step = 6801 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1123.69\n",
            "INFO:tensorflow:loss = 40.80346, step = 6901 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1099.44\n",
            "INFO:tensorflow:loss = 411.1479, step = 7001 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1069.46\n",
            "INFO:tensorflow:loss = 40.599724, step = 7101 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1012.5\n",
            "INFO:tensorflow:loss = 40.41153, step = 7201 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1042.11\n",
            "INFO:tensorflow:loss = 40.28469, step = 7301 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1048.88\n",
            "INFO:tensorflow:loss = 134.67072, step = 7401 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 1048.7\n",
            "INFO:tensorflow:loss = 40.048153, step = 7501 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1010.42\n",
            "INFO:tensorflow:loss = 39.92975, step = 7601 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 997.651\n",
            "INFO:tensorflow:loss = 236.1532, step = 7701 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1037.1\n",
            "INFO:tensorflow:loss = 39.712315, step = 7801 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1142.75\n",
            "INFO:tensorflow:loss = 39.6062, step = 7901 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1110.4\n",
            "INFO:tensorflow:loss = 42.23884, step = 8001 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1033.25\n",
            "INFO:tensorflow:loss = 39.429718, step = 8101 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1065.88\n",
            "INFO:tensorflow:loss = 39.31053, step = 8201 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1104.61\n",
            "INFO:tensorflow:loss = 39.21443, step = 8301 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1155.52\n",
            "INFO:tensorflow:loss = 39.643795, step = 8401 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.73\n",
            "INFO:tensorflow:loss = 39.038918, step = 8501 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 968.27\n",
            "INFO:tensorflow:loss = 38.95195, step = 8601 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1067.19\n",
            "INFO:tensorflow:loss = 44.141064, step = 8701 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1079.51\n",
            "INFO:tensorflow:loss = 38.791363, step = 8801 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1169.34\n",
            "INFO:tensorflow:loss = 38.715385, step = 8901 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1076.66\n",
            "INFO:tensorflow:loss = 38.63784, step = 9001 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1110.03\n",
            "INFO:tensorflow:loss = 93.580444, step = 9101 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1190.82\n",
            "INFO:tensorflow:loss = 38.49626, step = 9201 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1019.67\n",
            "INFO:tensorflow:loss = 38.42524, step = 9301 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1167.55\n",
            "INFO:tensorflow:loss = 38.398846, step = 9401 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1069.54\n",
            "INFO:tensorflow:loss = 38.31794, step = 9501 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1016.67\n",
            "INFO:tensorflow:loss = 38.229313, step = 9601 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 954.729\n",
            "INFO:tensorflow:loss = 38.166, step = 9701 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1098.29\n",
            "INFO:tensorflow:loss = 54.31258, step = 9801 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1095\n",
            "INFO:tensorflow:loss = 38.0495, step = 9901 (0.095 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 37.99214.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "// DNNRegression has RMSE of 15.15753173828125\n",
            "// Just using average = 109.5 has RMSE of 12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjS3zTafVMB8",
        "outputId": "94342f6d-e563-4fa4-ff56-0d17177f4c1b"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'DAY' : [1,1,1],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'YEAR' : [2013, 2016, 2022]\n",
        "        })\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model', \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "print(preds)\n",
        "\n",
        "# The Number of collisions scale will be 106.104 - which is the average number of collisions in Manhattan (rounding this to 106)\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores'] * 106\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f775097c9d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "{'scores': array([ 882.93146,  963.4941 , 1061.203  ], dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hnzo1hOFa-l"
      },
      "source": [
        "### Result of First Run\n",
        "\n",
        "The model is being asked to predict 3 dates.  Two of these dates are known, this will allow how accurate the model is in relateion to real data to be shown.\n",
        "\n",
        "The dates are:\n",
        "\n",
        "1/1/2013  = 882\n",
        "1/6/2016 = 963\n",
        "1/12/2020 = 1061"
      ]
    }
  ]
}