{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J_Adams_Assignment_Part_2--.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2YM-cY3XAb1"
      },
      "source": [
        "# Training a linear regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4OkOIjgXImQ"
      },
      "source": [
        "### Background\n",
        "\n",
        "The dataset which was created for part 1 has been constructed so that each borough can be identified.  This means that a linear regressor could be made for each indivual borough.  As the code uses the dataset with the same structure, what works for one, would work for all.  However, in order to simplifiy this notebook, only one borough will be used.  That borough is Manhatten.\n",
        "\n",
        "To begin with, the data must first be loaded.  Once loaded, using the query method of the pandas dataframe the rows which are in Mahattan can be extracted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUkPRKJw1mm6"
      },
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load the data as per normal\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv', index_col=0)\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/adamsjoe/Data_Analytics_On_The_Web/main/Final_Data/Final_Data_Collated.csv')\n",
        "\n",
        "# now setup to query the dataframe for only the boroughs noted\n",
        "manhat_df = df.query('BOROUGH==\"MANHATTAN\"').head()\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYJbRFX5YExF"
      },
      "source": [
        "#### Data Verification\n",
        "\n",
        "Once the data has been loaded, it is a good idea to check this.  Printing only 6 rows shows that all are Manhattan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNzPMAL314nG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5811865f-b55e-4593-ca6b-022bea7389c2"
      },
      "source": [
        "# check the data had loaded by printing it\n",
        "print(manhat_df[:6])\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          DATE    BOROUGH  WEEKDAY  ...  PERS_KILL  PERS_INJD  NUM_COLS\n",
            "0   2012-08-21  MANHATTAN        2  ...          0         28       109\n",
            "6   2012-10-27  MANHATTAN        6  ...          0         20       122\n",
            "13  2012-08-25  MANHATTAN        6  ...          0         22        97\n",
            "16  2012-09-09  MANHATTAN        7  ...          0         29       109\n",
            "20  2012-09-17  MANHATTAN        1  ...          1         27       123\n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSW7NtK4dBAj"
      },
      "source": [
        "## Import numpy and shuffle\n",
        "\n",
        "Create a new shuffled data by using the random permutation function of numpy using the length of the original mahattan data frame.  In this particular data set this is important as the data is time series (or time series derived) and there could be patterns within the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-NlRVds2BEM"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "shuffle_manhatten = manhat_df.iloc[np.random.permutation(len(manhat_df))]\n",
        "shuffle_manhatten[:5]\n",
        "\n",
        "# setup constant for use later\n",
        "SCALE_NUM_COLS = 1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFG25By8dtfc"
      },
      "source": [
        "## Predictors, Training set and Testing set\n",
        "\n",
        "Firstly the predictors are created.  These are created from the shuffled data and only the third, fourth, fifth, seventh and last column is used.  These are, in order, year, month, day, temp and num_cols (number of collisions).  If the data was not being filtered by borough at the start, then the borough would need to be brought in also.\n",
        "\n",
        "The Target is then defined - this is the last column in the shuffled dataset.\n",
        "\n",
        "The training set will be 80% of the full data set (0.8) and the testing data will be the remainder - so in this case, 100 - 80 = 20%\n",
        "\n",
        "Constants are setup for the number of predictors (3 in this case: year, month and day) and the number of outputs (or targets, which is 1 here.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01AcNdrBh3o"
      },
      "source": [
        "# select the day, month, year and number of collisions columns.  \n",
        "predictors_manhatten = shuffle_manhatten.iloc[:,[3,4,5]]\n",
        "\n",
        "targets_manhattan = shuffle_manhatten.iloc[:,-1]\n",
        "\n",
        "# split data into training set\n",
        "training_size_manhattan = int(len(shuffle_manhatten['NUM_COLS']) * 0.8)\n",
        "\n",
        "# test size is the size of the data - the training size (in this case 20%)\n",
        "testing_size_manhattan = len(shuffle_manhatten['NUM_COLS']) - training_size_manhattan\n",
        "\n",
        "# define the number of input params, day, month and year = 3 (predictors)\n",
        "NO_PREDICTORS_MANHATTAN = 4\n",
        "\n",
        "# define the number of output params, collisions = 1 (targets)\n",
        "NO_TARGETS = 1\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9cyW1wjfAIk"
      },
      "source": [
        "### Verification\n",
        "\n",
        "Just a simple print to ensure the predictor and values are populated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYOnh5yUElQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3c5e866-4e5c-49f9-b0e0-b27f9bd1ee45"
      },
      "source": [
        "print(predictors_manhatten.values)\n",
        "print(predictors_manhatten)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2012    9    9]\n",
            " [2012    8   21]\n",
            " [2012    8   25]\n",
            " [2012    9   17]\n",
            " [2012   10   27]]\n",
            "    YEAR  MONTH  DAY\n",
            "16  2012      9    9\n",
            "0   2012      8   21\n",
            "13  2012      8   25\n",
            "20  2012      9   17\n",
            "6   2012     10   27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axySTDY1fKHw"
      },
      "source": [
        "## The Tensorflow bit.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIj_sLztBlsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e7085a-264c-472f-9a2c-91e0c5afb008"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# check tensor version\n",
        "print(tf.__version__)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# logging for tensorflow\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "# setup some variables to hold the file path\n",
        "manhattan_dir = '/tmp/linear_regression_trained_model'\n",
        "\n",
        "# remove the last training model\n",
        "shutil.rmtree(manhattan_dir, ignore_errors=True)\n",
        "\n",
        "# estimators for each borough\n",
        "# estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.DNNRegressor(\n",
        "#     model_dir=manhattan_dir, \n",
        "#     hidden_units=[20,18,14], \n",
        "#     optimizer=tf.train.AdamOptimizer(learning_rate=0.01), \n",
        "#     enable_centered_bias=False, \n",
        "#     feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)\n",
        "#     )\n",
        "# )\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir=manhattan_dir, optimizer=tf.train.AdamOptimizer(learning_rate=0.1), enable_centered_bias=False, feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors_manhatten.values)))\n",
        "\n",
        "\n",
        "# # Prints a log to show model is starting to train\n",
        "print(\"// Starting to train Manhattan model............\");\n",
        "\n",
        "# Train the model. Pass in predictor values and target values.\n",
        "estimator_manhattan.fit(\n",
        "    predictors_manhatten[:training_size_manhattan].values, \n",
        "    targets_manhattan[:training_size_manhattan].values.reshape(training_size_manhattan, \n",
        "    NO_TARGETS)/SCALE_NUM_COLS, \n",
        "    steps=10000\n",
        ")\n",
        "\n",
        "# Next, we can check our predictions based on our predictors.\n",
        "preds = estimator_manhattan.predict(x=predictors_manhatten[training_size_manhattan:].values)\n",
        "\n",
        "# Apply the Scale value (not really needed here) to the outputs.\n",
        "predslistscale = preds['scores'] * SCALE_NUM_COLS\n",
        "\n",
        "# pred = format(str(predslistscale)) # useful for checking outputs and printing.\n",
        "\n",
        "# Calculate RMSE i.e. how good the model works using the predictions and targets.\n",
        "# i.e. take the difference between the actual and the forecast then square the difference, \n",
        "# find the average of all the squares and then find the square root. \n",
        "# The RMSE essentially punishes larger errors i.e. it puts a heavier weight on larger errors.\n",
        "rmse = np.sqrt(np.mean((targets_manhattan[training_size_manhattan:].values - predslistscale)**2))\n",
        "print('// DNNRegression has RMSE of {0}'.format(rmse));\n",
        "\n",
        "\n",
        "# Calculate the mean of the NUM_COLS Values.\n",
        "avg = np.mean(shuffle_manhatten['NUM_COLS'][:training_size_manhattan])\n",
        "\n",
        "# Calculate the RMSE using NUM_COLS Values and the mean of all target values.\n",
        "# The fit of a proposed regression model should therefore be better than the fit of the mean model.\n",
        "# In this case, it doesn't seem to be the case but it will vary on every run.\n",
        "rmse = np.sqrt(np.mean((shuffle_manhatten['NUM_COLS'][training_size_manhattan:] - avg)**2))\n",
        "print('// Just using average = {0} has RMSE of {1}'.format(avg, rmse));"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff8e7649b10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "// Starting to train Manhattan model............\n",
            "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 12075.0, step = 1\n",
            "INFO:tensorflow:global_step/sec: 950.811\n",
            "INFO:tensorflow:loss = 73.93711, step = 101 (0.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1073.92\n",
            "INFO:tensorflow:loss = 67.52806, step = 201 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1071.27\n",
            "INFO:tensorflow:loss = 66.41782, step = 301 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1030.8\n",
            "INFO:tensorflow:loss = 65.98319, step = 401 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 1070.25\n",
            "INFO:tensorflow:loss = 65.533936, step = 501 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1000.34\n",
            "INFO:tensorflow:loss = 65.03302, step = 601 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1071.39\n",
            "INFO:tensorflow:loss = 64.48336, step = 701 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1138.27\n",
            "INFO:tensorflow:loss = 63.888306, step = 801 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1137.83\n",
            "INFO:tensorflow:loss = 63.250866, step = 901 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1026.04\n",
            "INFO:tensorflow:loss = 62.57393, step = 1001 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 844.939\n",
            "INFO:tensorflow:loss = 61.86023, step = 1101 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 981.746\n",
            "INFO:tensorflow:loss = 61.112453, step = 1201 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1039.87\n",
            "INFO:tensorflow:loss = 93.337845, step = 1301 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1093.84\n",
            "INFO:tensorflow:loss = 59.712364, step = 1401 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 986.698\n",
            "INFO:tensorflow:loss = 59.02882, step = 1501 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1081.57\n",
            "INFO:tensorflow:loss = 186.95506, step = 1601 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1125.64\n",
            "INFO:tensorflow:loss = 57.742172, step = 1701 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 863.754\n",
            "INFO:tensorflow:loss = 57.111015, step = 1801 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 1021.89\n",
            "INFO:tensorflow:loss = 385.10242, step = 1901 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 965.657\n",
            "INFO:tensorflow:loss = 55.953285, step = 2001 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1023.9\n",
            "INFO:tensorflow:loss = 55.34504, step = 2101 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1131.91\n",
            "INFO:tensorflow:loss = 54.763412, step = 2201 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1188.59\n",
            "INFO:tensorflow:loss = 54.314423, step = 2301 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1204.6\n",
            "INFO:tensorflow:loss = 53.738518, step = 2401 (0.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 993.518\n",
            "INFO:tensorflow:loss = 53.22176, step = 2501 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1040.88\n",
            "INFO:tensorflow:loss = 52.782677, step = 2601 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1093.69\n",
            "INFO:tensorflow:loss = 52.24938, step = 2701 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 975.796\n",
            "INFO:tensorflow:loss = 51.781868, step = 2801 (0.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 1036.31\n",
            "INFO:tensorflow:loss = 71.98454, step = 2901 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1127.92\n",
            "INFO:tensorflow:loss = 50.96683, step = 3001 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 951.074\n",
            "INFO:tensorflow:loss = 50.464043, step = 3101 (0.103 sec)\n",
            "INFO:tensorflow:global_step/sec: 1056.07\n",
            "INFO:tensorflow:loss = 50.03426, step = 3201 (0.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 1113.87\n",
            "INFO:tensorflow:loss = 55.160522, step = 3301 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1195.28\n",
            "INFO:tensorflow:loss = 49.255302, step = 3401 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1172.49\n",
            "INFO:tensorflow:loss = 48.871048, step = 3501 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1064.64\n",
            "INFO:tensorflow:loss = 50.78199, step = 3601 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1038.43\n",
            "INFO:tensorflow:loss = 48.166626, step = 3701 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1148.56\n",
            "INFO:tensorflow:loss = 47.79852, step = 3801 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1135.55\n",
            "INFO:tensorflow:loss = 47.44718, step = 3901 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1018.51\n",
            "INFO:tensorflow:loss = 47.68164, step = 4001 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 1178.62\n",
            "INFO:tensorflow:loss = 46.80648, step = 4101 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1156.31\n",
            "INFO:tensorflow:loss = 46.485615, step = 4201 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1029.23\n",
            "INFO:tensorflow:loss = 47.530792, step = 4301 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1107.33\n",
            "INFO:tensorflow:loss = 45.9033, step = 4401 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1130.26\n",
            "INFO:tensorflow:loss = 45.615395, step = 4501 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1113.94\n",
            "INFO:tensorflow:loss = 466.4668, step = 4601 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1081.17\n",
            "INFO:tensorflow:loss = 45.0885, step = 4701 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1156.09\n",
            "INFO:tensorflow:loss = 44.81904, step = 4801 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1058.94\n",
            "INFO:tensorflow:loss = 44.557755, step = 4901 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1122\n",
            "INFO:tensorflow:loss = 44.328194, step = 5001 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1113.11\n",
            "INFO:tensorflow:loss = 44.080647, step = 5101 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1029.92\n",
            "INFO:tensorflow:loss = 43.843525, step = 5201 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1143.11\n",
            "INFO:tensorflow:loss = 56.707172, step = 5301 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1025.56\n",
            "INFO:tensorflow:loss = 43.4056, step = 5401 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 1053.17\n",
            "INFO:tensorflow:loss = 43.190723, step = 5501 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 1137.47\n",
            "INFO:tensorflow:loss = 425.16537, step = 5601 (0.088 sec)\n",
            "INFO:tensorflow:global_step/sec: 1030.29\n",
            "INFO:tensorflow:loss = 42.79234, step = 5701 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 957.612\n",
            "INFO:tensorflow:loss = 42.59461, step = 5801 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 994.743\n",
            "INFO:tensorflow:loss = 42.399868, step = 5901 (0.102 sec)\n",
            "INFO:tensorflow:global_step/sec: 1100.13\n",
            "INFO:tensorflow:loss = 42.42825, step = 6001 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 965.915\n",
            "INFO:tensorflow:loss = 42.045265, step = 6101 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 985.821\n",
            "INFO:tensorflow:loss = 41.86778, step = 6201 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 998.827\n",
            "INFO:tensorflow:loss = 43.347305, step = 6301 (0.100 sec)\n",
            "INFO:tensorflow:global_step/sec: 892.768\n",
            "INFO:tensorflow:loss = 41.542023, step = 6401 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 1137.4\n",
            "INFO:tensorflow:loss = 41.381615, step = 6501 (0.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 1069.46\n",
            "INFO:tensorflow:loss = 144.41449, step = 6601 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1035.74\n",
            "INFO:tensorflow:loss = 41.086838, step = 6701 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1119.9\n",
            "INFO:tensorflow:loss = 40.938248, step = 6801 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1063.58\n",
            "INFO:tensorflow:loss = 40.796604, step = 6901 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 972.653\n",
            "INFO:tensorflow:loss = 40.863926, step = 7001 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1047.7\n",
            "INFO:tensorflow:loss = 40.529922, step = 7101 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 1112.35\n",
            "INFO:tensorflow:loss = 40.398075, step = 7201 (0.090 sec)\n",
            "INFO:tensorflow:global_step/sec: 1077.71\n",
            "INFO:tensorflow:loss = 49.940258, step = 7301 (0.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 1062.91\n",
            "INFO:tensorflow:loss = 40.155083, step = 7401 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1068.11\n",
            "INFO:tensorflow:loss = 40.03608, step = 7501 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1138.41\n",
            "INFO:tensorflow:loss = 782.31805, step = 7601 (0.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1166.08\n",
            "INFO:tensorflow:loss = 39.82416, step = 7701 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 958.812\n",
            "INFO:tensorflow:loss = 39.706993, step = 7801 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 1050.91\n",
            "INFO:tensorflow:loss = 39.599495, step = 7901 (0.097 sec)\n",
            "INFO:tensorflow:global_step/sec: 1024.9\n",
            "INFO:tensorflow:loss = 69.67966, step = 8001 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 1048.4\n",
            "INFO:tensorflow:loss = 39.4057, step = 8101 (0.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 1069.72\n",
            "INFO:tensorflow:loss = 39.310486, step = 8201 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1170.91\n",
            "INFO:tensorflow:loss = 39.21482, step = 8301 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1050.15\n",
            "INFO:tensorflow:loss = 43.183784, step = 8401 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 982.995\n",
            "INFO:tensorflow:loss = 39.039387, step = 8501 (0.101 sec)\n",
            "INFO:tensorflow:global_step/sec: 1113.19\n",
            "INFO:tensorflow:loss = 38.95379, step = 8601 (0.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 1004.36\n",
            "INFO:tensorflow:loss = 123.367485, step = 8701 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1086.71\n",
            "INFO:tensorflow:loss = 38.80523, step = 8801 (0.089 sec)\n",
            "INFO:tensorflow:global_step/sec: 1033.99\n",
            "INFO:tensorflow:loss = 38.71409, step = 8901 (0.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 1022.79\n",
            "INFO:tensorflow:loss = 38.63614, step = 9001 (0.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1165.52\n",
            "INFO:tensorflow:loss = 48.97747, step = 9101 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 907.667\n",
            "INFO:tensorflow:loss = 38.49318, step = 9201 (0.110 sec)\n",
            "INFO:tensorflow:global_step/sec: 1070.48\n",
            "INFO:tensorflow:loss = 38.422714, step = 9301 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1133.84\n",
            "INFO:tensorflow:loss = 48.438927, step = 9401 (0.086 sec)\n",
            "INFO:tensorflow:global_step/sec: 1151.42\n",
            "INFO:tensorflow:loss = 38.293495, step = 9501 (0.087 sec)\n",
            "INFO:tensorflow:global_step/sec: 1072.65\n",
            "INFO:tensorflow:loss = 38.22629, step = 9601 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1106.03\n",
            "INFO:tensorflow:loss = 48.493355, step = 9701 (0.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 1143.32\n",
            "INFO:tensorflow:loss = 38.17265, step = 9801 (0.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 1149.38\n",
            "INFO:tensorflow:loss = 38.04775, step = 9901 (0.086 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/linear_regression_trained_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 37.99044.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "// DNNRegression has RMSE of 15.16278076171875\n",
            "// Just using average = 109.5 has RMSE of 12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjS3zTafVMB8",
        "outputId": "2a34ffb3-790b-4d1e-e806-a6585cbdff74"
      },
      "source": [
        "input = pd.DataFrame.from_dict(data = \n",
        "\t\t\t\t{'DAY' : [1,1,1],\n",
        "         'MONTH' : [1, 6, 12],\n",
        "         'YEAR' : [2013, 2016, 2022]\n",
        "        })\n",
        "\n",
        "estimator_manhattan = tf.contrib.learn.SKCompat(tf.contrib.learn.LinearRegressor(model_dir='/tmp/linear_regression_trained_model', \n",
        "                                                                                 enable_centered_bias=False, \n",
        "                                                                                 feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values)))\n",
        "\n",
        "preds = estimator_manhattan.predict(x=input.values)\n",
        "print(preds)\n",
        "\n",
        "# Assume number of trips scale value is 600000 when at a maximum, based on the analysis from Tutorial 2\n",
        "predslistnorm = preds['scores']\n",
        "predslistscale = preds['scores']*600000\n",
        "prednorm = format(str(predslistnorm))\n",
        "pred = format(str(predslistscale))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff8e744f290>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/linear_regression_trained_model', '_session_creation_timeout_secs': 7200}\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/linear_regression_trained_model/model.ckpt-10000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "{'scores': array([ 883.2694,  963.8441, 1061.5681], dtype=float32)}\n"
          ]
        }
      ]
    }
  ]
}